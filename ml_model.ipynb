{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXioJ69rYWlQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xxM_VbSbbeN",
        "outputId": "430ae946-d708-490c-a94e-58a0ace33759"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 2.07MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.6MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.34MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Introduce parameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "lr = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# Loading Dataset\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32,32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.1307), std = (0.3081))\n",
        "    ])\n",
        ", download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train= False,\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32,32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean =(0.1325), std=(0.1305))\n",
        "    ])\n",
        ", download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NeORvY4gs8D",
        "outputId": "654839ac-74cd-427c-dfcf-27ac07bffa46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train dataset size 60000\n",
            "test dataset size 10000\n"
          ]
        }
      ],
      "source": [
        "# check dataset size\n",
        "print('train dataset size', len(train_dataset))\n",
        "print('test dataset size', len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wPSan_DijlM"
      },
      "outputs": [],
      "source": [
        "# Defining Convolutional Neural Network\n",
        "# Functional API\n",
        "\n",
        "class LeNet5(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(LeNet5, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(1,6, kernel_size=5, stride=1, padding=0),\n",
        "        nn.BatchNorm2d(6),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride =2)\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(6,16, kernel_size = 5, stride=1, padding=0),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc = nn.Linear(400, 120)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc1 = nn.Linear(120, 84)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(84, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc1(out)\n",
        "    out = self.relu1(out)\n",
        "    out = self.fc2(out)\n",
        "    return out\n",
        "\n",
        "model = LeNet5(num_classes)\n",
        "\n",
        "# Defining Loss Calculation function\n",
        "cost = nn.CrossEntropyLoss()\n",
        "\n",
        "# Defining Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWVBGZ7i9TSv",
        "outputId": "d0859e3a-5efa-4ada-d19a-9d52a0b2183e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 5/10, Step: 629/938, Loss: 0.003361918032169342\n",
            "Epoch: 5/10, Step: 630/938, Loss: 0.07565367966890335\n",
            "Epoch: 5/10, Step: 631/938, Loss: 0.010830060578882694\n",
            "Epoch: 5/10, Step: 632/938, Loss: 8.949342009145766e-05\n",
            "Epoch: 5/10, Step: 633/938, Loss: 0.017498379573225975\n",
            "Epoch: 5/10, Step: 634/938, Loss: 0.00018575586727820337\n",
            "Epoch: 5/10, Step: 635/938, Loss: 0.013257138431072235\n",
            "Epoch: 5/10, Step: 636/938, Loss: 0.0002461170661263168\n",
            "Epoch: 5/10, Step: 637/938, Loss: 5.595730181084946e-05\n",
            "Epoch: 5/10, Step: 638/938, Loss: 0.00014165250468067825\n",
            "Epoch: 5/10, Step: 639/938, Loss: 0.0003704586415551603\n",
            "Epoch: 5/10, Step: 640/938, Loss: 0.008190135471522808\n",
            "Epoch: 5/10, Step: 641/938, Loss: 0.0004038750194013119\n",
            "Epoch: 5/10, Step: 642/938, Loss: 0.002989268396049738\n",
            "Epoch: 5/10, Step: 643/938, Loss: 0.0009864631574600935\n",
            "Epoch: 5/10, Step: 644/938, Loss: 0.0019104795064777136\n",
            "Epoch: 5/10, Step: 645/938, Loss: 0.008559586480259895\n",
            "Epoch: 5/10, Step: 646/938, Loss: 4.434273068909533e-05\n",
            "Epoch: 5/10, Step: 647/938, Loss: 0.037334833294153214\n",
            "Epoch: 5/10, Step: 648/938, Loss: 0.007388996426016092\n",
            "Epoch: 5/10, Step: 649/938, Loss: 0.0044172946363687515\n",
            "Epoch: 5/10, Step: 650/938, Loss: 0.0011218106374144554\n",
            "Epoch: 5/10, Step: 651/938, Loss: 2.1010728232795373e-05\n",
            "Epoch: 5/10, Step: 652/938, Loss: 0.0044826543889939785\n",
            "Epoch: 5/10, Step: 653/938, Loss: 0.0021726812701672316\n",
            "Epoch: 5/10, Step: 654/938, Loss: 0.07768469303846359\n",
            "Epoch: 5/10, Step: 655/938, Loss: 7.424158684443682e-05\n",
            "Epoch: 5/10, Step: 656/938, Loss: 0.002854127436876297\n",
            "Epoch: 5/10, Step: 657/938, Loss: 0.0008142224396578968\n",
            "Epoch: 5/10, Step: 658/938, Loss: 0.0014304369688034058\n",
            "Epoch: 5/10, Step: 659/938, Loss: 0.00020809366833418608\n",
            "Epoch: 5/10, Step: 660/938, Loss: 3.1161460356088355e-05\n",
            "Epoch: 5/10, Step: 661/938, Loss: 0.013137808069586754\n",
            "Epoch: 5/10, Step: 662/938, Loss: 0.0023180139251053333\n",
            "Epoch: 5/10, Step: 663/938, Loss: 0.0018542816396802664\n",
            "Epoch: 5/10, Step: 664/938, Loss: 5.336916365195066e-05\n",
            "Epoch: 5/10, Step: 665/938, Loss: 0.00040687393629923463\n",
            "Epoch: 5/10, Step: 666/938, Loss: 0.0040760464034974575\n",
            "Epoch: 5/10, Step: 667/938, Loss: 0.00011808470299001783\n",
            "Epoch: 5/10, Step: 668/938, Loss: 0.005155759863555431\n",
            "Epoch: 5/10, Step: 669/938, Loss: 0.006549233570694923\n",
            "Epoch: 5/10, Step: 670/938, Loss: 0.004256737418472767\n",
            "Epoch: 5/10, Step: 671/938, Loss: 0.013261576183140278\n",
            "Epoch: 5/10, Step: 672/938, Loss: 0.03557313606142998\n",
            "Epoch: 5/10, Step: 673/938, Loss: 0.0018268396379426122\n",
            "Epoch: 5/10, Step: 674/938, Loss: 0.00015761912800371647\n",
            "Epoch: 5/10, Step: 675/938, Loss: 7.040922355372459e-05\n",
            "Epoch: 5/10, Step: 676/938, Loss: 0.03058258816599846\n",
            "Epoch: 5/10, Step: 677/938, Loss: 0.00046364328591153026\n",
            "Epoch: 5/10, Step: 678/938, Loss: 0.000155387373524718\n",
            "Epoch: 5/10, Step: 679/938, Loss: 0.00034049287205561996\n",
            "Epoch: 5/10, Step: 680/938, Loss: 0.00017803817172534764\n",
            "Epoch: 5/10, Step: 681/938, Loss: 0.00017406004189979285\n",
            "Epoch: 5/10, Step: 682/938, Loss: 0.0005870948662050068\n",
            "Epoch: 5/10, Step: 683/938, Loss: 0.0003396616375539452\n",
            "Epoch: 5/10, Step: 684/938, Loss: 7.3878480179701e-05\n",
            "Epoch: 5/10, Step: 685/938, Loss: 0.1048971638083458\n",
            "Epoch: 5/10, Step: 686/938, Loss: 0.00033906326279975474\n",
            "Epoch: 5/10, Step: 687/938, Loss: 0.007971539162099361\n",
            "Epoch: 5/10, Step: 688/938, Loss: 0.0013916842872276902\n",
            "Epoch: 5/10, Step: 689/938, Loss: 0.04711835831403732\n",
            "Epoch: 5/10, Step: 690/938, Loss: 3.612949149101041e-05\n",
            "Epoch: 5/10, Step: 691/938, Loss: 0.001431560842320323\n",
            "Epoch: 5/10, Step: 692/938, Loss: 0.00019371116650290787\n",
            "Epoch: 5/10, Step: 693/938, Loss: 0.0004419823526404798\n",
            "Epoch: 5/10, Step: 694/938, Loss: 0.0016586050624027848\n",
            "Epoch: 5/10, Step: 695/938, Loss: 0.0011892089387401938\n",
            "Epoch: 5/10, Step: 696/938, Loss: 0.0012376295635476708\n",
            "Epoch: 5/10, Step: 697/938, Loss: 0.04688919708132744\n",
            "Epoch: 5/10, Step: 698/938, Loss: 0.0007385398494079709\n",
            "Epoch: 5/10, Step: 699/938, Loss: 0.002019970677793026\n",
            "Epoch: 5/10, Step: 700/938, Loss: 0.004756297450512648\n",
            "Epoch: 5/10, Step: 701/938, Loss: 0.00038252482772804797\n",
            "Epoch: 5/10, Step: 702/938, Loss: 0.007335579488426447\n",
            "Epoch: 5/10, Step: 703/938, Loss: 0.024594994261860847\n",
            "Epoch: 5/10, Step: 704/938, Loss: 0.01916602812707424\n",
            "Epoch: 5/10, Step: 705/938, Loss: 0.005563585553318262\n",
            "Epoch: 5/10, Step: 706/938, Loss: 6.977736484259367e-05\n",
            "Epoch: 5/10, Step: 707/938, Loss: 0.0001815890136640519\n",
            "Epoch: 5/10, Step: 708/938, Loss: 0.00190358969848603\n",
            "Epoch: 5/10, Step: 709/938, Loss: 0.00040289165917783976\n",
            "Epoch: 5/10, Step: 710/938, Loss: 0.01117172185331583\n",
            "Epoch: 5/10, Step: 711/938, Loss: 0.012160067446529865\n",
            "Epoch: 5/10, Step: 712/938, Loss: 0.000631431583315134\n",
            "Epoch: 5/10, Step: 713/938, Loss: 0.003441269975155592\n",
            "Epoch: 5/10, Step: 714/938, Loss: 0.001245237304829061\n",
            "Epoch: 5/10, Step: 715/938, Loss: 0.005089576356112957\n",
            "Epoch: 5/10, Step: 716/938, Loss: 5.552585935220122e-05\n",
            "Epoch: 5/10, Step: 717/938, Loss: 0.012948074378073215\n",
            "Epoch: 5/10, Step: 718/938, Loss: 0.06615381687879562\n",
            "Epoch: 5/10, Step: 719/938, Loss: 0.0008608082425780594\n",
            "Epoch: 5/10, Step: 720/938, Loss: 0.0009053204557858407\n",
            "Epoch: 5/10, Step: 721/938, Loss: 0.10334885120391846\n",
            "Epoch: 5/10, Step: 722/938, Loss: 0.0010557138593867421\n",
            "Epoch: 5/10, Step: 723/938, Loss: 0.06455476582050323\n",
            "Epoch: 5/10, Step: 724/938, Loss: 0.0013148101279512048\n",
            "Epoch: 5/10, Step: 725/938, Loss: 0.0006578670581802726\n",
            "Epoch: 5/10, Step: 726/938, Loss: 0.0011327173560857773\n",
            "Epoch: 5/10, Step: 727/938, Loss: 0.00012891789083369076\n",
            "Epoch: 5/10, Step: 728/938, Loss: 1.894484921649564e-05\n",
            "Epoch: 5/10, Step: 729/938, Loss: 0.0006704292027279735\n",
            "Epoch: 5/10, Step: 730/938, Loss: 0.006834686733782291\n",
            "Epoch: 5/10, Step: 731/938, Loss: 0.07460040599107742\n",
            "Epoch: 5/10, Step: 732/938, Loss: 0.003580220276489854\n",
            "Epoch: 5/10, Step: 733/938, Loss: 0.0013280101120471954\n",
            "Epoch: 5/10, Step: 734/938, Loss: 0.00017361993377562612\n",
            "Epoch: 5/10, Step: 735/938, Loss: 0.00038578378735110164\n",
            "Epoch: 5/10, Step: 736/938, Loss: 0.00026445629191584885\n",
            "Epoch: 5/10, Step: 737/938, Loss: 0.019828511402010918\n",
            "Epoch: 5/10, Step: 738/938, Loss: 0.007841192185878754\n",
            "Epoch: 5/10, Step: 739/938, Loss: 0.0005007293075323105\n",
            "Epoch: 5/10, Step: 740/938, Loss: 0.00033768691355362535\n",
            "Epoch: 5/10, Step: 741/938, Loss: 0.027506353333592415\n",
            "Epoch: 5/10, Step: 742/938, Loss: 0.001457575592212379\n",
            "Epoch: 5/10, Step: 743/938, Loss: 0.00896772276610136\n",
            "Epoch: 5/10, Step: 744/938, Loss: 0.0025226327124983072\n",
            "Epoch: 5/10, Step: 745/938, Loss: 0.014663376845419407\n",
            "Epoch: 5/10, Step: 746/938, Loss: 0.011437349952757359\n",
            "Epoch: 5/10, Step: 747/938, Loss: 0.000768081983551383\n",
            "Epoch: 5/10, Step: 748/938, Loss: 6.716476491419598e-05\n",
            "Epoch: 5/10, Step: 749/938, Loss: 0.0019187744474038482\n",
            "Epoch: 5/10, Step: 750/938, Loss: 0.0012346924049779773\n",
            "Epoch: 5/10, Step: 751/938, Loss: 0.0015416236128658056\n",
            "Epoch: 5/10, Step: 752/938, Loss: 0.01118946447968483\n",
            "Epoch: 5/10, Step: 753/938, Loss: 0.006070695351809263\n",
            "Epoch: 5/10, Step: 754/938, Loss: 0.04712606966495514\n",
            "Epoch: 5/10, Step: 755/938, Loss: 0.002124388702213764\n",
            "Epoch: 5/10, Step: 756/938, Loss: 0.009914958849549294\n",
            "Epoch: 5/10, Step: 757/938, Loss: 0.00040114103467203677\n",
            "Epoch: 5/10, Step: 758/938, Loss: 0.008138736709952354\n",
            "Epoch: 5/10, Step: 759/938, Loss: 0.0009487377828918397\n",
            "Epoch: 5/10, Step: 760/938, Loss: 0.011500544846057892\n",
            "Epoch: 5/10, Step: 761/938, Loss: 0.0019273272482678294\n",
            "Epoch: 5/10, Step: 762/938, Loss: 7.113476749509573e-05\n",
            "Epoch: 5/10, Step: 763/938, Loss: 0.0001327493373537436\n",
            "Epoch: 5/10, Step: 764/938, Loss: 0.00011369437561370432\n",
            "Epoch: 5/10, Step: 765/938, Loss: 0.00025633772020228207\n",
            "Epoch: 5/10, Step: 766/938, Loss: 0.002097544725984335\n",
            "Epoch: 5/10, Step: 767/938, Loss: 4.879071639152244e-05\n",
            "Epoch: 5/10, Step: 768/938, Loss: 0.000781678594648838\n",
            "Epoch: 5/10, Step: 769/938, Loss: 0.002968525979667902\n",
            "Epoch: 5/10, Step: 770/938, Loss: 0.00014715740690007806\n",
            "Epoch: 5/10, Step: 771/938, Loss: 0.015318351797759533\n",
            "Epoch: 5/10, Step: 772/938, Loss: 0.004910659976303577\n",
            "Epoch: 5/10, Step: 773/938, Loss: 0.00031243939884006977\n",
            "Epoch: 5/10, Step: 774/938, Loss: 0.0002696777228266001\n",
            "Epoch: 5/10, Step: 775/938, Loss: 0.00023684148618485779\n",
            "Epoch: 5/10, Step: 776/938, Loss: 0.0032306495122611523\n",
            "Epoch: 5/10, Step: 777/938, Loss: 0.003202405758202076\n",
            "Epoch: 5/10, Step: 778/938, Loss: 0.0004984128172509372\n",
            "Epoch: 5/10, Step: 779/938, Loss: 0.009686501696705818\n",
            "Epoch: 5/10, Step: 780/938, Loss: 0.003650777507573366\n",
            "Epoch: 5/10, Step: 781/938, Loss: 0.00022272042406257242\n",
            "Epoch: 5/10, Step: 782/938, Loss: 0.003038247814401984\n",
            "Epoch: 5/10, Step: 783/938, Loss: 1.3616418073070236e-05\n",
            "Epoch: 5/10, Step: 784/938, Loss: 0.010333762504160404\n",
            "Epoch: 5/10, Step: 785/938, Loss: 0.0019401946337893605\n",
            "Epoch: 5/10, Step: 786/938, Loss: 3.866767201543553e-06\n",
            "Epoch: 5/10, Step: 787/938, Loss: 3.833197297353763e-06\n",
            "Epoch: 5/10, Step: 788/938, Loss: 0.016361622139811516\n",
            "Epoch: 5/10, Step: 789/938, Loss: 6.190623389557004e-05\n",
            "Epoch: 5/10, Step: 790/938, Loss: 2.6607584004523233e-05\n",
            "Epoch: 5/10, Step: 791/938, Loss: 0.006499655544757843\n",
            "Epoch: 5/10, Step: 792/938, Loss: 0.0003267009451519698\n",
            "Epoch: 5/10, Step: 793/938, Loss: 0.001851022127084434\n",
            "Epoch: 5/10, Step: 794/938, Loss: 0.028385378420352936\n",
            "Epoch: 5/10, Step: 795/938, Loss: 4.444380829227157e-05\n",
            "Epoch: 5/10, Step: 796/938, Loss: 2.849553493433632e-05\n",
            "Epoch: 5/10, Step: 797/938, Loss: 3.127561285509728e-05\n",
            "Epoch: 5/10, Step: 798/938, Loss: 7.26172438589856e-05\n",
            "Epoch: 5/10, Step: 799/938, Loss: 0.00015496076957788318\n",
            "Epoch: 5/10, Step: 800/938, Loss: 0.0004044913803227246\n",
            "Epoch: 5/10, Step: 801/938, Loss: 0.014991063624620438\n",
            "Epoch: 5/10, Step: 802/938, Loss: 0.0013400602620095015\n",
            "Epoch: 5/10, Step: 803/938, Loss: 0.0021916558034718037\n",
            "Epoch: 5/10, Step: 804/938, Loss: 0.005618071649223566\n",
            "Epoch: 5/10, Step: 805/938, Loss: 0.02672566846013069\n",
            "Epoch: 5/10, Step: 806/938, Loss: 0.0007303553866222501\n",
            "Epoch: 5/10, Step: 807/938, Loss: 0.17837117612361908\n",
            "Epoch: 5/10, Step: 808/938, Loss: 7.587146683363244e-05\n",
            "Epoch: 5/10, Step: 809/938, Loss: 1.0608772754494566e-05\n",
            "Epoch: 5/10, Step: 810/938, Loss: 0.003796136239543557\n",
            "Epoch: 5/10, Step: 811/938, Loss: 0.024511029943823814\n",
            "Epoch: 5/10, Step: 812/938, Loss: 3.7128796975594014e-05\n",
            "Epoch: 5/10, Step: 813/938, Loss: 0.0012916626874357462\n",
            "Epoch: 5/10, Step: 814/938, Loss: 0.00017424493853468448\n",
            "Epoch: 5/10, Step: 815/938, Loss: 0.002479719929397106\n",
            "Epoch: 5/10, Step: 816/938, Loss: 0.015538562089204788\n",
            "Epoch: 5/10, Step: 817/938, Loss: 0.05019929260015488\n",
            "Epoch: 5/10, Step: 818/938, Loss: 0.009156709536910057\n",
            "Epoch: 5/10, Step: 819/938, Loss: 0.025832178071141243\n",
            "Epoch: 5/10, Step: 820/938, Loss: 0.000286056223558262\n",
            "Epoch: 5/10, Step: 821/938, Loss: 0.0005945163429714739\n",
            "Epoch: 5/10, Step: 822/938, Loss: 0.0003544132341630757\n",
            "Epoch: 5/10, Step: 823/938, Loss: 0.0008272063569165766\n",
            "Epoch: 5/10, Step: 824/938, Loss: 0.00014787835243623704\n",
            "Epoch: 5/10, Step: 825/938, Loss: 0.01757868193089962\n",
            "Epoch: 5/10, Step: 826/938, Loss: 0.010767471045255661\n",
            "Epoch: 5/10, Step: 827/938, Loss: 0.004447099752724171\n",
            "Epoch: 5/10, Step: 828/938, Loss: 1.4164672393235378e-05\n",
            "Epoch: 5/10, Step: 829/938, Loss: 4.312121382099576e-05\n",
            "Epoch: 5/10, Step: 830/938, Loss: 0.008945888839662075\n",
            "Epoch: 5/10, Step: 831/938, Loss: 0.01899808645248413\n",
            "Epoch: 5/10, Step: 832/938, Loss: 0.013572929427027702\n",
            "Epoch: 5/10, Step: 833/938, Loss: 0.00014663442561868578\n",
            "Epoch: 5/10, Step: 834/938, Loss: 0.00013293014490045607\n",
            "Epoch: 5/10, Step: 835/938, Loss: 0.00501261604949832\n",
            "Epoch: 5/10, Step: 836/938, Loss: 0.06645694375038147\n",
            "Epoch: 5/10, Step: 837/938, Loss: 0.0001779307785909623\n",
            "Epoch: 5/10, Step: 838/938, Loss: 0.0014814576134085655\n",
            "Epoch: 5/10, Step: 839/938, Loss: 0.001907816738821566\n",
            "Epoch: 5/10, Step: 840/938, Loss: 0.001817018841393292\n",
            "Epoch: 5/10, Step: 841/938, Loss: 0.008978590369224548\n",
            "Epoch: 5/10, Step: 842/938, Loss: 9.62272533797659e-05\n",
            "Epoch: 5/10, Step: 843/938, Loss: 0.0015340495156124234\n",
            "Epoch: 5/10, Step: 844/938, Loss: 0.0755997747182846\n",
            "Epoch: 5/10, Step: 845/938, Loss: 0.002468009712174535\n",
            "Epoch: 5/10, Step: 846/938, Loss: 0.0002825174597091973\n",
            "Epoch: 5/10, Step: 847/938, Loss: 0.001646858756430447\n",
            "Epoch: 5/10, Step: 848/938, Loss: 0.0016212770715355873\n",
            "Epoch: 5/10, Step: 849/938, Loss: 2.366268017794937e-05\n",
            "Epoch: 5/10, Step: 850/938, Loss: 0.09023786336183548\n",
            "Epoch: 5/10, Step: 851/938, Loss: 7.631961489096284e-05\n",
            "Epoch: 5/10, Step: 852/938, Loss: 0.05199432745575905\n",
            "Epoch: 5/10, Step: 853/938, Loss: 0.022860275581479073\n",
            "Epoch: 5/10, Step: 854/938, Loss: 0.01949995756149292\n",
            "Epoch: 5/10, Step: 855/938, Loss: 0.00423716614022851\n",
            "Epoch: 5/10, Step: 856/938, Loss: 0.012620181776583195\n",
            "Epoch: 5/10, Step: 857/938, Loss: 0.03451254591345787\n",
            "Epoch: 5/10, Step: 858/938, Loss: 0.001001846743747592\n",
            "Epoch: 5/10, Step: 859/938, Loss: 0.0020085417199879885\n",
            "Epoch: 5/10, Step: 860/938, Loss: 0.014281632378697395\n",
            "Epoch: 5/10, Step: 861/938, Loss: 0.022145750001072884\n",
            "Epoch: 5/10, Step: 862/938, Loss: 0.001424526097252965\n",
            "Epoch: 5/10, Step: 863/938, Loss: 0.006948457099497318\n",
            "Epoch: 5/10, Step: 864/938, Loss: 0.0924450233578682\n",
            "Epoch: 5/10, Step: 865/938, Loss: 7.420247129630297e-05\n",
            "Epoch: 5/10, Step: 866/938, Loss: 0.0003236393094994128\n",
            "Epoch: 5/10, Step: 867/938, Loss: 0.009072340093553066\n",
            "Epoch: 5/10, Step: 868/938, Loss: 4.484264718485065e-05\n",
            "Epoch: 5/10, Step: 869/938, Loss: 0.00016252064961008728\n",
            "Epoch: 5/10, Step: 870/938, Loss: 0.00031183980172500014\n",
            "Epoch: 5/10, Step: 871/938, Loss: 0.0002133475209120661\n",
            "Epoch: 5/10, Step: 872/938, Loss: 0.02551281824707985\n",
            "Epoch: 5/10, Step: 873/938, Loss: 0.0005548706976696849\n",
            "Epoch: 5/10, Step: 874/938, Loss: 0.005213113036006689\n",
            "Epoch: 5/10, Step: 875/938, Loss: 0.0007459516637027264\n",
            "Epoch: 5/10, Step: 876/938, Loss: 0.0009306066203862429\n",
            "Epoch: 5/10, Step: 877/938, Loss: 9.668973507359624e-05\n",
            "Epoch: 5/10, Step: 878/938, Loss: 0.0030338005162775517\n",
            "Epoch: 5/10, Step: 879/938, Loss: 0.0002480854745954275\n",
            "Epoch: 5/10, Step: 880/938, Loss: 7.266931788763031e-05\n",
            "Epoch: 5/10, Step: 881/938, Loss: 0.001196047174744308\n",
            "Epoch: 5/10, Step: 882/938, Loss: 0.0006932858377695084\n",
            "Epoch: 5/10, Step: 883/938, Loss: 0.002530989469960332\n",
            "Epoch: 5/10, Step: 884/938, Loss: 0.001745818299241364\n",
            "Epoch: 5/10, Step: 885/938, Loss: 0.0007597022922709584\n",
            "Epoch: 5/10, Step: 886/938, Loss: 0.001435152138583362\n",
            "Epoch: 5/10, Step: 887/938, Loss: 0.001994179328903556\n",
            "Epoch: 5/10, Step: 888/938, Loss: 0.0008338100160472095\n",
            "Epoch: 5/10, Step: 889/938, Loss: 0.0002784828539006412\n",
            "Epoch: 5/10, Step: 890/938, Loss: 0.018259607255458832\n",
            "Epoch: 5/10, Step: 891/938, Loss: 0.005000544246286154\n",
            "Epoch: 5/10, Step: 892/938, Loss: 0.0004931249422952533\n",
            "Epoch: 5/10, Step: 893/938, Loss: 0.001633846084587276\n",
            "Epoch: 5/10, Step: 894/938, Loss: 0.05945613607764244\n",
            "Epoch: 5/10, Step: 895/938, Loss: 0.000218927365494892\n",
            "Epoch: 5/10, Step: 896/938, Loss: 0.020089037716388702\n",
            "Epoch: 5/10, Step: 897/938, Loss: 0.0038647183682769537\n",
            "Epoch: 5/10, Step: 898/938, Loss: 0.0008665502537041903\n",
            "Epoch: 5/10, Step: 899/938, Loss: 0.0012703798711299896\n",
            "Epoch: 5/10, Step: 900/938, Loss: 0.004877363797277212\n",
            "Epoch: 5/10, Step: 901/938, Loss: 0.012350733391940594\n",
            "Epoch: 5/10, Step: 902/938, Loss: 0.0005305472295731306\n",
            "Epoch: 5/10, Step: 903/938, Loss: 0.0016055844025686383\n",
            "Epoch: 5/10, Step: 904/938, Loss: 0.012571231462061405\n",
            "Epoch: 5/10, Step: 905/938, Loss: 0.00015737659123260528\n",
            "Epoch: 5/10, Step: 906/938, Loss: 8.108982001431286e-06\n",
            "Epoch: 5/10, Step: 907/938, Loss: 0.0008181097218766809\n",
            "Epoch: 5/10, Step: 908/938, Loss: 0.003644363023340702\n",
            "Epoch: 5/10, Step: 909/938, Loss: 0.0002378165372647345\n",
            "Epoch: 5/10, Step: 910/938, Loss: 0.0010716755641624331\n",
            "Epoch: 5/10, Step: 911/938, Loss: 0.0006087289657443762\n",
            "Epoch: 5/10, Step: 912/938, Loss: 0.00037910841638222337\n",
            "Epoch: 5/10, Step: 913/938, Loss: 0.01582414098083973\n",
            "Epoch: 5/10, Step: 914/938, Loss: 0.00012716458877548575\n",
            "Epoch: 5/10, Step: 915/938, Loss: 0.0007726927869953215\n",
            "Epoch: 5/10, Step: 916/938, Loss: 0.00620536832138896\n",
            "Epoch: 5/10, Step: 917/938, Loss: 9.867720655165613e-05\n",
            "Epoch: 5/10, Step: 918/938, Loss: 0.0028204445261508226\n",
            "Epoch: 5/10, Step: 919/938, Loss: 0.0009205035748891532\n",
            "Epoch: 5/10, Step: 920/938, Loss: 0.00011069617903558537\n",
            "Epoch: 5/10, Step: 921/938, Loss: 0.0001258144766325131\n",
            "Epoch: 5/10, Step: 922/938, Loss: 1.7763542928150855e-05\n",
            "Epoch: 5/10, Step: 923/938, Loss: 4.655090378946625e-05\n",
            "Epoch: 5/10, Step: 924/938, Loss: 0.0001965329283848405\n",
            "Epoch: 5/10, Step: 925/938, Loss: 0.00029338261811062694\n",
            "Epoch: 5/10, Step: 926/938, Loss: 4.183359123999253e-06\n",
            "Epoch: 5/10, Step: 927/938, Loss: 0.0020440607331693172\n",
            "Epoch: 5/10, Step: 928/938, Loss: 0.00047945367987267673\n",
            "Epoch: 5/10, Step: 929/938, Loss: 0.001752466312609613\n",
            "Epoch: 5/10, Step: 930/938, Loss: 0.001313940854743123\n",
            "Epoch: 5/10, Step: 931/938, Loss: 5.796520781586878e-05\n",
            "Epoch: 5/10, Step: 932/938, Loss: 0.0013799495063722134\n",
            "Epoch: 5/10, Step: 933/938, Loss: 0.00028901780024170876\n",
            "Epoch: 5/10, Step: 934/938, Loss: 0.013072291389107704\n",
            "Epoch: 5/10, Step: 935/938, Loss: 0.011457379907369614\n",
            "Epoch: 5/10, Step: 936/938, Loss: 0.004515395499765873\n",
            "Epoch: 5/10, Step: 937/938, Loss: 0.003715572878718376\n",
            "Epoch: 5/10, Step: 938/938, Loss: 0.00013350041990634054\n",
            "Epoch: 6/10, Step: 1/938, Loss: 0.07680411636829376\n",
            "Epoch: 6/10, Step: 2/938, Loss: 0.003947722725570202\n",
            "Epoch: 6/10, Step: 3/938, Loss: 0.007521131541579962\n",
            "Epoch: 6/10, Step: 4/938, Loss: 0.0038131799083203077\n",
            "Epoch: 6/10, Step: 5/938, Loss: 0.007760546635836363\n",
            "Epoch: 6/10, Step: 6/938, Loss: 0.0003207297995686531\n",
            "Epoch: 6/10, Step: 7/938, Loss: 0.025405459105968475\n",
            "Epoch: 6/10, Step: 8/938, Loss: 0.0004551635356619954\n",
            "Epoch: 6/10, Step: 9/938, Loss: 0.00040203167009167373\n",
            "Epoch: 6/10, Step: 10/938, Loss: 0.00044833164429292083\n",
            "Epoch: 6/10, Step: 11/938, Loss: 0.00042745695100165904\n",
            "Epoch: 6/10, Step: 12/938, Loss: 0.005084509029984474\n",
            "Epoch: 6/10, Step: 13/938, Loss: 0.0035022813826799393\n",
            "Epoch: 6/10, Step: 14/938, Loss: 0.0027995111886411905\n",
            "Epoch: 6/10, Step: 15/938, Loss: 0.0009709119913168252\n",
            "Epoch: 6/10, Step: 16/938, Loss: 0.00030068084015510976\n",
            "Epoch: 6/10, Step: 17/938, Loss: 0.00013867314555682242\n",
            "Epoch: 6/10, Step: 18/938, Loss: 0.0002990674984175712\n",
            "Epoch: 6/10, Step: 19/938, Loss: 0.016486316919326782\n",
            "Epoch: 6/10, Step: 20/938, Loss: 0.001995083410292864\n",
            "Epoch: 6/10, Step: 21/938, Loss: 0.039881810545921326\n",
            "Epoch: 6/10, Step: 22/938, Loss: 0.0006342947599478066\n",
            "Epoch: 6/10, Step: 23/938, Loss: 4.902414002572186e-05\n",
            "Epoch: 6/10, Step: 24/938, Loss: 0.0014003899414092302\n",
            "Epoch: 6/10, Step: 25/938, Loss: 0.00014372743316926062\n",
            "Epoch: 6/10, Step: 26/938, Loss: 0.0003171837015543133\n",
            "Epoch: 6/10, Step: 27/938, Loss: 0.0002772114530671388\n",
            "Epoch: 6/10, Step: 28/938, Loss: 0.00013247040624264628\n",
            "Epoch: 6/10, Step: 29/938, Loss: 0.006023764610290527\n",
            "Epoch: 6/10, Step: 30/938, Loss: 0.0009684616234153509\n",
            "Epoch: 6/10, Step: 31/938, Loss: 0.00025662724510766566\n",
            "Epoch: 6/10, Step: 32/938, Loss: 4.453073051990941e-05\n",
            "Epoch: 6/10, Step: 33/938, Loss: 0.007229719776660204\n",
            "Epoch: 6/10, Step: 34/938, Loss: 0.0038911732845008373\n",
            "Epoch: 6/10, Step: 35/938, Loss: 0.0011670223902910948\n",
            "Epoch: 6/10, Step: 36/938, Loss: 2.561401743150782e-05\n",
            "Epoch: 6/10, Step: 37/938, Loss: 0.00011257114238105714\n",
            "Epoch: 6/10, Step: 38/938, Loss: 0.0004498491180129349\n",
            "Epoch: 6/10, Step: 39/938, Loss: 0.004990857560187578\n",
            "Epoch: 6/10, Step: 40/938, Loss: 0.00011164414172526449\n",
            "Epoch: 6/10, Step: 41/938, Loss: 0.0002979898126795888\n",
            "Epoch: 6/10, Step: 42/938, Loss: 0.0017500619869679213\n",
            "Epoch: 6/10, Step: 43/938, Loss: 0.0005073245847597718\n",
            "Epoch: 6/10, Step: 44/938, Loss: 0.009730277583003044\n",
            "Epoch: 6/10, Step: 45/938, Loss: 0.00010444784129504114\n",
            "Epoch: 6/10, Step: 46/938, Loss: 1.8105292838299647e-05\n",
            "Epoch: 6/10, Step: 47/938, Loss: 0.00048323956434614956\n",
            "Epoch: 6/10, Step: 48/938, Loss: 9.278171637561172e-05\n",
            "Epoch: 6/10, Step: 49/938, Loss: 0.005392064806073904\n",
            "Epoch: 6/10, Step: 50/938, Loss: 0.00011355209426255897\n",
            "Epoch: 6/10, Step: 51/938, Loss: 0.0002539315028116107\n",
            "Epoch: 6/10, Step: 52/938, Loss: 0.0007418459863401949\n",
            "Epoch: 6/10, Step: 53/938, Loss: 0.000585462839808315\n",
            "Epoch: 6/10, Step: 54/938, Loss: 0.0008158690179698169\n",
            "Epoch: 6/10, Step: 55/938, Loss: 0.0008776918984949589\n",
            "Epoch: 6/10, Step: 56/938, Loss: 0.0002783153613563627\n",
            "Epoch: 6/10, Step: 57/938, Loss: 0.0009234031895175576\n",
            "Epoch: 6/10, Step: 58/938, Loss: 0.0001210482296301052\n",
            "Epoch: 6/10, Step: 59/938, Loss: 0.00018013008229900151\n",
            "Epoch: 6/10, Step: 60/938, Loss: 1.4927093616279308e-05\n",
            "Epoch: 6/10, Step: 61/938, Loss: 0.000217940061702393\n",
            "Epoch: 6/10, Step: 62/938, Loss: 0.005630492232739925\n",
            "Epoch: 6/10, Step: 63/938, Loss: 0.00023579517437610775\n",
            "Epoch: 6/10, Step: 64/938, Loss: 0.0007174666388891637\n",
            "Epoch: 6/10, Step: 65/938, Loss: 6.605426460737363e-05\n",
            "Epoch: 6/10, Step: 66/938, Loss: 0.00010885536903515458\n",
            "Epoch: 6/10, Step: 67/938, Loss: 5.2598610636778176e-05\n",
            "Epoch: 6/10, Step: 68/938, Loss: 0.00021204986842349172\n",
            "Epoch: 6/10, Step: 69/938, Loss: 0.00016778273857198656\n",
            "Epoch: 6/10, Step: 70/938, Loss: 0.0002542129950597882\n",
            "Epoch: 6/10, Step: 71/938, Loss: 0.0011676187859848142\n",
            "Epoch: 6/10, Step: 72/938, Loss: 0.00190104974899441\n",
            "Epoch: 6/10, Step: 73/938, Loss: 0.02683098427951336\n",
            "Epoch: 6/10, Step: 74/938, Loss: 0.00039640750037506223\n",
            "Epoch: 6/10, Step: 75/938, Loss: 0.0010093391174450517\n",
            "Epoch: 6/10, Step: 76/938, Loss: 0.0025648032315075397\n",
            "Epoch: 6/10, Step: 77/938, Loss: 0.0020730916876345873\n",
            "Epoch: 6/10, Step: 78/938, Loss: 0.01042501162737608\n",
            "Epoch: 6/10, Step: 79/938, Loss: 0.005003046244382858\n",
            "Epoch: 6/10, Step: 80/938, Loss: 6.123979255789891e-05\n",
            "Epoch: 6/10, Step: 81/938, Loss: 0.0005238734884187579\n",
            "Epoch: 6/10, Step: 82/938, Loss: 0.028124069795012474\n",
            "Epoch: 6/10, Step: 83/938, Loss: 2.1686271793441847e-05\n",
            "Epoch: 6/10, Step: 84/938, Loss: 0.00025443450431339443\n",
            "Epoch: 6/10, Step: 85/938, Loss: 0.001470479415729642\n",
            "Epoch: 6/10, Step: 86/938, Loss: 0.0026113511994481087\n",
            "Epoch: 6/10, Step: 87/938, Loss: 0.00042972908704541624\n",
            "Epoch: 6/10, Step: 88/938, Loss: 9.996382868848741e-05\n",
            "Epoch: 6/10, Step: 89/938, Loss: 7.420110341627151e-05\n",
            "Epoch: 6/10, Step: 90/938, Loss: 0.003656786633655429\n",
            "Epoch: 6/10, Step: 91/938, Loss: 0.0009578308090567589\n",
            "Epoch: 6/10, Step: 92/938, Loss: 0.0017760557821020484\n",
            "Epoch: 6/10, Step: 93/938, Loss: 0.0026517980732023716\n",
            "Epoch: 6/10, Step: 94/938, Loss: 2.9556864319602028e-05\n",
            "Epoch: 6/10, Step: 95/938, Loss: 0.010320993140339851\n",
            "Epoch: 6/10, Step: 96/938, Loss: 9.105505159823224e-05\n",
            "Epoch: 6/10, Step: 97/938, Loss: 0.0028921104967594147\n",
            "Epoch: 6/10, Step: 98/938, Loss: 0.012569175101816654\n",
            "Epoch: 6/10, Step: 99/938, Loss: 0.00023447080457117409\n",
            "Epoch: 6/10, Step: 100/938, Loss: 0.0002702442288864404\n",
            "Epoch: 6/10, Step: 101/938, Loss: 0.00038111014873720706\n",
            "Epoch: 6/10, Step: 102/938, Loss: 2.3059790692059323e-05\n",
            "Epoch: 6/10, Step: 103/938, Loss: 0.0001975510676857084\n",
            "Epoch: 6/10, Step: 104/938, Loss: 8.20561035652645e-05\n",
            "Epoch: 6/10, Step: 105/938, Loss: 0.0007224637665785849\n",
            "Epoch: 6/10, Step: 106/938, Loss: 0.003195332596078515\n",
            "Epoch: 6/10, Step: 107/938, Loss: 0.00014278067101258785\n",
            "Epoch: 6/10, Step: 108/938, Loss: 0.02131998911499977\n",
            "Epoch: 6/10, Step: 109/938, Loss: 0.0021187076345086098\n",
            "Epoch: 6/10, Step: 110/938, Loss: 0.008685246109962463\n",
            "Epoch: 6/10, Step: 111/938, Loss: 0.005412662867456675\n",
            "Epoch: 6/10, Step: 112/938, Loss: 4.9208218115381896e-05\n",
            "Epoch: 6/10, Step: 113/938, Loss: 0.0006050925003364682\n",
            "Epoch: 6/10, Step: 114/938, Loss: 0.0016934707527980208\n",
            "Epoch: 6/10, Step: 115/938, Loss: 0.0002181997406296432\n",
            "Epoch: 6/10, Step: 116/938, Loss: 0.0009026509942486882\n",
            "Epoch: 6/10, Step: 117/938, Loss: 0.00040057572186924517\n",
            "Epoch: 6/10, Step: 118/938, Loss: 0.0022576635237783194\n",
            "Epoch: 6/10, Step: 119/938, Loss: 0.0004909539129585028\n",
            "Epoch: 6/10, Step: 120/938, Loss: 0.01108739897608757\n",
            "Epoch: 6/10, Step: 121/938, Loss: 0.0012009843485429883\n",
            "Epoch: 6/10, Step: 122/938, Loss: 0.00014500506222248077\n",
            "Epoch: 6/10, Step: 123/938, Loss: 0.012477192096412182\n",
            "Epoch: 6/10, Step: 124/938, Loss: 0.00012801098637282848\n",
            "Epoch: 6/10, Step: 125/938, Loss: 0.0016654753126204014\n",
            "Epoch: 6/10, Step: 126/938, Loss: 0.003512956900522113\n",
            "Epoch: 6/10, Step: 127/938, Loss: 1.9125378457829356e-05\n",
            "Epoch: 6/10, Step: 128/938, Loss: 0.02877301722764969\n",
            "Epoch: 6/10, Step: 129/938, Loss: 0.0004907046095468104\n",
            "Epoch: 6/10, Step: 130/938, Loss: 0.00035782274790108204\n",
            "Epoch: 6/10, Step: 131/938, Loss: 6.438616765080951e-06\n",
            "Epoch: 6/10, Step: 132/938, Loss: 0.0005968362675048411\n",
            "Epoch: 6/10, Step: 133/938, Loss: 0.00025402018218301237\n",
            "Epoch: 6/10, Step: 134/938, Loss: 0.00012231913569848984\n",
            "Epoch: 6/10, Step: 135/938, Loss: 0.00043630757136270404\n",
            "Epoch: 6/10, Step: 136/938, Loss: 0.00046423880849033594\n",
            "Epoch: 6/10, Step: 137/938, Loss: 0.001939113950356841\n",
            "Epoch: 6/10, Step: 138/938, Loss: 0.0034301874693483114\n",
            "Epoch: 6/10, Step: 139/938, Loss: 0.00022355624241754413\n",
            "Epoch: 6/10, Step: 140/938, Loss: 0.00038074591429904103\n",
            "Epoch: 6/10, Step: 141/938, Loss: 7.458552136085927e-05\n",
            "Epoch: 6/10, Step: 142/938, Loss: 0.00022027095837984234\n",
            "Epoch: 6/10, Step: 143/938, Loss: 0.005452554207295179\n",
            "Epoch: 6/10, Step: 144/938, Loss: 0.00016978761414065957\n",
            "Epoch: 6/10, Step: 145/938, Loss: 0.03735953941941261\n",
            "Epoch: 6/10, Step: 146/938, Loss: 0.00023235038679558784\n",
            "Epoch: 6/10, Step: 147/938, Loss: 4.0506864024791867e-05\n",
            "Epoch: 6/10, Step: 148/938, Loss: 0.0001603690761839971\n",
            "Epoch: 6/10, Step: 149/938, Loss: 0.0007402088376693428\n",
            "Epoch: 6/10, Step: 150/938, Loss: 1.7507069060229696e-05\n",
            "Epoch: 6/10, Step: 151/938, Loss: 3.420344364712946e-05\n",
            "Epoch: 6/10, Step: 152/938, Loss: 5.6377106375293806e-05\n",
            "Epoch: 6/10, Step: 153/938, Loss: 0.030940264463424683\n",
            "Epoch: 6/10, Step: 154/938, Loss: 9.732499165693298e-05\n",
            "Epoch: 6/10, Step: 155/938, Loss: 0.00018120562890544534\n",
            "Epoch: 6/10, Step: 156/938, Loss: 0.00026252883253619075\n",
            "Epoch: 6/10, Step: 157/938, Loss: 0.000184630072908476\n",
            "Epoch: 6/10, Step: 158/938, Loss: 0.00037597122718580067\n",
            "Epoch: 6/10, Step: 159/938, Loss: 0.0030247175600379705\n",
            "Epoch: 6/10, Step: 160/938, Loss: 0.0009438328561373055\n",
            "Epoch: 6/10, Step: 161/938, Loss: 2.109226079483051e-05\n",
            "Epoch: 6/10, Step: 162/938, Loss: 0.0002933116047643125\n",
            "Epoch: 6/10, Step: 163/938, Loss: 1.6078416592790745e-05\n",
            "Epoch: 6/10, Step: 164/938, Loss: 2.6094855911651393e-06\n",
            "Epoch: 6/10, Step: 165/938, Loss: 0.0001389260432915762\n",
            "Epoch: 6/10, Step: 166/938, Loss: 0.001088206423446536\n",
            "Epoch: 6/10, Step: 167/938, Loss: 1.2926576573590864e-06\n",
            "Epoch: 6/10, Step: 168/938, Loss: 0.00034351652720943093\n",
            "Epoch: 6/10, Step: 169/938, Loss: 0.001292903907597065\n",
            "Epoch: 6/10, Step: 170/938, Loss: 0.00034907867666333914\n",
            "Epoch: 6/10, Step: 171/938, Loss: 0.0007425305084325373\n",
            "Epoch: 6/10, Step: 172/938, Loss: 1.4431214367505163e-05\n",
            "Epoch: 6/10, Step: 173/938, Loss: 0.0005425609415397048\n",
            "Epoch: 6/10, Step: 174/938, Loss: 0.0018635268788784742\n",
            "Epoch: 6/10, Step: 175/938, Loss: 0.0004800794704351574\n",
            "Epoch: 6/10, Step: 176/938, Loss: 0.00453735888004303\n",
            "Epoch: 6/10, Step: 177/938, Loss: 0.002082293154671788\n",
            "Epoch: 6/10, Step: 178/938, Loss: 0.0001564957929076627\n",
            "Epoch: 6/10, Step: 179/938, Loss: 3.126203955616802e-05\n",
            "Epoch: 6/10, Step: 180/938, Loss: 1.5462626834050752e-05\n",
            "Epoch: 6/10, Step: 181/938, Loss: 7.673642539884895e-05\n",
            "Epoch: 6/10, Step: 182/938, Loss: 0.00023997543030418456\n",
            "Epoch: 6/10, Step: 183/938, Loss: 0.0006298894877545536\n",
            "Epoch: 6/10, Step: 184/938, Loss: 0.00014211262168828398\n",
            "Epoch: 6/10, Step: 185/938, Loss: 0.0005972209619358182\n",
            "Epoch: 6/10, Step: 186/938, Loss: 7.748158168396913e-06\n",
            "Epoch: 6/10, Step: 187/938, Loss: 0.000803508679382503\n",
            "Epoch: 6/10, Step: 188/938, Loss: 0.0006821905844844878\n",
            "Epoch: 6/10, Step: 189/938, Loss: 0.0003069874073844403\n",
            "Epoch: 6/10, Step: 190/938, Loss: 0.002248903037980199\n",
            "Epoch: 6/10, Step: 191/938, Loss: 3.5602795833256096e-05\n",
            "Epoch: 6/10, Step: 192/938, Loss: 0.00014777330216020346\n",
            "Epoch: 6/10, Step: 193/938, Loss: 0.0006138705648481846\n",
            "Epoch: 6/10, Step: 194/938, Loss: 5.7106433814624324e-05\n",
            "Epoch: 6/10, Step: 195/938, Loss: 0.01590684987604618\n",
            "Epoch: 6/10, Step: 196/938, Loss: 2.2984729639574653e-06\n",
            "Epoch: 6/10, Step: 197/938, Loss: 0.0027314522303640842\n",
            "Epoch: 6/10, Step: 198/938, Loss: 0.00013573140313383192\n",
            "Epoch: 6/10, Step: 199/938, Loss: 0.0022209722083061934\n",
            "Epoch: 6/10, Step: 200/938, Loss: 4.45937184849754e-05\n",
            "Epoch: 6/10, Step: 201/938, Loss: 5.359471106203273e-05\n",
            "Epoch: 6/10, Step: 202/938, Loss: 0.00021304641268216074\n",
            "Epoch: 6/10, Step: 203/938, Loss: 1.8909864593297243e-05\n",
            "Epoch: 6/10, Step: 204/938, Loss: 0.0012680783402174711\n",
            "Epoch: 6/10, Step: 205/938, Loss: 0.00016131062875501812\n",
            "Epoch: 6/10, Step: 206/938, Loss: 0.00327262538485229\n",
            "Epoch: 6/10, Step: 207/938, Loss: 1.2882664123026188e-05\n",
            "Epoch: 6/10, Step: 208/938, Loss: 0.00010446259693708271\n",
            "Epoch: 6/10, Step: 209/938, Loss: 3.234841278754175e-05\n",
            "Epoch: 6/10, Step: 210/938, Loss: 4.334534241934307e-05\n",
            "Epoch: 6/10, Step: 211/938, Loss: 0.0002537358086556196\n",
            "Epoch: 6/10, Step: 212/938, Loss: 5.267060259939171e-06\n",
            "Epoch: 6/10, Step: 213/938, Loss: 0.004572783596813679\n",
            "Epoch: 6/10, Step: 214/938, Loss: 0.00028084899531677365\n",
            "Epoch: 6/10, Step: 215/938, Loss: 0.00010787957580760121\n",
            "Epoch: 6/10, Step: 216/938, Loss: 0.0009246441186405718\n",
            "Epoch: 6/10, Step: 217/938, Loss: 0.00034215475898236036\n",
            "Epoch: 6/10, Step: 218/938, Loss: 0.0038143442943692207\n",
            "Epoch: 6/10, Step: 219/938, Loss: 0.025826968252658844\n",
            "Epoch: 6/10, Step: 220/938, Loss: 0.0029971529729664326\n",
            "Epoch: 6/10, Step: 221/938, Loss: 0.0004815496504306793\n",
            "Epoch: 6/10, Step: 222/938, Loss: 7.671630737604573e-05\n",
            "Epoch: 6/10, Step: 223/938, Loss: 0.0002914236974902451\n",
            "Epoch: 6/10, Step: 224/938, Loss: 0.0015839729458093643\n",
            "Epoch: 6/10, Step: 225/938, Loss: 0.0026325066573917866\n",
            "Epoch: 6/10, Step: 226/938, Loss: 0.0007231403142213821\n",
            "Epoch: 6/10, Step: 227/938, Loss: 0.0012114651035517454\n",
            "Epoch: 6/10, Step: 228/938, Loss: 0.0017913017654791474\n",
            "Epoch: 6/10, Step: 229/938, Loss: 0.00671595660969615\n",
            "Epoch: 6/10, Step: 230/938, Loss: 0.0002133145899279043\n",
            "Epoch: 6/10, Step: 231/938, Loss: 0.00025388188078068197\n",
            "Epoch: 6/10, Step: 232/938, Loss: 2.6206114398519276e-06\n",
            "Epoch: 6/10, Step: 233/938, Loss: 9.285635314881802e-06\n",
            "Epoch: 6/10, Step: 234/938, Loss: 0.0015214175218716264\n",
            "Epoch: 6/10, Step: 235/938, Loss: 0.00038990325992926955\n",
            "Epoch: 6/10, Step: 236/938, Loss: 5.681455149897374e-05\n",
            "Epoch: 6/10, Step: 237/938, Loss: 3.440226282691583e-05\n",
            "Epoch: 6/10, Step: 238/938, Loss: 4.8626901843817905e-05\n",
            "Epoch: 6/10, Step: 239/938, Loss: 7.384239870589226e-05\n",
            "Epoch: 6/10, Step: 240/938, Loss: 0.00023910622985567898\n",
            "Epoch: 6/10, Step: 241/938, Loss: 0.00016010712715797126\n",
            "Epoch: 6/10, Step: 242/938, Loss: 2.058181053143926e-06\n",
            "Epoch: 6/10, Step: 243/938, Loss: 7.325421393034048e-06\n",
            "Epoch: 6/10, Step: 244/938, Loss: 0.00012228015111759305\n",
            "Epoch: 6/10, Step: 245/938, Loss: 0.0001729136420181021\n",
            "Epoch: 6/10, Step: 246/938, Loss: 0.003032994456589222\n",
            "Epoch: 6/10, Step: 247/938, Loss: 0.0001708894851617515\n",
            "Epoch: 6/10, Step: 248/938, Loss: 0.00016060411871876568\n",
            "Epoch: 6/10, Step: 249/938, Loss: 3.188387199770659e-05\n",
            "Epoch: 6/10, Step: 250/938, Loss: 6.5276376517431345e-06\n",
            "Epoch: 6/10, Step: 251/938, Loss: 0.033552370965480804\n",
            "Epoch: 6/10, Step: 252/938, Loss: 6.454283720813692e-05\n",
            "Epoch: 6/10, Step: 253/938, Loss: 0.00012690557923633605\n",
            "Epoch: 6/10, Step: 254/938, Loss: 0.008291617035865784\n",
            "Epoch: 6/10, Step: 255/938, Loss: 7.555166666861624e-05\n",
            "Epoch: 6/10, Step: 256/938, Loss: 0.00037499985774047673\n",
            "Epoch: 6/10, Step: 257/938, Loss: 0.00029493594774976373\n",
            "Epoch: 6/10, Step: 258/938, Loss: 4.1129038436338305e-05\n",
            "Epoch: 6/10, Step: 259/938, Loss: 0.00020582182332873344\n",
            "Epoch: 6/10, Step: 260/938, Loss: 0.001290510524995625\n",
            "Epoch: 6/10, Step: 261/938, Loss: 0.04928867518901825\n",
            "Epoch: 6/10, Step: 262/938, Loss: 5.591788067249581e-05\n",
            "Epoch: 6/10, Step: 263/938, Loss: 5.099250756757101e-06\n",
            "Epoch: 6/10, Step: 264/938, Loss: 1.6488151231897064e-05\n",
            "Epoch: 6/10, Step: 265/938, Loss: 7.095788168953732e-05\n",
            "Epoch: 6/10, Step: 266/938, Loss: 5.5335412980639376e-06\n",
            "Epoch: 6/10, Step: 267/938, Loss: 9.75000875769183e-06\n",
            "Epoch: 6/10, Step: 268/938, Loss: 0.001201415667310357\n",
            "Epoch: 6/10, Step: 269/938, Loss: 0.0003455589176155627\n",
            "Epoch: 6/10, Step: 270/938, Loss: 0.000882987747900188\n",
            "Epoch: 6/10, Step: 271/938, Loss: 0.0024357677903026342\n",
            "Epoch: 6/10, Step: 272/938, Loss: 0.0008767782710492611\n",
            "Epoch: 6/10, Step: 273/938, Loss: 5.5019759201968554e-06\n",
            "Epoch: 6/10, Step: 274/938, Loss: 0.07615657895803452\n",
            "Epoch: 6/10, Step: 275/938, Loss: 6.150495755719021e-05\n",
            "Epoch: 6/10, Step: 276/938, Loss: 0.0023338431492447853\n",
            "Epoch: 6/10, Step: 277/938, Loss: 4.5666132791666314e-05\n",
            "Epoch: 6/10, Step: 278/938, Loss: 0.0041156732477247715\n",
            "Epoch: 6/10, Step: 279/938, Loss: 0.00012366734154056758\n",
            "Epoch: 6/10, Step: 280/938, Loss: 3.6275494494475424e-05\n",
            "Epoch: 6/10, Step: 281/938, Loss: 0.13434052467346191\n",
            "Epoch: 6/10, Step: 282/938, Loss: 0.0001500263751950115\n",
            "Epoch: 6/10, Step: 283/938, Loss: 0.019904011860489845\n",
            "Epoch: 6/10, Step: 284/938, Loss: 0.0015631908318027854\n",
            "Epoch: 6/10, Step: 285/938, Loss: 0.00027638848405331373\n",
            "Epoch: 6/10, Step: 286/938, Loss: 0.03467368334531784\n",
            "Epoch: 6/10, Step: 287/938, Loss: 0.00560200959444046\n",
            "Epoch: 6/10, Step: 288/938, Loss: 0.00038771904655732214\n",
            "Epoch: 6/10, Step: 289/938, Loss: 0.00028041022596880794\n",
            "Epoch: 6/10, Step: 290/938, Loss: 0.00010000109614338726\n",
            "Epoch: 6/10, Step: 291/938, Loss: 0.00048743587103672326\n",
            "Epoch: 6/10, Step: 292/938, Loss: 8.928166062105447e-05\n",
            "Epoch: 6/10, Step: 293/938, Loss: 2.4581822799518704e-05\n",
            "Epoch: 6/10, Step: 294/938, Loss: 0.00017027367721311748\n",
            "Epoch: 6/10, Step: 295/938, Loss: 4.017472383566201e-05\n",
            "Epoch: 6/10, Step: 296/938, Loss: 0.0001592546032043174\n",
            "Epoch: 6/10, Step: 297/938, Loss: 0.0032503344118595123\n",
            "Epoch: 6/10, Step: 298/938, Loss: 0.0030028303153812885\n",
            "Epoch: 6/10, Step: 299/938, Loss: 0.014755161479115486\n",
            "Epoch: 6/10, Step: 300/938, Loss: 0.00026096912915818393\n",
            "Epoch: 6/10, Step: 301/938, Loss: 0.00050455576274544\n",
            "Epoch: 6/10, Step: 302/938, Loss: 0.017561616376042366\n",
            "Epoch: 6/10, Step: 303/938, Loss: 7.748289499431849e-05\n",
            "Epoch: 6/10, Step: 304/938, Loss: 0.0021010348573327065\n",
            "Epoch: 6/10, Step: 305/938, Loss: 0.010977798141539097\n",
            "Epoch: 6/10, Step: 306/938, Loss: 0.00045557343401014805\n",
            "Epoch: 6/10, Step: 307/938, Loss: 0.00017762949573807418\n",
            "Epoch: 6/10, Step: 308/938, Loss: 0.0062184203416109085\n",
            "Epoch: 6/10, Step: 309/938, Loss: 0.003764207474887371\n",
            "Epoch: 6/10, Step: 310/938, Loss: 0.010094265453517437\n",
            "Epoch: 6/10, Step: 311/938, Loss: 0.01004876010119915\n",
            "Epoch: 6/10, Step: 312/938, Loss: 4.9480404413770884e-05\n",
            "Epoch: 6/10, Step: 313/938, Loss: 0.014149226248264313\n",
            "Epoch: 6/10, Step: 314/938, Loss: 0.004573900252580643\n",
            "Epoch: 6/10, Step: 315/938, Loss: 0.0005022436380386353\n",
            "Epoch: 6/10, Step: 316/938, Loss: 0.0002130486536771059\n",
            "Epoch: 6/10, Step: 317/938, Loss: 0.0011543348664417863\n",
            "Epoch: 6/10, Step: 318/938, Loss: 5.464474725158652e-06\n",
            "Epoch: 6/10, Step: 319/938, Loss: 0.0037771465722471476\n",
            "Epoch: 6/10, Step: 320/938, Loss: 0.000425200501922518\n",
            "Epoch: 6/10, Step: 321/938, Loss: 0.0016663020942360163\n",
            "Epoch: 6/10, Step: 322/938, Loss: 0.002062437357380986\n",
            "Epoch: 6/10, Step: 323/938, Loss: 0.00826657097786665\n",
            "Epoch: 6/10, Step: 324/938, Loss: 0.0012657016050070524\n",
            "Epoch: 6/10, Step: 325/938, Loss: 4.4155192881589755e-05\n",
            "Epoch: 6/10, Step: 326/938, Loss: 4.605187859851867e-05\n",
            "Epoch: 6/10, Step: 327/938, Loss: 0.00012742391845677048\n",
            "Epoch: 6/10, Step: 328/938, Loss: 0.00889541395008564\n",
            "Epoch: 6/10, Step: 329/938, Loss: 0.0005526666063815355\n",
            "Epoch: 6/10, Step: 330/938, Loss: 0.00025222726981155574\n",
            "Epoch: 6/10, Step: 331/938, Loss: 0.0002302280772710219\n",
            "Epoch: 6/10, Step: 332/938, Loss: 0.02731444500386715\n",
            "Epoch: 6/10, Step: 333/938, Loss: 0.0002231477410532534\n",
            "Epoch: 6/10, Step: 334/938, Loss: 0.00010586412099655718\n",
            "Epoch: 6/10, Step: 335/938, Loss: 0.07352864742279053\n",
            "Epoch: 6/10, Step: 336/938, Loss: 0.007715947460383177\n",
            "Epoch: 6/10, Step: 337/938, Loss: 0.0004574792110361159\n",
            "Epoch: 6/10, Step: 338/938, Loss: 0.0006359692197293043\n",
            "Epoch: 6/10, Step: 339/938, Loss: 0.0006242405506782234\n",
            "Epoch: 6/10, Step: 340/938, Loss: 4.014909063698724e-05\n",
            "Epoch: 6/10, Step: 341/938, Loss: 0.010437769815325737\n",
            "Epoch: 6/10, Step: 342/938, Loss: 0.006114358082413673\n",
            "Epoch: 6/10, Step: 343/938, Loss: 0.08346546441316605\n",
            "Epoch: 6/10, Step: 344/938, Loss: 0.0011849045986309648\n",
            "Epoch: 6/10, Step: 345/938, Loss: 0.030934561043977737\n",
            "Epoch: 6/10, Step: 346/938, Loss: 0.0034577103797346354\n",
            "Epoch: 6/10, Step: 347/938, Loss: 0.0003252892638556659\n",
            "Epoch: 6/10, Step: 348/938, Loss: 0.0024982804898172617\n",
            "Epoch: 6/10, Step: 349/938, Loss: 0.0002812735619954765\n",
            "Epoch: 6/10, Step: 350/938, Loss: 0.0014620721340179443\n",
            "Epoch: 6/10, Step: 351/938, Loss: 0.03263048455119133\n",
            "Epoch: 6/10, Step: 352/938, Loss: 0.002108081243932247\n",
            "Epoch: 6/10, Step: 353/938, Loss: 0.0009977705776691437\n",
            "Epoch: 6/10, Step: 354/938, Loss: 0.00013707859034184366\n",
            "Epoch: 6/10, Step: 355/938, Loss: 0.00035632678191177547\n",
            "Epoch: 6/10, Step: 356/938, Loss: 0.002421546960249543\n",
            "Epoch: 6/10, Step: 357/938, Loss: 0.0013725843746215105\n",
            "Epoch: 6/10, Step: 358/938, Loss: 0.007747625932097435\n",
            "Epoch: 6/10, Step: 359/938, Loss: 0.02484465017914772\n",
            "Epoch: 6/10, Step: 360/938, Loss: 0.004955782555043697\n",
            "Epoch: 6/10, Step: 361/938, Loss: 9.429424244444817e-05\n",
            "Epoch: 6/10, Step: 362/938, Loss: 0.0009986553341150284\n",
            "Epoch: 6/10, Step: 363/938, Loss: 0.0021803085692226887\n",
            "Epoch: 6/10, Step: 364/938, Loss: 9.005191532196477e-05\n",
            "Epoch: 6/10, Step: 365/938, Loss: 0.01573490910232067\n",
            "Epoch: 6/10, Step: 366/938, Loss: 7.521937368437648e-05\n",
            "Epoch: 6/10, Step: 367/938, Loss: 0.00013063199003227055\n",
            "Epoch: 6/10, Step: 368/938, Loss: 4.447626633918844e-05\n",
            "Epoch: 6/10, Step: 369/938, Loss: 0.004265249706804752\n",
            "Epoch: 6/10, Step: 370/938, Loss: 0.001419816049747169\n",
            "Epoch: 6/10, Step: 371/938, Loss: 0.006613219156861305\n",
            "Epoch: 6/10, Step: 372/938, Loss: 0.0021665063686668873\n",
            "Epoch: 6/10, Step: 373/938, Loss: 0.005803513340651989\n",
            "Epoch: 6/10, Step: 374/938, Loss: 0.020291507244110107\n",
            "Epoch: 6/10, Step: 375/938, Loss: 0.0005803913809359074\n",
            "Epoch: 6/10, Step: 376/938, Loss: 0.0016176506178453565\n",
            "Epoch: 6/10, Step: 377/938, Loss: 0.00041037704795598984\n",
            "Epoch: 6/10, Step: 378/938, Loss: 0.0001592549670021981\n",
            "Epoch: 6/10, Step: 379/938, Loss: 0.030088642612099648\n",
            "Epoch: 6/10, Step: 380/938, Loss: 2.0260911696823314e-05\n",
            "Epoch: 6/10, Step: 381/938, Loss: 1.0752072739705909e-05\n",
            "Epoch: 6/10, Step: 382/938, Loss: 0.0002539794077165425\n",
            "Epoch: 6/10, Step: 383/938, Loss: 0.0005415997002273798\n",
            "Epoch: 6/10, Step: 384/938, Loss: 0.0002631670795381069\n",
            "Epoch: 6/10, Step: 385/938, Loss: 0.0009869792265817523\n",
            "Epoch: 6/10, Step: 386/938, Loss: 0.0004932604497298598\n",
            "Epoch: 6/10, Step: 387/938, Loss: 0.14894583821296692\n",
            "Epoch: 6/10, Step: 388/938, Loss: 0.0011852551251649857\n",
            "Epoch: 6/10, Step: 389/938, Loss: 0.005786179099231958\n",
            "Epoch: 6/10, Step: 390/938, Loss: 0.011659003794193268\n",
            "Epoch: 6/10, Step: 391/938, Loss: 4.2494648369029164e-05\n",
            "Epoch: 6/10, Step: 392/938, Loss: 0.00030460202833637595\n",
            "Epoch: 6/10, Step: 393/938, Loss: 0.0012801957782357931\n",
            "Epoch: 6/10, Step: 394/938, Loss: 0.00018307293066754937\n",
            "Epoch: 6/10, Step: 395/938, Loss: 0.0015737327048555017\n",
            "Epoch: 6/10, Step: 396/938, Loss: 0.03612367808818817\n",
            "Epoch: 6/10, Step: 397/938, Loss: 0.022535473108291626\n",
            "Epoch: 6/10, Step: 398/938, Loss: 0.014927045442163944\n",
            "Epoch: 6/10, Step: 399/938, Loss: 0.01427998673170805\n",
            "Epoch: 6/10, Step: 400/938, Loss: 0.0005624678451567888\n",
            "Epoch: 6/10, Step: 401/938, Loss: 0.0008308829856105149\n",
            "Epoch: 6/10, Step: 402/938, Loss: 0.0035281232558190823\n",
            "Epoch: 6/10, Step: 403/938, Loss: 6.143932841951028e-05\n",
            "Epoch: 6/10, Step: 404/938, Loss: 0.04009808599948883\n",
            "Epoch: 6/10, Step: 405/938, Loss: 0.013530476950109005\n",
            "Epoch: 6/10, Step: 406/938, Loss: 0.0007387395016849041\n",
            "Epoch: 6/10, Step: 407/938, Loss: 0.00010854518041014671\n",
            "Epoch: 6/10, Step: 408/938, Loss: 0.0008072963100858033\n",
            "Epoch: 6/10, Step: 409/938, Loss: 0.00011764286318793893\n",
            "Epoch: 6/10, Step: 410/938, Loss: 0.009571557864546776\n",
            "Epoch: 6/10, Step: 411/938, Loss: 0.0016230891924351454\n",
            "Epoch: 6/10, Step: 412/938, Loss: 0.03171251341700554\n",
            "Epoch: 6/10, Step: 413/938, Loss: 0.0003088071825914085\n",
            "Epoch: 6/10, Step: 414/938, Loss: 0.00016680073167663068\n",
            "Epoch: 6/10, Step: 415/938, Loss: 0.0009292135364376009\n",
            "Epoch: 6/10, Step: 416/938, Loss: 0.0049674976617097855\n",
            "Epoch: 6/10, Step: 417/938, Loss: 0.0018467538757249713\n",
            "Epoch: 6/10, Step: 418/938, Loss: 0.0025862755719572306\n",
            "Epoch: 6/10, Step: 419/938, Loss: 0.003215498523786664\n",
            "Epoch: 6/10, Step: 420/938, Loss: 0.00017131163622252643\n",
            "Epoch: 6/10, Step: 421/938, Loss: 0.001440116437152028\n",
            "Epoch: 6/10, Step: 422/938, Loss: 0.011306755244731903\n",
            "Epoch: 6/10, Step: 423/938, Loss: 0.000114071459393017\n",
            "Epoch: 6/10, Step: 424/938, Loss: 0.04925015941262245\n",
            "Epoch: 6/10, Step: 425/938, Loss: 0.010457656346261501\n",
            "Epoch: 6/10, Step: 426/938, Loss: 0.016310900449752808\n",
            "Epoch: 6/10, Step: 427/938, Loss: 0.00026908412110060453\n",
            "Epoch: 6/10, Step: 428/938, Loss: 0.00528376130387187\n",
            "Epoch: 6/10, Step: 429/938, Loss: 0.0006302306428551674\n",
            "Epoch: 6/10, Step: 430/938, Loss: 0.0004436688614077866\n",
            "Epoch: 6/10, Step: 431/938, Loss: 0.0005493615753948689\n",
            "Epoch: 6/10, Step: 432/938, Loss: 0.022612493485212326\n",
            "Epoch: 6/10, Step: 433/938, Loss: 8.337535109603778e-05\n",
            "Epoch: 6/10, Step: 434/938, Loss: 0.0026914337649941444\n",
            "Epoch: 6/10, Step: 435/938, Loss: 0.003964301198720932\n",
            "Epoch: 6/10, Step: 436/938, Loss: 0.07153097540140152\n",
            "Epoch: 6/10, Step: 437/938, Loss: 0.0007244098815135658\n",
            "Epoch: 6/10, Step: 438/938, Loss: 0.1213928610086441\n",
            "Epoch: 6/10, Step: 439/938, Loss: 0.008202051743865013\n",
            "Epoch: 6/10, Step: 440/938, Loss: 0.00406377948820591\n",
            "Epoch: 6/10, Step: 441/938, Loss: 0.004449685104191303\n",
            "Epoch: 6/10, Step: 442/938, Loss: 0.00041624033474363387\n",
            "Epoch: 6/10, Step: 443/938, Loss: 0.006195623427629471\n",
            "Epoch: 6/10, Step: 444/938, Loss: 0.000768727739341557\n",
            "Epoch: 6/10, Step: 445/938, Loss: 0.00025423115584999323\n",
            "Epoch: 6/10, Step: 446/938, Loss: 0.048788003623485565\n",
            "Epoch: 6/10, Step: 447/938, Loss: 0.00020202284213155508\n",
            "Epoch: 6/10, Step: 448/938, Loss: 0.0726456269621849\n",
            "Epoch: 6/10, Step: 449/938, Loss: 0.041789498180150986\n",
            "Epoch: 6/10, Step: 450/938, Loss: 0.00017636592383496463\n",
            "Epoch: 6/10, Step: 451/938, Loss: 0.0020447042770683765\n",
            "Epoch: 6/10, Step: 452/938, Loss: 0.04532289132475853\n",
            "Epoch: 6/10, Step: 453/938, Loss: 0.0019820246379822493\n",
            "Epoch: 6/10, Step: 454/938, Loss: 0.0013650248292833567\n",
            "Epoch: 6/10, Step: 455/938, Loss: 1.3095876056468114e-05\n",
            "Epoch: 6/10, Step: 456/938, Loss: 0.018272755667567253\n",
            "Epoch: 6/10, Step: 457/938, Loss: 0.004888512194156647\n",
            "Epoch: 6/10, Step: 458/938, Loss: 9.07268185983412e-05\n",
            "Epoch: 6/10, Step: 459/938, Loss: 0.001525734318420291\n",
            "Epoch: 6/10, Step: 460/938, Loss: 0.00032724926131777465\n",
            "Epoch: 6/10, Step: 461/938, Loss: 0.0012547700898721814\n",
            "Epoch: 6/10, Step: 462/938, Loss: 0.0035695629194378853\n",
            "Epoch: 6/10, Step: 463/938, Loss: 0.0009619244374334812\n",
            "Epoch: 6/10, Step: 464/938, Loss: 0.00039115766412578523\n",
            "Epoch: 6/10, Step: 465/938, Loss: 0.0015104024205356836\n",
            "Epoch: 6/10, Step: 466/938, Loss: 1.5350646208389662e-05\n",
            "Epoch: 6/10, Step: 467/938, Loss: 0.02956496551632881\n",
            "Epoch: 6/10, Step: 468/938, Loss: 0.009587026201188564\n",
            "Epoch: 6/10, Step: 469/938, Loss: 0.00027124403277412057\n",
            "Epoch: 6/10, Step: 470/938, Loss: 0.0017861002124845982\n",
            "Epoch: 6/10, Step: 471/938, Loss: 0.026882067322731018\n",
            "Epoch: 6/10, Step: 472/938, Loss: 0.0006139776087366045\n",
            "Epoch: 6/10, Step: 473/938, Loss: 0.00015028603957034647\n",
            "Epoch: 6/10, Step: 474/938, Loss: 0.008310392498970032\n",
            "Epoch: 6/10, Step: 475/938, Loss: 0.04351408779621124\n",
            "Epoch: 6/10, Step: 476/938, Loss: 0.0014193970710039139\n",
            "Epoch: 6/10, Step: 477/938, Loss: 0.03524349257349968\n",
            "Epoch: 6/10, Step: 478/938, Loss: 0.06959564238786697\n",
            "Epoch: 6/10, Step: 479/938, Loss: 0.0456010140478611\n",
            "Epoch: 6/10, Step: 480/938, Loss: 1.5493604223593138e-05\n",
            "Epoch: 6/10, Step: 481/938, Loss: 0.039182163774967194\n",
            "Epoch: 6/10, Step: 482/938, Loss: 1.63805962074548e-05\n",
            "Epoch: 6/10, Step: 483/938, Loss: 0.003122416092082858\n",
            "Epoch: 6/10, Step: 484/938, Loss: 0.0005969018093310297\n",
            "Epoch: 6/10, Step: 485/938, Loss: 0.004666778724640608\n",
            "Epoch: 6/10, Step: 486/938, Loss: 0.00013900648627895862\n",
            "Epoch: 6/10, Step: 487/938, Loss: 0.003718902822583914\n",
            "Epoch: 6/10, Step: 488/938, Loss: 0.02480928599834442\n",
            "Epoch: 6/10, Step: 489/938, Loss: 0.0005667440127581358\n",
            "Epoch: 6/10, Step: 490/938, Loss: 0.017039502039551735\n",
            "Epoch: 6/10, Step: 491/938, Loss: 0.00015453774540219456\n",
            "Epoch: 6/10, Step: 492/938, Loss: 0.011383469216525555\n",
            "Epoch: 6/10, Step: 493/938, Loss: 0.004423530772328377\n",
            "Epoch: 6/10, Step: 494/938, Loss: 2.0423616660991684e-05\n",
            "Epoch: 6/10, Step: 495/938, Loss: 0.005930402781814337\n",
            "Epoch: 6/10, Step: 496/938, Loss: 0.000462112482637167\n",
            "Epoch: 6/10, Step: 497/938, Loss: 0.004935926292091608\n",
            "Epoch: 6/10, Step: 498/938, Loss: 0.17805223166942596\n",
            "Epoch: 6/10, Step: 499/938, Loss: 0.0006078603328205645\n",
            "Epoch: 6/10, Step: 500/938, Loss: 9.805735317058861e-06\n",
            "Epoch: 6/10, Step: 501/938, Loss: 0.00011199278378626332\n",
            "Epoch: 6/10, Step: 502/938, Loss: 0.013394623063504696\n",
            "Epoch: 6/10, Step: 503/938, Loss: 0.0046687135472893715\n",
            "Epoch: 6/10, Step: 504/938, Loss: 0.00023686615168116987\n",
            "Epoch: 6/10, Step: 505/938, Loss: 0.014066802337765694\n",
            "Epoch: 6/10, Step: 506/938, Loss: 1.2160690857854206e-05\n",
            "Epoch: 6/10, Step: 507/938, Loss: 0.005545164458453655\n",
            "Epoch: 6/10, Step: 508/938, Loss: 4.283787711756304e-05\n",
            "Epoch: 6/10, Step: 509/938, Loss: 6.1002287111477926e-05\n",
            "Epoch: 6/10, Step: 510/938, Loss: 0.0001895370805868879\n",
            "Epoch: 6/10, Step: 511/938, Loss: 3.089995516347699e-05\n",
            "Epoch: 6/10, Step: 512/938, Loss: 0.0022859948221594095\n",
            "Epoch: 6/10, Step: 513/938, Loss: 0.00011215070844627917\n",
            "Epoch: 6/10, Step: 514/938, Loss: 0.07744380086660385\n",
            "Epoch: 6/10, Step: 515/938, Loss: 0.0007502998923882842\n",
            "Epoch: 6/10, Step: 516/938, Loss: 0.003704342059791088\n",
            "Epoch: 6/10, Step: 517/938, Loss: 0.0002947679895441979\n",
            "Epoch: 6/10, Step: 518/938, Loss: 0.023257765918970108\n",
            "Epoch: 6/10, Step: 519/938, Loss: 0.003777449717745185\n",
            "Epoch: 6/10, Step: 520/938, Loss: 7.907993858680129e-05\n",
            "Epoch: 6/10, Step: 521/938, Loss: 0.00021582678891718388\n",
            "Epoch: 6/10, Step: 522/938, Loss: 0.00029806935344822705\n",
            "Epoch: 6/10, Step: 523/938, Loss: 0.009004008024930954\n",
            "Epoch: 6/10, Step: 524/938, Loss: 0.00029263831675052643\n",
            "Epoch: 6/10, Step: 525/938, Loss: 0.13772130012512207\n",
            "Epoch: 6/10, Step: 526/938, Loss: 0.0010499459458515048\n",
            "Epoch: 6/10, Step: 527/938, Loss: 0.00016484320804011077\n",
            "Epoch: 6/10, Step: 528/938, Loss: 0.0013297627447173\n",
            "Epoch: 6/10, Step: 529/938, Loss: 3.051078056159895e-05\n",
            "Epoch: 6/10, Step: 530/938, Loss: 0.002167584141716361\n",
            "Epoch: 6/10, Step: 531/938, Loss: 0.001170129282400012\n",
            "Epoch: 6/10, Step: 532/938, Loss: 0.004904104862362146\n",
            "Epoch: 6/10, Step: 533/938, Loss: 0.00021475221728906035\n",
            "Epoch: 6/10, Step: 534/938, Loss: 0.0015288362046703696\n",
            "Epoch: 6/10, Step: 535/938, Loss: 0.0001596993242856115\n",
            "Epoch: 6/10, Step: 536/938, Loss: 0.00012696879275608808\n",
            "Epoch: 6/10, Step: 537/938, Loss: 0.019685545936226845\n",
            "Epoch: 6/10, Step: 538/938, Loss: 2.8270154871279374e-05\n",
            "Epoch: 6/10, Step: 539/938, Loss: 0.011070146225392818\n",
            "Epoch: 6/10, Step: 540/938, Loss: 0.005748865194618702\n",
            "Epoch: 6/10, Step: 541/938, Loss: 0.00143502838909626\n",
            "Epoch: 6/10, Step: 542/938, Loss: 0.005570832174271345\n",
            "Epoch: 6/10, Step: 543/938, Loss: 0.01778574287891388\n",
            "Epoch: 6/10, Step: 544/938, Loss: 3.061617098865099e-05\n",
            "Epoch: 6/10, Step: 545/938, Loss: 0.0017589256167411804\n",
            "Epoch: 6/10, Step: 546/938, Loss: 0.00020076855435036123\n",
            "Epoch: 6/10, Step: 547/938, Loss: 0.0008840438676998019\n",
            "Epoch: 6/10, Step: 548/938, Loss: 0.0002337666810490191\n",
            "Epoch: 6/10, Step: 549/938, Loss: 0.00019353802781552076\n",
            "Epoch: 6/10, Step: 550/938, Loss: 0.00037816260010004044\n",
            "Epoch: 6/10, Step: 551/938, Loss: 0.0017289376119151711\n",
            "Epoch: 6/10, Step: 552/938, Loss: 0.006470206659287214\n",
            "Epoch: 6/10, Step: 553/938, Loss: 0.0006963653722777963\n",
            "Epoch: 6/10, Step: 554/938, Loss: 0.00027353339828550816\n",
            "Epoch: 6/10, Step: 555/938, Loss: 5.5529133533127606e-05\n",
            "Epoch: 6/10, Step: 556/938, Loss: 0.0002780098875518888\n",
            "Epoch: 6/10, Step: 557/938, Loss: 0.000966802064795047\n",
            "Epoch: 6/10, Step: 558/938, Loss: 0.06216847524046898\n",
            "Epoch: 6/10, Step: 559/938, Loss: 0.0007786591304466128\n",
            "Epoch: 6/10, Step: 560/938, Loss: 0.0007754062535241246\n",
            "Epoch: 6/10, Step: 561/938, Loss: 0.00016847497317939997\n",
            "Epoch: 6/10, Step: 562/938, Loss: 0.0009149286197498441\n",
            "Epoch: 6/10, Step: 563/938, Loss: 0.001087071723304689\n",
            "Epoch: 6/10, Step: 564/938, Loss: 0.0015043916646391153\n",
            "Epoch: 6/10, Step: 565/938, Loss: 0.0010378743754699826\n",
            "Epoch: 6/10, Step: 566/938, Loss: 4.346095374785364e-05\n",
            "Epoch: 6/10, Step: 567/938, Loss: 0.00015717810310889035\n",
            "Epoch: 6/10, Step: 568/938, Loss: 0.00028846904751844704\n",
            "Epoch: 6/10, Step: 569/938, Loss: 0.001482736668549478\n",
            "Epoch: 6/10, Step: 570/938, Loss: 0.009897026233375072\n",
            "Epoch: 6/10, Step: 571/938, Loss: 0.0029539407696574926\n",
            "Epoch: 6/10, Step: 572/938, Loss: 0.0002904367574956268\n",
            "Epoch: 6/10, Step: 573/938, Loss: 0.008359025232493877\n",
            "Epoch: 6/10, Step: 574/938, Loss: 0.0002019809471676126\n",
            "Epoch: 6/10, Step: 575/938, Loss: 0.007726677693426609\n",
            "Epoch: 6/10, Step: 576/938, Loss: 0.00018736674974206835\n",
            "Epoch: 6/10, Step: 577/938, Loss: 0.0007572931936010718\n",
            "Epoch: 6/10, Step: 578/938, Loss: 0.0010546144330874085\n",
            "Epoch: 6/10, Step: 579/938, Loss: 0.000260402710409835\n",
            "Epoch: 6/10, Step: 580/938, Loss: 0.0002953045768663287\n",
            "Epoch: 6/10, Step: 581/938, Loss: 0.05453044921159744\n",
            "Epoch: 6/10, Step: 582/938, Loss: 0.0002123889426002279\n",
            "Epoch: 6/10, Step: 583/938, Loss: 0.002711367793381214\n",
            "Epoch: 6/10, Step: 584/938, Loss: 0.013702861033380032\n",
            "Epoch: 6/10, Step: 585/938, Loss: 0.0003945211065001786\n",
            "Epoch: 6/10, Step: 586/938, Loss: 0.0019399712327867746\n",
            "Epoch: 6/10, Step: 587/938, Loss: 0.0009689806029200554\n",
            "Epoch: 6/10, Step: 588/938, Loss: 0.0005313456058502197\n",
            "Epoch: 6/10, Step: 589/938, Loss: 0.00010285111784469336\n",
            "Epoch: 6/10, Step: 590/938, Loss: 6.633756129303947e-05\n",
            "Epoch: 6/10, Step: 591/938, Loss: 0.0112806037068367\n",
            "Epoch: 6/10, Step: 592/938, Loss: 0.002556659746915102\n",
            "Epoch: 6/10, Step: 593/938, Loss: 0.0015643032966181636\n",
            "Epoch: 6/10, Step: 594/938, Loss: 8.765176062297542e-06\n",
            "Epoch: 6/10, Step: 595/938, Loss: 6.086853318265639e-06\n",
            "Epoch: 6/10, Step: 596/938, Loss: 7.384607306448743e-05\n",
            "Epoch: 6/10, Step: 597/938, Loss: 5.285363658913411e-05\n",
            "Epoch: 6/10, Step: 598/938, Loss: 0.002934862859547138\n",
            "Epoch: 6/10, Step: 599/938, Loss: 0.004330979660153389\n",
            "Epoch: 6/10, Step: 600/938, Loss: 0.0011435989290475845\n",
            "Epoch: 6/10, Step: 601/938, Loss: 0.00012732674076687545\n",
            "Epoch: 6/10, Step: 602/938, Loss: 0.0021637137979269028\n",
            "Epoch: 6/10, Step: 603/938, Loss: 7.027735409792513e-05\n",
            "Epoch: 6/10, Step: 604/938, Loss: 0.03770722821354866\n",
            "Epoch: 6/10, Step: 605/938, Loss: 0.0011814204044640064\n",
            "Epoch: 6/10, Step: 606/938, Loss: 2.261222653032746e-05\n",
            "Epoch: 6/10, Step: 607/938, Loss: 0.0006922514294274151\n",
            "Epoch: 6/10, Step: 608/938, Loss: 0.02035501040518284\n",
            "Epoch: 6/10, Step: 609/938, Loss: 0.0008733446011319757\n",
            "Epoch: 6/10, Step: 610/938, Loss: 0.053381744772195816\n",
            "Epoch: 6/10, Step: 611/938, Loss: 0.00031296603265218437\n",
            "Epoch: 6/10, Step: 612/938, Loss: 0.019906049594283104\n",
            "Epoch: 6/10, Step: 613/938, Loss: 0.0002880372921936214\n",
            "Epoch: 6/10, Step: 614/938, Loss: 0.00026449907454662025\n",
            "Epoch: 6/10, Step: 615/938, Loss: 0.043840017169713974\n",
            "Epoch: 6/10, Step: 616/938, Loss: 0.002212880877777934\n",
            "Epoch: 6/10, Step: 617/938, Loss: 0.0008281725458800793\n",
            "Epoch: 6/10, Step: 618/938, Loss: 0.00019125480321235955\n",
            "Epoch: 6/10, Step: 619/938, Loss: 1.7143547665909864e-05\n",
            "Epoch: 6/10, Step: 620/938, Loss: 0.042717885226011276\n",
            "Epoch: 6/10, Step: 621/938, Loss: 0.005098479334264994\n",
            "Epoch: 6/10, Step: 622/938, Loss: 0.002558621112257242\n",
            "Epoch: 6/10, Step: 623/938, Loss: 0.012708038091659546\n",
            "Epoch: 6/10, Step: 624/938, Loss: 0.0006166039383970201\n",
            "Epoch: 6/10, Step: 625/938, Loss: 0.023029819130897522\n",
            "Epoch: 6/10, Step: 626/938, Loss: 0.0002296395250596106\n",
            "Epoch: 6/10, Step: 627/938, Loss: 0.0001231048663612455\n",
            "Epoch: 6/10, Step: 628/938, Loss: 0.0011216953862458467\n",
            "Epoch: 6/10, Step: 629/938, Loss: 9.70074615906924e-05\n",
            "Epoch: 6/10, Step: 630/938, Loss: 0.023898014798760414\n",
            "Epoch: 6/10, Step: 631/938, Loss: 0.0002385012194281444\n",
            "Epoch: 6/10, Step: 632/938, Loss: 0.0003657321212813258\n",
            "Epoch: 6/10, Step: 633/938, Loss: 0.00025272919447161257\n",
            "Epoch: 6/10, Step: 634/938, Loss: 0.000597599777393043\n",
            "Epoch: 6/10, Step: 635/938, Loss: 0.00016903555660974234\n",
            "Epoch: 6/10, Step: 636/938, Loss: 0.0005918158567510545\n",
            "Epoch: 6/10, Step: 637/938, Loss: 1.8135748177883215e-05\n",
            "Epoch: 6/10, Step: 638/938, Loss: 0.00022872036788612604\n",
            "Epoch: 6/10, Step: 639/938, Loss: 9.770895303518046e-06\n",
            "Epoch: 6/10, Step: 640/938, Loss: 0.015163061209022999\n",
            "Epoch: 6/10, Step: 641/938, Loss: 0.0006060331361368299\n",
            "Epoch: 6/10, Step: 642/938, Loss: 0.00024623883655294776\n",
            "Epoch: 6/10, Step: 643/938, Loss: 0.005138732492923737\n",
            "Epoch: 6/10, Step: 644/938, Loss: 0.00016475222946610302\n",
            "Epoch: 6/10, Step: 645/938, Loss: 0.0008145082974806428\n",
            "Epoch: 6/10, Step: 646/938, Loss: 0.0026260872837156057\n",
            "Epoch: 6/10, Step: 647/938, Loss: 0.025681648403406143\n",
            "Epoch: 6/10, Step: 648/938, Loss: 0.0011183777824044228\n",
            "Epoch: 6/10, Step: 649/938, Loss: 0.003650390077382326\n",
            "Epoch: 6/10, Step: 650/938, Loss: 0.00021682905207853764\n",
            "Epoch: 6/10, Step: 651/938, Loss: 0.04430804401636124\n",
            "Epoch: 6/10, Step: 652/938, Loss: 2.5757990442798473e-05\n",
            "Epoch: 6/10, Step: 653/938, Loss: 0.0007755756960250437\n",
            "Epoch: 6/10, Step: 654/938, Loss: 3.718630614457652e-05\n",
            "Epoch: 6/10, Step: 655/938, Loss: 0.06578805297613144\n",
            "Epoch: 6/10, Step: 656/938, Loss: 0.016220329329371452\n",
            "Epoch: 6/10, Step: 657/938, Loss: 0.02025298774242401\n",
            "Epoch: 6/10, Step: 658/938, Loss: 8.585560135543346e-05\n",
            "Epoch: 6/10, Step: 659/938, Loss: 0.0002546922769397497\n",
            "Epoch: 6/10, Step: 660/938, Loss: 0.00036818813532590866\n",
            "Epoch: 6/10, Step: 661/938, Loss: 0.0032009563874453306\n",
            "Epoch: 6/10, Step: 662/938, Loss: 0.014736286364495754\n",
            "Epoch: 6/10, Step: 663/938, Loss: 0.029736045747995377\n",
            "Epoch: 6/10, Step: 664/938, Loss: 0.0008033498888835311\n",
            "Epoch: 6/10, Step: 665/938, Loss: 1.9841008906951174e-05\n",
            "Epoch: 6/10, Step: 666/938, Loss: 0.01907380111515522\n",
            "Epoch: 6/10, Step: 667/938, Loss: 0.0011162285227328539\n",
            "Epoch: 6/10, Step: 668/938, Loss: 0.0007178893429227173\n",
            "Epoch: 6/10, Step: 669/938, Loss: 0.00039446799200959504\n",
            "Epoch: 6/10, Step: 670/938, Loss: 0.012693341821432114\n",
            "Epoch: 6/10, Step: 671/938, Loss: 4.494957101996988e-05\n",
            "Epoch: 6/10, Step: 672/938, Loss: 0.00011545854067662731\n",
            "Epoch: 6/10, Step: 673/938, Loss: 0.0006494062836281955\n",
            "Epoch: 6/10, Step: 674/938, Loss: 7.855627336539328e-05\n",
            "Epoch: 6/10, Step: 675/938, Loss: 0.015108157880604267\n",
            "Epoch: 6/10, Step: 676/938, Loss: 1.77506899490254e-05\n",
            "Epoch: 6/10, Step: 677/938, Loss: 0.0004202054697088897\n",
            "Epoch: 6/10, Step: 678/938, Loss: 0.000736845307983458\n",
            "Epoch: 6/10, Step: 679/938, Loss: 0.006495876703411341\n",
            "Epoch: 6/10, Step: 680/938, Loss: 0.0014927226584404707\n",
            "Epoch: 6/10, Step: 681/938, Loss: 0.0023638310376554728\n",
            "Epoch: 6/10, Step: 682/938, Loss: 0.0007692999206483364\n",
            "Epoch: 6/10, Step: 683/938, Loss: 0.004879309330135584\n",
            "Epoch: 6/10, Step: 684/938, Loss: 0.0006654404569417238\n",
            "Epoch: 6/10, Step: 685/938, Loss: 7.81490234658122e-05\n",
            "Epoch: 6/10, Step: 686/938, Loss: 0.0006543899653479457\n",
            "Epoch: 6/10, Step: 687/938, Loss: 0.009804646484553814\n",
            "Epoch: 6/10, Step: 688/938, Loss: 9.04680709936656e-05\n",
            "Epoch: 6/10, Step: 689/938, Loss: 0.04330763965845108\n",
            "Epoch: 6/10, Step: 690/938, Loss: 0.005651906598359346\n",
            "Epoch: 6/10, Step: 691/938, Loss: 0.0002618354046717286\n",
            "Epoch: 6/10, Step: 692/938, Loss: 0.00031242426484823227\n",
            "Epoch: 6/10, Step: 693/938, Loss: 0.00022027464001439512\n",
            "Epoch: 6/10, Step: 694/938, Loss: 0.10309863090515137\n",
            "Epoch: 6/10, Step: 695/938, Loss: 0.000434996240073815\n",
            "Epoch: 6/10, Step: 696/938, Loss: 4.64714685222134e-06\n",
            "Epoch: 6/10, Step: 697/938, Loss: 0.034735213965177536\n",
            "Epoch: 6/10, Step: 698/938, Loss: 7.795923011144623e-05\n",
            "Epoch: 6/10, Step: 699/938, Loss: 0.0035382879432290792\n",
            "Epoch: 6/10, Step: 700/938, Loss: 0.09845087677240372\n",
            "Epoch: 6/10, Step: 701/938, Loss: 0.00015841548156458884\n",
            "Epoch: 6/10, Step: 702/938, Loss: 0.05056479200720787\n",
            "Epoch: 6/10, Step: 703/938, Loss: 0.0001015886155073531\n",
            "Epoch: 6/10, Step: 704/938, Loss: 4.5700744522036985e-05\n",
            "Epoch: 6/10, Step: 705/938, Loss: 0.01304186787456274\n",
            "Epoch: 6/10, Step: 706/938, Loss: 0.02712336555123329\n",
            "Epoch: 6/10, Step: 707/938, Loss: 0.01866966299712658\n",
            "Epoch: 6/10, Step: 708/938, Loss: 0.006131434813141823\n",
            "Epoch: 6/10, Step: 709/938, Loss: 6.302740075625479e-05\n",
            "Epoch: 6/10, Step: 710/938, Loss: 0.0004035679157823324\n",
            "Epoch: 6/10, Step: 711/938, Loss: 0.0019510560669004917\n",
            "Epoch: 6/10, Step: 712/938, Loss: 0.0013732512015849352\n",
            "Epoch: 6/10, Step: 713/938, Loss: 0.019289029762148857\n",
            "Epoch: 6/10, Step: 714/938, Loss: 0.00032011137227527797\n",
            "Epoch: 6/10, Step: 715/938, Loss: 0.016200268641114235\n",
            "Epoch: 6/10, Step: 716/938, Loss: 0.05171087011694908\n",
            "Epoch: 6/10, Step: 717/938, Loss: 0.0024158204905688763\n",
            "Epoch: 6/10, Step: 718/938, Loss: 0.00020991326891817153\n",
            "Epoch: 6/10, Step: 719/938, Loss: 0.001331093953922391\n",
            "Epoch: 6/10, Step: 720/938, Loss: 0.000976066046860069\n",
            "Epoch: 6/10, Step: 721/938, Loss: 0.0007394503336399794\n",
            "Epoch: 6/10, Step: 722/938, Loss: 0.0245266892015934\n",
            "Epoch: 6/10, Step: 723/938, Loss: 0.00209612469188869\n",
            "Epoch: 6/10, Step: 724/938, Loss: 0.00013700216368306428\n",
            "Epoch: 6/10, Step: 725/938, Loss: 0.0005062638083472848\n",
            "Epoch: 6/10, Step: 726/938, Loss: 0.004430240951478481\n",
            "Epoch: 6/10, Step: 727/938, Loss: 0.015322373248636723\n",
            "Epoch: 6/10, Step: 728/938, Loss: 4.511710358201526e-05\n",
            "Epoch: 6/10, Step: 729/938, Loss: 0.019324056804180145\n",
            "Epoch: 6/10, Step: 730/938, Loss: 0.05393564701080322\n",
            "Epoch: 6/10, Step: 731/938, Loss: 7.712497608736157e-05\n",
            "Epoch: 6/10, Step: 732/938, Loss: 0.0009846030734479427\n",
            "Epoch: 6/10, Step: 733/938, Loss: 5.9387464716564864e-05\n",
            "Epoch: 6/10, Step: 734/938, Loss: 0.0005286921514198184\n",
            "Epoch: 6/10, Step: 735/938, Loss: 0.0005006889114156365\n",
            "Epoch: 6/10, Step: 736/938, Loss: 0.016078760847449303\n",
            "Epoch: 6/10, Step: 737/938, Loss: 0.0003844234743155539\n",
            "Epoch: 6/10, Step: 738/938, Loss: 0.0023701682221144438\n",
            "Epoch: 6/10, Step: 739/938, Loss: 0.0019838795997202396\n",
            "Epoch: 6/10, Step: 740/938, Loss: 0.008525705896317959\n",
            "Epoch: 6/10, Step: 741/938, Loss: 0.0004951792070642114\n",
            "Epoch: 6/10, Step: 742/938, Loss: 0.007312009576708078\n",
            "Epoch: 6/10, Step: 743/938, Loss: 0.0023780986666679382\n",
            "Epoch: 6/10, Step: 744/938, Loss: 0.0001274544483749196\n",
            "Epoch: 6/10, Step: 745/938, Loss: 0.0036028714384883642\n",
            "Epoch: 6/10, Step: 746/938, Loss: 0.009368294849991798\n",
            "Epoch: 6/10, Step: 747/938, Loss: 0.001056306529790163\n",
            "Epoch: 6/10, Step: 748/938, Loss: 0.0006877838750369847\n",
            "Epoch: 6/10, Step: 749/938, Loss: 0.0012314176419749856\n",
            "Epoch: 6/10, Step: 750/938, Loss: 0.0004566299612633884\n",
            "Epoch: 6/10, Step: 751/938, Loss: 9.580350888427347e-05\n",
            "Epoch: 6/10, Step: 752/938, Loss: 0.005021564196795225\n",
            "Epoch: 6/10, Step: 753/938, Loss: 7.403175550280139e-05\n",
            "Epoch: 6/10, Step: 754/938, Loss: 0.0006028367206454277\n",
            "Epoch: 6/10, Step: 755/938, Loss: 0.0008541762363165617\n",
            "Epoch: 6/10, Step: 756/938, Loss: 0.0004444464575499296\n",
            "Epoch: 6/10, Step: 757/938, Loss: 0.00019788311328738928\n",
            "Epoch: 6/10, Step: 758/938, Loss: 0.0006770420004613698\n",
            "Epoch: 6/10, Step: 759/938, Loss: 0.002123395213857293\n",
            "Epoch: 6/10, Step: 760/938, Loss: 0.00015009488561190665\n",
            "Epoch: 6/10, Step: 761/938, Loss: 0.00017770181875675917\n",
            "Epoch: 6/10, Step: 762/938, Loss: 0.00011331493442412466\n",
            "Epoch: 6/10, Step: 763/938, Loss: 0.02609432116150856\n",
            "Epoch: 6/10, Step: 764/938, Loss: 0.0003733581688720733\n",
            "Epoch: 6/10, Step: 765/938, Loss: 0.004090509377419949\n",
            "Epoch: 6/10, Step: 766/938, Loss: 0.0004356944700703025\n",
            "Epoch: 6/10, Step: 767/938, Loss: 0.00047719693975523114\n",
            "Epoch: 6/10, Step: 768/938, Loss: 0.00019661879923660308\n",
            "Epoch: 6/10, Step: 769/938, Loss: 0.03155609965324402\n",
            "Epoch: 6/10, Step: 770/938, Loss: 9.024453902384266e-05\n",
            "Epoch: 6/10, Step: 771/938, Loss: 0.0032069976441562176\n",
            "Epoch: 6/10, Step: 772/938, Loss: 0.00516974413767457\n",
            "Epoch: 6/10, Step: 773/938, Loss: 2.4418804969172925e-06\n",
            "Epoch: 6/10, Step: 774/938, Loss: 0.03650074079632759\n",
            "Epoch: 6/10, Step: 775/938, Loss: 0.009876874275505543\n",
            "Epoch: 6/10, Step: 776/938, Loss: 0.08851759135723114\n",
            "Epoch: 6/10, Step: 777/938, Loss: 0.002558312611654401\n",
            "Epoch: 6/10, Step: 778/938, Loss: 0.0037112946156412363\n",
            "Epoch: 6/10, Step: 779/938, Loss: 0.00034581386717036366\n",
            "Epoch: 6/10, Step: 780/938, Loss: 3.519363235682249e-05\n",
            "Epoch: 6/10, Step: 781/938, Loss: 0.001034384942613542\n",
            "Epoch: 6/10, Step: 782/938, Loss: 7.465224189218134e-05\n",
            "Epoch: 6/10, Step: 783/938, Loss: 0.0003690953890327364\n",
            "Epoch: 6/10, Step: 784/938, Loss: 0.0009134798310697079\n",
            "Epoch: 6/10, Step: 785/938, Loss: 0.00031793833477422595\n",
            "Epoch: 6/10, Step: 786/938, Loss: 0.0049515957944095135\n",
            "Epoch: 6/10, Step: 787/938, Loss: 0.0011214035330340266\n",
            "Epoch: 6/10, Step: 788/938, Loss: 0.0008423158433288336\n",
            "Epoch: 6/10, Step: 789/938, Loss: 0.048556845635175705\n",
            "Epoch: 6/10, Step: 790/938, Loss: 0.005726966541260481\n",
            "Epoch: 6/10, Step: 791/938, Loss: 0.0017244373448193073\n",
            "Epoch: 6/10, Step: 792/938, Loss: 0.0009739493252709508\n",
            "Epoch: 6/10, Step: 793/938, Loss: 0.0004394162679091096\n",
            "Epoch: 6/10, Step: 794/938, Loss: 0.0056495824828743935\n",
            "Epoch: 6/10, Step: 795/938, Loss: 0.00014128514158073813\n",
            "Epoch: 6/10, Step: 796/938, Loss: 0.000761910283472389\n",
            "Epoch: 6/10, Step: 797/938, Loss: 0.02855795994400978\n",
            "Epoch: 6/10, Step: 798/938, Loss: 0.009491750970482826\n",
            "Epoch: 6/10, Step: 799/938, Loss: 0.07046348601579666\n",
            "Epoch: 6/10, Step: 800/938, Loss: 0.018821509554982185\n",
            "Epoch: 6/10, Step: 801/938, Loss: 0.0008783104130998254\n",
            "Epoch: 6/10, Step: 802/938, Loss: 0.00028465117793530226\n",
            "Epoch: 6/10, Step: 803/938, Loss: 0.00023420184152200818\n",
            "Epoch: 6/10, Step: 804/938, Loss: 0.006837874185293913\n",
            "Epoch: 6/10, Step: 805/938, Loss: 1.4136063327896409e-05\n",
            "Epoch: 6/10, Step: 806/938, Loss: 0.00032929546432569623\n",
            "Epoch: 6/10, Step: 807/938, Loss: 0.00035366127849556506\n",
            "Epoch: 6/10, Step: 808/938, Loss: 0.003274742979556322\n",
            "Epoch: 6/10, Step: 809/938, Loss: 0.0012347442097961903\n",
            "Epoch: 6/10, Step: 810/938, Loss: 0.00022327953774947673\n",
            "Epoch: 6/10, Step: 811/938, Loss: 0.00012115311983507127\n",
            "Epoch: 6/10, Step: 812/938, Loss: 0.0015266488771885633\n",
            "Epoch: 6/10, Step: 813/938, Loss: 0.014360828325152397\n",
            "Epoch: 6/10, Step: 814/938, Loss: 0.000495139800477773\n",
            "Epoch: 6/10, Step: 815/938, Loss: 0.00020708153897430748\n",
            "Epoch: 6/10, Step: 816/938, Loss: 0.0041922410018742085\n",
            "Epoch: 6/10, Step: 817/938, Loss: 0.002123649697750807\n",
            "Epoch: 6/10, Step: 818/938, Loss: 0.030006900429725647\n",
            "Epoch: 6/10, Step: 819/938, Loss: 0.0017562020802870393\n",
            "Epoch: 6/10, Step: 820/938, Loss: 0.00020046727149747312\n",
            "Epoch: 6/10, Step: 821/938, Loss: 0.0008427014108747244\n",
            "Epoch: 6/10, Step: 822/938, Loss: 0.045843176543712616\n",
            "Epoch: 6/10, Step: 823/938, Loss: 0.0005447933217510581\n",
            "Epoch: 6/10, Step: 824/938, Loss: 0.0007621344993822277\n",
            "Epoch: 6/10, Step: 825/938, Loss: 2.4421293346676975e-05\n",
            "Epoch: 6/10, Step: 826/938, Loss: 0.028066499158740044\n",
            "Epoch: 6/10, Step: 827/938, Loss: 0.06305167824029922\n",
            "Epoch: 6/10, Step: 828/938, Loss: 0.000344420550391078\n",
            "Epoch: 6/10, Step: 829/938, Loss: 0.00027619668981060386\n",
            "Epoch: 6/10, Step: 830/938, Loss: 0.002909516915678978\n",
            "Epoch: 6/10, Step: 831/938, Loss: 1.9744153178180568e-05\n",
            "Epoch: 6/10, Step: 832/938, Loss: 0.007122798822820187\n",
            "Epoch: 6/10, Step: 833/938, Loss: 0.005122669041156769\n",
            "Epoch: 6/10, Step: 834/938, Loss: 0.12908737361431122\n",
            "Epoch: 6/10, Step: 835/938, Loss: 0.017565039917826653\n",
            "Epoch: 6/10, Step: 836/938, Loss: 0.032182615250349045\n",
            "Epoch: 6/10, Step: 837/938, Loss: 0.002469603903591633\n",
            "Epoch: 6/10, Step: 838/938, Loss: 0.0002958459372166544\n",
            "Epoch: 6/10, Step: 839/938, Loss: 5.466852235258557e-05\n",
            "Epoch: 6/10, Step: 840/938, Loss: 1.2037612577842083e-05\n",
            "Epoch: 6/10, Step: 841/938, Loss: 0.00544588640332222\n",
            "Epoch: 6/10, Step: 842/938, Loss: 0.006364000029861927\n",
            "Epoch: 6/10, Step: 843/938, Loss: 9.678821515990421e-05\n",
            "Epoch: 6/10, Step: 844/938, Loss: 0.003929540514945984\n",
            "Epoch: 6/10, Step: 845/938, Loss: 0.00029946453287266195\n",
            "Epoch: 6/10, Step: 846/938, Loss: 0.0011599079007282853\n",
            "Epoch: 6/10, Step: 847/938, Loss: 0.04038684442639351\n",
            "Epoch: 6/10, Step: 848/938, Loss: 0.01349758543074131\n",
            "Epoch: 6/10, Step: 849/938, Loss: 0.0037578484043478966\n",
            "Epoch: 6/10, Step: 850/938, Loss: 0.0001203952488140203\n",
            "Epoch: 6/10, Step: 851/938, Loss: 0.009404306299984455\n",
            "Epoch: 6/10, Step: 852/938, Loss: 0.00033490266650915146\n",
            "Epoch: 6/10, Step: 853/938, Loss: 0.0073739648796617985\n",
            "Epoch: 6/10, Step: 854/938, Loss: 0.00215217680670321\n",
            "Epoch: 6/10, Step: 855/938, Loss: 0.002723420038819313\n",
            "Epoch: 6/10, Step: 856/938, Loss: 0.027802886441349983\n",
            "Epoch: 6/10, Step: 857/938, Loss: 0.001699644373729825\n",
            "Epoch: 6/10, Step: 858/938, Loss: 0.010522021912038326\n",
            "Epoch: 6/10, Step: 859/938, Loss: 0.00028903590282425284\n",
            "Epoch: 6/10, Step: 860/938, Loss: 0.008132869377732277\n",
            "Epoch: 6/10, Step: 861/938, Loss: 0.0005187042406760156\n",
            "Epoch: 6/10, Step: 862/938, Loss: 0.0002595672267489135\n",
            "Epoch: 6/10, Step: 863/938, Loss: 0.08480909466743469\n",
            "Epoch: 6/10, Step: 864/938, Loss: 0.002616645535454154\n",
            "Epoch: 6/10, Step: 865/938, Loss: 0.00043448543874546885\n",
            "Epoch: 6/10, Step: 866/938, Loss: 0.004747660364955664\n",
            "Epoch: 6/10, Step: 867/938, Loss: 0.00880138948559761\n",
            "Epoch: 6/10, Step: 868/938, Loss: 0.005833174102008343\n",
            "Epoch: 6/10, Step: 869/938, Loss: 0.031280070543289185\n",
            "Epoch: 6/10, Step: 870/938, Loss: 2.3993849026737735e-05\n",
            "Epoch: 6/10, Step: 871/938, Loss: 0.0007974774925969541\n",
            "Epoch: 6/10, Step: 872/938, Loss: 0.0031129568815231323\n",
            "Epoch: 6/10, Step: 873/938, Loss: 0.005286140367388725\n",
            "Epoch: 6/10, Step: 874/938, Loss: 7.088144775480032e-05\n",
            "Epoch: 6/10, Step: 875/938, Loss: 0.037868499755859375\n",
            "Epoch: 6/10, Step: 876/938, Loss: 0.020510969683527946\n",
            "Epoch: 6/10, Step: 877/938, Loss: 0.012003813870251179\n",
            "Epoch: 6/10, Step: 878/938, Loss: 0.06715123355388641\n",
            "Epoch: 6/10, Step: 879/938, Loss: 0.0003862447920255363\n",
            "Epoch: 6/10, Step: 880/938, Loss: 0.0029549873434007168\n",
            "Epoch: 6/10, Step: 881/938, Loss: 0.0009451514342799783\n",
            "Epoch: 6/10, Step: 882/938, Loss: 0.01760919950902462\n",
            "Epoch: 6/10, Step: 883/938, Loss: 0.016870060935616493\n",
            "Epoch: 6/10, Step: 884/938, Loss: 0.0007286570616997778\n",
            "Epoch: 6/10, Step: 885/938, Loss: 0.0024499844294041395\n",
            "Epoch: 6/10, Step: 886/938, Loss: 0.0006018531275913119\n",
            "Epoch: 6/10, Step: 887/938, Loss: 0.018135324120521545\n",
            "Epoch: 6/10, Step: 888/938, Loss: 0.021384499967098236\n",
            "Epoch: 6/10, Step: 889/938, Loss: 0.013087400235235691\n",
            "Epoch: 6/10, Step: 890/938, Loss: 0.00015196646563708782\n",
            "Epoch: 6/10, Step: 891/938, Loss: 0.016797397285699844\n",
            "Epoch: 6/10, Step: 892/938, Loss: 0.10867480933666229\n",
            "Epoch: 6/10, Step: 893/938, Loss: 3.0524741305271164e-05\n",
            "Epoch: 6/10, Step: 894/938, Loss: 0.11270853132009506\n",
            "Epoch: 6/10, Step: 895/938, Loss: 0.00011207703937543556\n",
            "Epoch: 6/10, Step: 896/938, Loss: 0.0017782626673579216\n",
            "Epoch: 6/10, Step: 897/938, Loss: 0.00010085299436468631\n",
            "Epoch: 6/10, Step: 898/938, Loss: 0.00017370512068737298\n",
            "Epoch: 6/10, Step: 899/938, Loss: 0.0002978781412821263\n",
            "Epoch: 6/10, Step: 900/938, Loss: 0.04368337243795395\n",
            "Epoch: 6/10, Step: 901/938, Loss: 0.0007179725216701627\n",
            "Epoch: 6/10, Step: 902/938, Loss: 0.0006126431399025023\n",
            "Epoch: 6/10, Step: 903/938, Loss: 0.004813895560801029\n",
            "Epoch: 6/10, Step: 904/938, Loss: 0.009349321946501732\n",
            "Epoch: 6/10, Step: 905/938, Loss: 0.012161308899521828\n",
            "Epoch: 6/10, Step: 906/938, Loss: 0.031744860112667084\n",
            "Epoch: 6/10, Step: 907/938, Loss: 0.009152671322226524\n",
            "Epoch: 6/10, Step: 908/938, Loss: 0.0004484253004193306\n",
            "Epoch: 6/10, Step: 909/938, Loss: 0.1395736187696457\n",
            "Epoch: 6/10, Step: 910/938, Loss: 0.0007322807796299458\n",
            "Epoch: 6/10, Step: 911/938, Loss: 0.0008836897904984653\n",
            "Epoch: 6/10, Step: 912/938, Loss: 9.881037112791091e-05\n",
            "Epoch: 6/10, Step: 913/938, Loss: 0.0005664782365784049\n",
            "Epoch: 6/10, Step: 914/938, Loss: 0.025891633704304695\n",
            "Epoch: 6/10, Step: 915/938, Loss: 0.00045347248669713736\n",
            "Epoch: 6/10, Step: 916/938, Loss: 0.00010806181671796367\n",
            "Epoch: 6/10, Step: 917/938, Loss: 0.0008591310470364988\n",
            "Epoch: 6/10, Step: 918/938, Loss: 0.0009101353352889419\n",
            "Epoch: 6/10, Step: 919/938, Loss: 0.0005952309584245086\n",
            "Epoch: 6/10, Step: 920/938, Loss: 0.00014773666043765843\n",
            "Epoch: 6/10, Step: 921/938, Loss: 0.00013672112254425883\n",
            "Epoch: 6/10, Step: 922/938, Loss: 0.0002691063564270735\n",
            "Epoch: 6/10, Step: 923/938, Loss: 0.0688357874751091\n",
            "Epoch: 6/10, Step: 924/938, Loss: 0.0009023676393553615\n",
            "Epoch: 6/10, Step: 925/938, Loss: 0.0004134960472583771\n",
            "Epoch: 6/10, Step: 926/938, Loss: 0.0003804662555921823\n",
            "Epoch: 6/10, Step: 927/938, Loss: 0.00011533153156051412\n",
            "Epoch: 6/10, Step: 928/938, Loss: 0.011201645247638226\n",
            "Epoch: 6/10, Step: 929/938, Loss: 6.713088805554435e-05\n",
            "Epoch: 6/10, Step: 930/938, Loss: 0.004684182815253735\n",
            "Epoch: 6/10, Step: 931/938, Loss: 0.0031371493823826313\n",
            "Epoch: 6/10, Step: 932/938, Loss: 0.037752073258161545\n",
            "Epoch: 6/10, Step: 933/938, Loss: 0.1307935118675232\n",
            "Epoch: 6/10, Step: 934/938, Loss: 0.0037989262491464615\n",
            "Epoch: 6/10, Step: 935/938, Loss: 0.0009080942836590111\n",
            "Epoch: 6/10, Step: 936/938, Loss: 0.0005546085303649306\n",
            "Epoch: 6/10, Step: 937/938, Loss: 0.000991164823062718\n",
            "Epoch: 6/10, Step: 938/938, Loss: 0.004358443897217512\n",
            "Epoch: 7/10, Step: 1/938, Loss: 0.0011658570729196072\n",
            "Epoch: 7/10, Step: 2/938, Loss: 0.0003330761974211782\n",
            "Epoch: 7/10, Step: 3/938, Loss: 0.0011948462342843413\n",
            "Epoch: 7/10, Step: 4/938, Loss: 0.000339624093612656\n",
            "Epoch: 7/10, Step: 5/938, Loss: 0.0002593848039396107\n",
            "Epoch: 7/10, Step: 6/938, Loss: 0.0080223698168993\n",
            "Epoch: 7/10, Step: 7/938, Loss: 0.00020807876717299223\n",
            "Epoch: 7/10, Step: 8/938, Loss: 0.0009669092833064497\n",
            "Epoch: 7/10, Step: 9/938, Loss: 0.0009969132952392101\n",
            "Epoch: 7/10, Step: 10/938, Loss: 0.01161428913474083\n",
            "Epoch: 7/10, Step: 11/938, Loss: 0.0085568493232131\n",
            "Epoch: 7/10, Step: 12/938, Loss: 0.001089839031919837\n",
            "Epoch: 7/10, Step: 13/938, Loss: 0.0005206050118431449\n",
            "Epoch: 7/10, Step: 14/938, Loss: 0.006812429521232843\n",
            "Epoch: 7/10, Step: 15/938, Loss: 0.0061653112061321735\n",
            "Epoch: 7/10, Step: 16/938, Loss: 0.005307903978973627\n",
            "Epoch: 7/10, Step: 17/938, Loss: 0.002018002327531576\n",
            "Epoch: 7/10, Step: 18/938, Loss: 0.00015553226694464684\n",
            "Epoch: 7/10, Step: 19/938, Loss: 0.0019162555690854788\n",
            "Epoch: 7/10, Step: 20/938, Loss: 0.0007257724064402282\n",
            "Epoch: 7/10, Step: 21/938, Loss: 0.007607479579746723\n",
            "Epoch: 7/10, Step: 22/938, Loss: 0.0003456073463894427\n",
            "Epoch: 7/10, Step: 23/938, Loss: 0.006578957196325064\n",
            "Epoch: 7/10, Step: 24/938, Loss: 0.0006535587017424405\n",
            "Epoch: 7/10, Step: 25/938, Loss: 0.00599197531118989\n",
            "Epoch: 7/10, Step: 26/938, Loss: 0.004624261986464262\n",
            "Epoch: 7/10, Step: 27/938, Loss: 5.6599255913170055e-05\n",
            "Epoch: 7/10, Step: 28/938, Loss: 0.0006148549146018922\n",
            "Epoch: 7/10, Step: 29/938, Loss: 2.9618380722240545e-05\n",
            "Epoch: 7/10, Step: 30/938, Loss: 9.179685730487108e-05\n",
            "Epoch: 7/10, Step: 31/938, Loss: 0.017409158870577812\n",
            "Epoch: 7/10, Step: 32/938, Loss: 0.0008870189194567502\n",
            "Epoch: 7/10, Step: 33/938, Loss: 0.0013948703417554498\n",
            "Epoch: 7/10, Step: 34/938, Loss: 0.012209253385663033\n",
            "Epoch: 7/10, Step: 35/938, Loss: 2.8013173505314626e-05\n",
            "Epoch: 7/10, Step: 36/938, Loss: 0.00193167629186064\n",
            "Epoch: 7/10, Step: 37/938, Loss: 0.0019021750194951892\n",
            "Epoch: 7/10, Step: 38/938, Loss: 0.0006100425380282104\n",
            "Epoch: 7/10, Step: 39/938, Loss: 0.0026806816458702087\n",
            "Epoch: 7/10, Step: 40/938, Loss: 4.332184107624926e-05\n",
            "Epoch: 7/10, Step: 41/938, Loss: 0.0001777536526788026\n",
            "Epoch: 7/10, Step: 42/938, Loss: 0.00011120126873720437\n",
            "Epoch: 7/10, Step: 43/938, Loss: 0.0009162949863821268\n",
            "Epoch: 7/10, Step: 44/938, Loss: 0.00020160336862318218\n",
            "Epoch: 7/10, Step: 45/938, Loss: 0.0034162746742367744\n",
            "Epoch: 7/10, Step: 46/938, Loss: 1.5073034774104599e-05\n",
            "Epoch: 7/10, Step: 47/938, Loss: 0.015453402884304523\n",
            "Epoch: 7/10, Step: 48/938, Loss: 0.00017335664597339928\n",
            "Epoch: 7/10, Step: 49/938, Loss: 0.018733562901616096\n",
            "Epoch: 7/10, Step: 50/938, Loss: 0.0003934529086109251\n",
            "Epoch: 7/10, Step: 51/938, Loss: 0.00661629531532526\n",
            "Epoch: 7/10, Step: 52/938, Loss: 0.00040638860082253814\n",
            "Epoch: 7/10, Step: 53/938, Loss: 0.006202380638569593\n",
            "Epoch: 7/10, Step: 54/938, Loss: 0.0004878268809989095\n",
            "Epoch: 7/10, Step: 55/938, Loss: 0.0025790692307054996\n",
            "Epoch: 7/10, Step: 56/938, Loss: 6.77106436342001e-05\n",
            "Epoch: 7/10, Step: 57/938, Loss: 0.052210528403520584\n",
            "Epoch: 7/10, Step: 58/938, Loss: 0.0006973448907956481\n",
            "Epoch: 7/10, Step: 59/938, Loss: 0.00011813437595264986\n",
            "Epoch: 7/10, Step: 60/938, Loss: 0.0011161307338625193\n",
            "Epoch: 7/10, Step: 61/938, Loss: 0.007692873477935791\n",
            "Epoch: 7/10, Step: 62/938, Loss: 0.014302940107882023\n",
            "Epoch: 7/10, Step: 63/938, Loss: 0.0150264548137784\n",
            "Epoch: 7/10, Step: 64/938, Loss: 0.0002718736359383911\n",
            "Epoch: 7/10, Step: 65/938, Loss: 0.0004054702876601368\n",
            "Epoch: 7/10, Step: 66/938, Loss: 0.023762540891766548\n",
            "Epoch: 7/10, Step: 67/938, Loss: 0.0009576505399309099\n",
            "Epoch: 7/10, Step: 68/938, Loss: 0.001684547052718699\n",
            "Epoch: 7/10, Step: 69/938, Loss: 0.00015197474567685276\n",
            "Epoch: 7/10, Step: 70/938, Loss: 0.0002132768277078867\n",
            "Epoch: 7/10, Step: 71/938, Loss: 0.0006198397604748607\n",
            "Epoch: 7/10, Step: 72/938, Loss: 8.53116434882395e-05\n",
            "Epoch: 7/10, Step: 73/938, Loss: 0.0006424046587198973\n",
            "Epoch: 7/10, Step: 74/938, Loss: 0.0002049192989943549\n",
            "Epoch: 7/10, Step: 75/938, Loss: 2.926178422058001e-05\n",
            "Epoch: 7/10, Step: 76/938, Loss: 0.00032683199970051646\n",
            "Epoch: 7/10, Step: 77/938, Loss: 0.02281724289059639\n",
            "Epoch: 7/10, Step: 78/938, Loss: 0.002462022239342332\n",
            "Epoch: 7/10, Step: 79/938, Loss: 3.4015065466519445e-05\n",
            "Epoch: 7/10, Step: 80/938, Loss: 0.0012942843604832888\n",
            "Epoch: 7/10, Step: 81/938, Loss: 6.400755864888197e-06\n",
            "Epoch: 7/10, Step: 82/938, Loss: 0.0022960598580539227\n",
            "Epoch: 7/10, Step: 83/938, Loss: 0.000984280020929873\n",
            "Epoch: 7/10, Step: 84/938, Loss: 4.3062354961875826e-05\n",
            "Epoch: 7/10, Step: 85/938, Loss: 0.0492946095764637\n",
            "Epoch: 7/10, Step: 86/938, Loss: 0.0015859137056395411\n",
            "Epoch: 7/10, Step: 87/938, Loss: 0.0001748906506691128\n",
            "Epoch: 7/10, Step: 88/938, Loss: 0.00039204192580655217\n",
            "Epoch: 7/10, Step: 89/938, Loss: 3.736731378012337e-05\n",
            "Epoch: 7/10, Step: 90/938, Loss: 0.00010482420475455001\n",
            "Epoch: 7/10, Step: 91/938, Loss: 0.0016068139811977744\n",
            "Epoch: 7/10, Step: 92/938, Loss: 0.02793816849589348\n",
            "Epoch: 7/10, Step: 93/938, Loss: 0.0001293337845709175\n",
            "Epoch: 7/10, Step: 94/938, Loss: 3.755029320018366e-05\n",
            "Epoch: 7/10, Step: 95/938, Loss: 0.03292945772409439\n",
            "Epoch: 7/10, Step: 96/938, Loss: 0.004801947623491287\n",
            "Epoch: 7/10, Step: 97/938, Loss: 0.003960958682000637\n",
            "Epoch: 7/10, Step: 98/938, Loss: 0.00035751500399783254\n",
            "Epoch: 7/10, Step: 99/938, Loss: 0.00025044212816283107\n",
            "Epoch: 7/10, Step: 100/938, Loss: 0.019126025959849358\n",
            "Epoch: 7/10, Step: 101/938, Loss: 0.0044570984318852425\n",
            "Epoch: 7/10, Step: 102/938, Loss: 6.524811760755256e-05\n",
            "Epoch: 7/10, Step: 103/938, Loss: 0.001412814948707819\n",
            "Epoch: 7/10, Step: 104/938, Loss: 4.18527088186238e-06\n",
            "Epoch: 7/10, Step: 105/938, Loss: 0.003494070377200842\n",
            "Epoch: 7/10, Step: 106/938, Loss: 0.0030462986323982477\n",
            "Epoch: 7/10, Step: 107/938, Loss: 0.0025578259956091642\n",
            "Epoch: 7/10, Step: 108/938, Loss: 0.0005843935068696737\n",
            "Epoch: 7/10, Step: 109/938, Loss: 6.742145342286676e-05\n",
            "Epoch: 7/10, Step: 110/938, Loss: 0.003509413916617632\n",
            "Epoch: 7/10, Step: 111/938, Loss: 0.0015093106776475906\n",
            "Epoch: 7/10, Step: 112/938, Loss: 0.0004629929317161441\n",
            "Epoch: 7/10, Step: 113/938, Loss: 0.000732999702449888\n",
            "Epoch: 7/10, Step: 114/938, Loss: 0.001401581452228129\n",
            "Epoch: 7/10, Step: 115/938, Loss: 0.021579504013061523\n",
            "Epoch: 7/10, Step: 116/938, Loss: 0.00257658283226192\n",
            "Epoch: 7/10, Step: 117/938, Loss: 0.000792861043009907\n",
            "Epoch: 7/10, Step: 118/938, Loss: 0.0025341608561575413\n",
            "Epoch: 7/10, Step: 119/938, Loss: 0.00024964616750366986\n",
            "Epoch: 7/10, Step: 120/938, Loss: 0.0002185675984947011\n",
            "Epoch: 7/10, Step: 121/938, Loss: 0.000788537145126611\n",
            "Epoch: 7/10, Step: 122/938, Loss: 1.8831169654731639e-06\n",
            "Epoch: 7/10, Step: 123/938, Loss: 0.026609038934111595\n",
            "Epoch: 7/10, Step: 124/938, Loss: 5.086831879452802e-05\n",
            "Epoch: 7/10, Step: 125/938, Loss: 0.0003173439181409776\n",
            "Epoch: 7/10, Step: 126/938, Loss: 5.284533472149633e-05\n",
            "Epoch: 7/10, Step: 127/938, Loss: 0.0012234761379659176\n",
            "Epoch: 7/10, Step: 128/938, Loss: 0.0022821982856839895\n",
            "Epoch: 7/10, Step: 129/938, Loss: 0.008065755479037762\n",
            "Epoch: 7/10, Step: 130/938, Loss: 0.00036017634556628764\n",
            "Epoch: 7/10, Step: 131/938, Loss: 0.07323238253593445\n",
            "Epoch: 7/10, Step: 132/938, Loss: 0.00814732350409031\n",
            "Epoch: 7/10, Step: 133/938, Loss: 5.3882384236203507e-05\n",
            "Epoch: 7/10, Step: 134/938, Loss: 0.0002044236462097615\n",
            "Epoch: 7/10, Step: 135/938, Loss: 0.00017495710926596075\n",
            "Epoch: 7/10, Step: 136/938, Loss: 0.00010796649439726025\n",
            "Epoch: 7/10, Step: 137/938, Loss: 0.03928060829639435\n",
            "Epoch: 7/10, Step: 138/938, Loss: 0.010595391504466534\n",
            "Epoch: 7/10, Step: 139/938, Loss: 1.8662787624634802e-05\n",
            "Epoch: 7/10, Step: 140/938, Loss: 0.00029059802182018757\n",
            "Epoch: 7/10, Step: 141/938, Loss: 1.1897473996214103e-05\n",
            "Epoch: 7/10, Step: 142/938, Loss: 0.00011108035687357187\n",
            "Epoch: 7/10, Step: 143/938, Loss: 3.8021928048692644e-05\n",
            "Epoch: 7/10, Step: 144/938, Loss: 3.899574585375376e-05\n",
            "Epoch: 7/10, Step: 145/938, Loss: 0.00144874001853168\n",
            "Epoch: 7/10, Step: 146/938, Loss: 0.00011864982661791146\n",
            "Epoch: 7/10, Step: 147/938, Loss: 0.0003457588027231395\n",
            "Epoch: 7/10, Step: 148/938, Loss: 0.0010537919588387012\n",
            "Epoch: 7/10, Step: 149/938, Loss: 1.6949781638686545e-05\n",
            "Epoch: 7/10, Step: 150/938, Loss: 0.004957611206918955\n",
            "Epoch: 7/10, Step: 151/938, Loss: 7.930613355711102e-05\n",
            "Epoch: 7/10, Step: 152/938, Loss: 7.115313928807154e-05\n",
            "Epoch: 7/10, Step: 153/938, Loss: 0.0003784516011364758\n",
            "Epoch: 7/10, Step: 154/938, Loss: 0.0009610039414837956\n",
            "Epoch: 7/10, Step: 155/938, Loss: 0.007872601971030235\n",
            "Epoch: 7/10, Step: 156/938, Loss: 0.0004297752457205206\n",
            "Epoch: 7/10, Step: 157/938, Loss: 0.00025178419309668243\n",
            "Epoch: 7/10, Step: 158/938, Loss: 0.0014058101223781705\n",
            "Epoch: 7/10, Step: 159/938, Loss: 0.00015607045497745275\n",
            "Epoch: 7/10, Step: 160/938, Loss: 0.06478241086006165\n",
            "Epoch: 7/10, Step: 161/938, Loss: 9.35151256271638e-05\n",
            "Epoch: 7/10, Step: 162/938, Loss: 0.0004948883433826268\n",
            "Epoch: 7/10, Step: 163/938, Loss: 7.45679353713058e-05\n",
            "Epoch: 7/10, Step: 164/938, Loss: 0.0003774487122427672\n",
            "Epoch: 7/10, Step: 165/938, Loss: 0.016872402280569077\n",
            "Epoch: 7/10, Step: 166/938, Loss: 0.004124864935874939\n",
            "Epoch: 7/10, Step: 167/938, Loss: 0.000528449600096792\n",
            "Epoch: 7/10, Step: 168/938, Loss: 0.010898864828050137\n",
            "Epoch: 7/10, Step: 169/938, Loss: 0.00029102974804118276\n",
            "Epoch: 7/10, Step: 170/938, Loss: 0.0024756737984716892\n",
            "Epoch: 7/10, Step: 171/938, Loss: 0.000347278721164912\n",
            "Epoch: 7/10, Step: 172/938, Loss: 0.00010276122338837013\n",
            "Epoch: 7/10, Step: 173/938, Loss: 0.006621215958148241\n",
            "Epoch: 7/10, Step: 174/938, Loss: 9.958434020518325e-06\n",
            "Epoch: 7/10, Step: 175/938, Loss: 0.0001120979359257035\n",
            "Epoch: 7/10, Step: 176/938, Loss: 0.0036633119452744722\n",
            "Epoch: 7/10, Step: 177/938, Loss: 0.005021131131798029\n",
            "Epoch: 7/10, Step: 178/938, Loss: 0.0006011858349665999\n",
            "Epoch: 7/10, Step: 179/938, Loss: 0.0027443161234259605\n",
            "Epoch: 7/10, Step: 180/938, Loss: 0.01434037834405899\n",
            "Epoch: 7/10, Step: 181/938, Loss: 7.312296656891704e-05\n",
            "Epoch: 7/10, Step: 182/938, Loss: 0.002607830101624131\n",
            "Epoch: 7/10, Step: 183/938, Loss: 0.0020512158516794443\n",
            "Epoch: 7/10, Step: 184/938, Loss: 0.0031555083114653826\n",
            "Epoch: 7/10, Step: 185/938, Loss: 0.0022068454418331385\n",
            "Epoch: 7/10, Step: 186/938, Loss: 0.000154483801452443\n",
            "Epoch: 7/10, Step: 187/938, Loss: 8.729274850338697e-05\n",
            "Epoch: 7/10, Step: 188/938, Loss: 0.00040829175850376487\n",
            "Epoch: 7/10, Step: 189/938, Loss: 5.3271509386831895e-05\n",
            "Epoch: 7/10, Step: 190/938, Loss: 0.001923457602970302\n",
            "Epoch: 7/10, Step: 191/938, Loss: 9.595688607078046e-05\n",
            "Epoch: 7/10, Step: 192/938, Loss: 0.00041353661799803376\n",
            "Epoch: 7/10, Step: 193/938, Loss: 0.0009450320503674448\n",
            "Epoch: 7/10, Step: 194/938, Loss: 0.0013067086692899466\n",
            "Epoch: 7/10, Step: 195/938, Loss: 0.00010722692240960896\n",
            "Epoch: 7/10, Step: 196/938, Loss: 0.07518116384744644\n",
            "Epoch: 7/10, Step: 197/938, Loss: 0.004357288125902414\n",
            "Epoch: 7/10, Step: 198/938, Loss: 0.0009452025406062603\n",
            "Epoch: 7/10, Step: 199/938, Loss: 0.002266389550641179\n",
            "Epoch: 7/10, Step: 200/938, Loss: 0.00014516423107124865\n",
            "Epoch: 7/10, Step: 201/938, Loss: 0.0009273654432035983\n",
            "Epoch: 7/10, Step: 202/938, Loss: 0.001348985475488007\n",
            "Epoch: 7/10, Step: 203/938, Loss: 0.026194706559181213\n",
            "Epoch: 7/10, Step: 204/938, Loss: 4.0495931898476556e-05\n",
            "Epoch: 7/10, Step: 205/938, Loss: 0.0005217748112045228\n",
            "Epoch: 7/10, Step: 206/938, Loss: 0.0013233888894319534\n",
            "Epoch: 7/10, Step: 207/938, Loss: 0.004429451189935207\n",
            "Epoch: 7/10, Step: 208/938, Loss: 0.0009700898663140833\n",
            "Epoch: 7/10, Step: 209/938, Loss: 8.323753718286753e-06\n",
            "Epoch: 7/10, Step: 210/938, Loss: 0.0009114049607887864\n",
            "Epoch: 7/10, Step: 211/938, Loss: 0.01755824126303196\n",
            "Epoch: 7/10, Step: 212/938, Loss: 0.007158958353102207\n",
            "Epoch: 7/10, Step: 213/938, Loss: 0.0014498064992949367\n",
            "Epoch: 7/10, Step: 214/938, Loss: 0.00025212240871042013\n",
            "Epoch: 7/10, Step: 215/938, Loss: 0.0008321924833580852\n",
            "Epoch: 7/10, Step: 216/938, Loss: 0.0001568182633491233\n",
            "Epoch: 7/10, Step: 217/938, Loss: 1.3049343579041306e-05\n",
            "Epoch: 7/10, Step: 218/938, Loss: 0.00035661549190990627\n",
            "Epoch: 7/10, Step: 219/938, Loss: 0.0024302303791046143\n",
            "Epoch: 7/10, Step: 220/938, Loss: 1.2881993825430982e-05\n",
            "Epoch: 7/10, Step: 221/938, Loss: 5.253289418760687e-05\n",
            "Epoch: 7/10, Step: 222/938, Loss: 2.1244090021355078e-05\n",
            "Epoch: 7/10, Step: 223/938, Loss: 0.00017274680431000888\n",
            "Epoch: 7/10, Step: 224/938, Loss: 2.915693767135963e-05\n",
            "Epoch: 7/10, Step: 225/938, Loss: 0.0001756182755343616\n",
            "Epoch: 7/10, Step: 226/938, Loss: 0.001331387204118073\n",
            "Epoch: 7/10, Step: 227/938, Loss: 0.008350669406354427\n",
            "Epoch: 7/10, Step: 228/938, Loss: 0.008161813020706177\n",
            "Epoch: 7/10, Step: 229/938, Loss: 0.0013322136364877224\n",
            "Epoch: 7/10, Step: 230/938, Loss: 0.007316824048757553\n",
            "Epoch: 7/10, Step: 231/938, Loss: 0.00028360699070617557\n",
            "Epoch: 7/10, Step: 232/938, Loss: 0.0015035757096484303\n",
            "Epoch: 7/10, Step: 233/938, Loss: 0.00014951637422200292\n",
            "Epoch: 7/10, Step: 234/938, Loss: 0.00027401262195780873\n",
            "Epoch: 7/10, Step: 235/938, Loss: 4.732480738312006e-05\n",
            "Epoch: 7/10, Step: 236/938, Loss: 0.00017228705110028386\n",
            "Epoch: 7/10, Step: 237/938, Loss: 0.00027885058079846203\n",
            "Epoch: 7/10, Step: 238/938, Loss: 0.002443338744342327\n",
            "Epoch: 7/10, Step: 239/938, Loss: 0.03815039247274399\n",
            "Epoch: 7/10, Step: 240/938, Loss: 0.003354507265612483\n",
            "Epoch: 7/10, Step: 241/938, Loss: 0.002740184310823679\n",
            "Epoch: 7/10, Step: 242/938, Loss: 0.00901290588080883\n",
            "Epoch: 7/10, Step: 243/938, Loss: 3.711500175995752e-05\n",
            "Epoch: 7/10, Step: 244/938, Loss: 7.734241080470383e-05\n",
            "Epoch: 7/10, Step: 245/938, Loss: 0.0008643974433653057\n",
            "Epoch: 7/10, Step: 246/938, Loss: 4.3696118154912256e-06\n",
            "Epoch: 7/10, Step: 247/938, Loss: 0.000736870220862329\n",
            "Epoch: 7/10, Step: 248/938, Loss: 0.006811507977545261\n",
            "Epoch: 7/10, Step: 249/938, Loss: 0.00011360008647898212\n",
            "Epoch: 7/10, Step: 250/938, Loss: 0.03296342492103577\n",
            "Epoch: 7/10, Step: 251/938, Loss: 0.001149237621575594\n",
            "Epoch: 7/10, Step: 252/938, Loss: 0.0024401035625487566\n",
            "Epoch: 7/10, Step: 253/938, Loss: 0.0021184359211474657\n",
            "Epoch: 7/10, Step: 254/938, Loss: 0.0004900493077002466\n",
            "Epoch: 7/10, Step: 255/938, Loss: 0.00027528280043043196\n",
            "Epoch: 7/10, Step: 256/938, Loss: 0.001183130545541644\n",
            "Epoch: 7/10, Step: 257/938, Loss: 7.155982166295871e-05\n",
            "Epoch: 7/10, Step: 258/938, Loss: 0.009409669786691666\n",
            "Epoch: 7/10, Step: 259/938, Loss: 9.622498509997968e-06\n",
            "Epoch: 7/10, Step: 260/938, Loss: 0.0001251602516276762\n",
            "Epoch: 7/10, Step: 261/938, Loss: 8.064669964369386e-05\n",
            "Epoch: 7/10, Step: 262/938, Loss: 0.00021103471226524562\n",
            "Epoch: 7/10, Step: 263/938, Loss: 0.09239788353443146\n",
            "Epoch: 7/10, Step: 264/938, Loss: 1.2138983947806992e-05\n",
            "Epoch: 7/10, Step: 265/938, Loss: 2.1401672711363062e-05\n",
            "Epoch: 7/10, Step: 266/938, Loss: 0.0011034782510250807\n",
            "Epoch: 7/10, Step: 267/938, Loss: 3.0799801606917754e-05\n",
            "Epoch: 7/10, Step: 268/938, Loss: 0.0003690242883749306\n",
            "Epoch: 7/10, Step: 269/938, Loss: 0.0009390126797370613\n",
            "Epoch: 7/10, Step: 270/938, Loss: 0.00021981690952088684\n",
            "Epoch: 7/10, Step: 271/938, Loss: 0.028100013732910156\n",
            "Epoch: 7/10, Step: 272/938, Loss: 0.002118654316291213\n",
            "Epoch: 7/10, Step: 273/938, Loss: 0.05988391488790512\n",
            "Epoch: 7/10, Step: 274/938, Loss: 0.00033766383421607316\n",
            "Epoch: 7/10, Step: 275/938, Loss: 0.00015820193220861256\n",
            "Epoch: 7/10, Step: 276/938, Loss: 0.0023541334085166454\n",
            "Epoch: 7/10, Step: 277/938, Loss: 0.0002763706143014133\n",
            "Epoch: 7/10, Step: 278/938, Loss: 4.3148629629286006e-05\n",
            "Epoch: 7/10, Step: 279/938, Loss: 4.902254204353085e-06\n",
            "Epoch: 7/10, Step: 280/938, Loss: 0.00017466660938225687\n",
            "Epoch: 7/10, Step: 281/938, Loss: 8.266385702881962e-05\n",
            "Epoch: 7/10, Step: 282/938, Loss: 0.00011118659313069656\n",
            "Epoch: 7/10, Step: 283/938, Loss: 0.0013387772487476468\n",
            "Epoch: 7/10, Step: 284/938, Loss: 0.00015205636736936867\n",
            "Epoch: 7/10, Step: 285/938, Loss: 6.112040864536539e-05\n",
            "Epoch: 7/10, Step: 286/938, Loss: 0.0003444304456934333\n",
            "Epoch: 7/10, Step: 287/938, Loss: 0.0016180214006453753\n",
            "Epoch: 7/10, Step: 288/938, Loss: 0.00011455341154942289\n",
            "Epoch: 7/10, Step: 289/938, Loss: 0.0005171241937205195\n",
            "Epoch: 7/10, Step: 290/938, Loss: 0.0006819784757681191\n",
            "Epoch: 7/10, Step: 291/938, Loss: 0.00032026873668655753\n",
            "Epoch: 7/10, Step: 292/938, Loss: 0.00013390937238000333\n",
            "Epoch: 7/10, Step: 293/938, Loss: 0.001375618390738964\n",
            "Epoch: 7/10, Step: 294/938, Loss: 0.0004899044870398939\n",
            "Epoch: 7/10, Step: 295/938, Loss: 0.0019416167633607984\n",
            "Epoch: 7/10, Step: 296/938, Loss: 0.004636491183191538\n",
            "Epoch: 7/10, Step: 297/938, Loss: 0.00029517686925828457\n",
            "Epoch: 7/10, Step: 298/938, Loss: 0.000497630622703582\n",
            "Epoch: 7/10, Step: 299/938, Loss: 7.481449574697763e-05\n",
            "Epoch: 7/10, Step: 300/938, Loss: 0.000237945350818336\n",
            "Epoch: 7/10, Step: 301/938, Loss: 0.006474756635725498\n",
            "Epoch: 7/10, Step: 302/938, Loss: 0.006148996762931347\n",
            "Epoch: 7/10, Step: 303/938, Loss: 0.000184103031642735\n",
            "Epoch: 7/10, Step: 304/938, Loss: 0.006256485357880592\n",
            "Epoch: 7/10, Step: 305/938, Loss: 0.0012110663810744882\n",
            "Epoch: 7/10, Step: 306/938, Loss: 0.00025738764088600874\n",
            "Epoch: 7/10, Step: 307/938, Loss: 0.01740294322371483\n",
            "Epoch: 7/10, Step: 308/938, Loss: 0.0002985348692163825\n",
            "Epoch: 7/10, Step: 309/938, Loss: 0.000880602456163615\n",
            "Epoch: 7/10, Step: 310/938, Loss: 9.227900591213256e-05\n",
            "Epoch: 7/10, Step: 311/938, Loss: 0.0003076378197874874\n",
            "Epoch: 7/10, Step: 312/938, Loss: 0.005282183177769184\n",
            "Epoch: 7/10, Step: 313/938, Loss: 0.013972118496894836\n",
            "Epoch: 7/10, Step: 314/938, Loss: 0.0001496132172178477\n",
            "Epoch: 7/10, Step: 315/938, Loss: 0.03639024496078491\n",
            "Epoch: 7/10, Step: 316/938, Loss: 0.0003084100317209959\n",
            "Epoch: 7/10, Step: 317/938, Loss: 0.0027704851236194372\n",
            "Epoch: 7/10, Step: 318/938, Loss: 0.0008405604166910052\n",
            "Epoch: 7/10, Step: 319/938, Loss: 0.001703832414932549\n",
            "Epoch: 7/10, Step: 320/938, Loss: 4.961263402947225e-05\n",
            "Epoch: 7/10, Step: 321/938, Loss: 0.0016663761343806982\n",
            "Epoch: 7/10, Step: 322/938, Loss: 7.637706585228443e-05\n",
            "Epoch: 7/10, Step: 323/938, Loss: 6.653085438301787e-05\n",
            "Epoch: 7/10, Step: 324/938, Loss: 0.04830939695239067\n",
            "Epoch: 7/10, Step: 325/938, Loss: 0.00039116988773457706\n",
            "Epoch: 7/10, Step: 326/938, Loss: 0.0891578197479248\n",
            "Epoch: 7/10, Step: 327/938, Loss: 0.0007735575782135129\n",
            "Epoch: 7/10, Step: 328/938, Loss: 0.0009360056719742715\n",
            "Epoch: 7/10, Step: 329/938, Loss: 0.005816232413053513\n",
            "Epoch: 7/10, Step: 330/938, Loss: 0.0002730507403612137\n",
            "Epoch: 7/10, Step: 331/938, Loss: 5.350665742298588e-05\n",
            "Epoch: 7/10, Step: 332/938, Loss: 0.00011645996710285544\n",
            "Epoch: 7/10, Step: 333/938, Loss: 0.018426179885864258\n",
            "Epoch: 7/10, Step: 334/938, Loss: 0.004622605163604021\n",
            "Epoch: 7/10, Step: 335/938, Loss: 0.0030832928605377674\n",
            "Epoch: 7/10, Step: 336/938, Loss: 0.004589293152093887\n",
            "Epoch: 7/10, Step: 337/938, Loss: 0.001154511235654354\n",
            "Epoch: 7/10, Step: 338/938, Loss: 0.00027843270800076425\n",
            "Epoch: 7/10, Step: 339/938, Loss: 0.0011332614812999964\n",
            "Epoch: 7/10, Step: 340/938, Loss: 0.00025835289852693677\n",
            "Epoch: 7/10, Step: 341/938, Loss: 0.002533934311941266\n",
            "Epoch: 7/10, Step: 342/938, Loss: 0.09265504032373428\n",
            "Epoch: 7/10, Step: 343/938, Loss: 0.0004769022052641958\n",
            "Epoch: 7/10, Step: 344/938, Loss: 2.558067899371963e-05\n",
            "Epoch: 7/10, Step: 345/938, Loss: 0.01421318482607603\n",
            "Epoch: 7/10, Step: 346/938, Loss: 4.477072070585564e-05\n",
            "Epoch: 7/10, Step: 347/938, Loss: 0.0028412360697984695\n",
            "Epoch: 7/10, Step: 348/938, Loss: 0.00213537085801363\n",
            "Epoch: 7/10, Step: 349/938, Loss: 0.001320935902185738\n",
            "Epoch: 7/10, Step: 350/938, Loss: 0.00037919520400464535\n",
            "Epoch: 7/10, Step: 351/938, Loss: 0.0016851247055456042\n",
            "Epoch: 7/10, Step: 352/938, Loss: 0.0004152815672568977\n",
            "Epoch: 7/10, Step: 353/938, Loss: 0.0001044844466377981\n",
            "Epoch: 7/10, Step: 354/938, Loss: 0.027656463906168938\n",
            "Epoch: 7/10, Step: 355/938, Loss: 0.006136339157819748\n",
            "Epoch: 7/10, Step: 356/938, Loss: 0.004916456062346697\n",
            "Epoch: 7/10, Step: 357/938, Loss: 0.00884025078266859\n",
            "Epoch: 7/10, Step: 358/938, Loss: 0.043542031198740005\n",
            "Epoch: 7/10, Step: 359/938, Loss: 0.0011433307081460953\n",
            "Epoch: 7/10, Step: 360/938, Loss: 0.01112756785005331\n",
            "Epoch: 7/10, Step: 361/938, Loss: 2.368518107687123e-05\n",
            "Epoch: 7/10, Step: 362/938, Loss: 0.013355739414691925\n",
            "Epoch: 7/10, Step: 363/938, Loss: 0.005071311257779598\n",
            "Epoch: 7/10, Step: 364/938, Loss: 0.0018637587781995535\n",
            "Epoch: 7/10, Step: 365/938, Loss: 0.001017061760649085\n",
            "Epoch: 7/10, Step: 366/938, Loss: 0.00016248955216724426\n",
            "Epoch: 7/10, Step: 367/938, Loss: 0.00039645726792514324\n",
            "Epoch: 7/10, Step: 368/938, Loss: 0.005807666108012199\n",
            "Epoch: 7/10, Step: 369/938, Loss: 5.761168722528964e-05\n",
            "Epoch: 7/10, Step: 370/938, Loss: 0.0025328733026981354\n",
            "Epoch: 7/10, Step: 371/938, Loss: 5.2253537432989106e-05\n",
            "Epoch: 7/10, Step: 372/938, Loss: 0.004013788886368275\n",
            "Epoch: 7/10, Step: 373/938, Loss: 0.000616519246250391\n",
            "Epoch: 7/10, Step: 374/938, Loss: 0.0003775165823753923\n",
            "Epoch: 7/10, Step: 375/938, Loss: 8.362549124285579e-05\n",
            "Epoch: 7/10, Step: 376/938, Loss: 0.0003847656771540642\n",
            "Epoch: 7/10, Step: 377/938, Loss: 0.04203597456216812\n",
            "Epoch: 7/10, Step: 378/938, Loss: 0.0006611816352233291\n",
            "Epoch: 7/10, Step: 379/938, Loss: 0.002443878212943673\n",
            "Epoch: 7/10, Step: 380/938, Loss: 0.00012166312080807984\n",
            "Epoch: 7/10, Step: 381/938, Loss: 0.00010103410022566095\n",
            "Epoch: 7/10, Step: 382/938, Loss: 0.0002101590798702091\n",
            "Epoch: 7/10, Step: 383/938, Loss: 0.002164128003641963\n",
            "Epoch: 7/10, Step: 384/938, Loss: 0.005136491265147924\n",
            "Epoch: 7/10, Step: 385/938, Loss: 0.0017004386754706502\n",
            "Epoch: 7/10, Step: 386/938, Loss: 0.00024395069340243936\n",
            "Epoch: 7/10, Step: 387/938, Loss: 0.0002122488949680701\n",
            "Epoch: 7/10, Step: 388/938, Loss: 0.0001629687612876296\n",
            "Epoch: 7/10, Step: 389/938, Loss: 0.0011263233609497547\n",
            "Epoch: 7/10, Step: 390/938, Loss: 0.001408724463544786\n",
            "Epoch: 7/10, Step: 391/938, Loss: 0.0009477042476646602\n",
            "Epoch: 7/10, Step: 392/938, Loss: 0.0006046409253031015\n",
            "Epoch: 7/10, Step: 393/938, Loss: 0.0076225255616009235\n",
            "Epoch: 7/10, Step: 394/938, Loss: 0.0006960330065339804\n",
            "Epoch: 7/10, Step: 395/938, Loss: 0.006557399407029152\n",
            "Epoch: 7/10, Step: 396/938, Loss: 0.09691912680864334\n",
            "Epoch: 7/10, Step: 397/938, Loss: 0.10505174100399017\n",
            "Epoch: 7/10, Step: 398/938, Loss: 0.0005292000132612884\n",
            "Epoch: 7/10, Step: 399/938, Loss: 0.07254957407712936\n",
            "Epoch: 7/10, Step: 400/938, Loss: 0.00016274662630166858\n",
            "Epoch: 7/10, Step: 401/938, Loss: 0.012322843074798584\n",
            "Epoch: 7/10, Step: 402/938, Loss: 4.262595030013472e-05\n",
            "Epoch: 7/10, Step: 403/938, Loss: 4.315738988225348e-05\n",
            "Epoch: 7/10, Step: 404/938, Loss: 0.011790153570473194\n",
            "Epoch: 7/10, Step: 405/938, Loss: 0.013887085020542145\n",
            "Epoch: 7/10, Step: 406/938, Loss: 4.16974289692007e-05\n",
            "Epoch: 7/10, Step: 407/938, Loss: 0.12647278606891632\n",
            "Epoch: 7/10, Step: 408/938, Loss: 0.0021270508877933025\n",
            "Epoch: 7/10, Step: 409/938, Loss: 0.00024187419330701232\n",
            "Epoch: 7/10, Step: 410/938, Loss: 0.006289700977504253\n",
            "Epoch: 7/10, Step: 411/938, Loss: 0.0009438665583729744\n",
            "Epoch: 7/10, Step: 412/938, Loss: 0.0010049022966995835\n",
            "Epoch: 7/10, Step: 413/938, Loss: 0.08617119491100311\n",
            "Epoch: 7/10, Step: 414/938, Loss: 0.0006453492096625268\n",
            "Epoch: 7/10, Step: 415/938, Loss: 0.005351250059902668\n",
            "Epoch: 7/10, Step: 416/938, Loss: 0.000758531445171684\n",
            "Epoch: 7/10, Step: 417/938, Loss: 0.0009732424514368176\n",
            "Epoch: 7/10, Step: 418/938, Loss: 0.0041600544936954975\n",
            "Epoch: 7/10, Step: 419/938, Loss: 0.05111558362841606\n",
            "Epoch: 7/10, Step: 420/938, Loss: 0.0008479626849293709\n",
            "Epoch: 7/10, Step: 421/938, Loss: 0.03597584366798401\n",
            "Epoch: 7/10, Step: 422/938, Loss: 0.0016068827826529741\n",
            "Epoch: 7/10, Step: 423/938, Loss: 0.005722196772694588\n",
            "Epoch: 7/10, Step: 424/938, Loss: 0.012961751781404018\n",
            "Epoch: 7/10, Step: 425/938, Loss: 0.00035214671515859663\n",
            "Epoch: 7/10, Step: 426/938, Loss: 0.16311223804950714\n",
            "Epoch: 7/10, Step: 427/938, Loss: 0.00016175306518562138\n",
            "Epoch: 7/10, Step: 428/938, Loss: 0.016111811622977257\n",
            "Epoch: 7/10, Step: 429/938, Loss: 0.0053876168094575405\n",
            "Epoch: 7/10, Step: 430/938, Loss: 0.05580319091677666\n",
            "Epoch: 7/10, Step: 431/938, Loss: 0.007644685450941324\n",
            "Epoch: 7/10, Step: 432/938, Loss: 0.0009410872589796782\n",
            "Epoch: 7/10, Step: 433/938, Loss: 0.00011217979044886306\n",
            "Epoch: 7/10, Step: 434/938, Loss: 0.03879433497786522\n",
            "Epoch: 7/10, Step: 435/938, Loss: 0.0042487503960728645\n",
            "Epoch: 7/10, Step: 436/938, Loss: 0.055652718991041183\n",
            "Epoch: 7/10, Step: 437/938, Loss: 3.760938852792606e-05\n",
            "Epoch: 7/10, Step: 438/938, Loss: 0.01797793246805668\n",
            "Epoch: 7/10, Step: 439/938, Loss: 0.0024433103390038013\n",
            "Epoch: 7/10, Step: 440/938, Loss: 0.08546353876590729\n",
            "Epoch: 7/10, Step: 441/938, Loss: 0.00020859747019130737\n",
            "Epoch: 7/10, Step: 442/938, Loss: 0.028444204479455948\n",
            "Epoch: 7/10, Step: 443/938, Loss: 0.0025644954293966293\n",
            "Epoch: 7/10, Step: 444/938, Loss: 9.644125384511426e-05\n",
            "Epoch: 7/10, Step: 445/938, Loss: 0.0024185252841562033\n",
            "Epoch: 7/10, Step: 446/938, Loss: 0.005718165542930365\n",
            "Epoch: 7/10, Step: 447/938, Loss: 0.00185866910032928\n",
            "Epoch: 7/10, Step: 448/938, Loss: 0.0023175838869065046\n",
            "Epoch: 7/10, Step: 449/938, Loss: 0.00137202104087919\n",
            "Epoch: 7/10, Step: 450/938, Loss: 9.283881809096783e-05\n",
            "Epoch: 7/10, Step: 451/938, Loss: 0.0002651322865858674\n",
            "Epoch: 7/10, Step: 452/938, Loss: 0.0011269141687080264\n",
            "Epoch: 7/10, Step: 453/938, Loss: 0.0005165399634279311\n",
            "Epoch: 7/10, Step: 454/938, Loss: 0.02440273016691208\n",
            "Epoch: 7/10, Step: 455/938, Loss: 8.765819802647457e-05\n",
            "Epoch: 7/10, Step: 456/938, Loss: 0.019455013796687126\n",
            "Epoch: 7/10, Step: 457/938, Loss: 0.00016348896315321326\n",
            "Epoch: 7/10, Step: 458/938, Loss: 0.022608382627367973\n",
            "Epoch: 7/10, Step: 459/938, Loss: 0.001433553290553391\n",
            "Epoch: 7/10, Step: 460/938, Loss: 0.028896525502204895\n",
            "Epoch: 7/10, Step: 461/938, Loss: 0.0004377982404548675\n",
            "Epoch: 7/10, Step: 462/938, Loss: 0.0006032370147295296\n",
            "Epoch: 7/10, Step: 463/938, Loss: 0.000554857193492353\n",
            "Epoch: 7/10, Step: 464/938, Loss: 0.00012384566070977598\n",
            "Epoch: 7/10, Step: 465/938, Loss: 0.003148693358525634\n",
            "Epoch: 7/10, Step: 466/938, Loss: 0.0013585329288616776\n",
            "Epoch: 7/10, Step: 467/938, Loss: 0.01347673311829567\n",
            "Epoch: 7/10, Step: 468/938, Loss: 0.006410410162061453\n",
            "Epoch: 7/10, Step: 469/938, Loss: 0.00038263489841483533\n",
            "Epoch: 7/10, Step: 470/938, Loss: 0.0034638994839042425\n",
            "Epoch: 7/10, Step: 471/938, Loss: 0.0018173189600929618\n",
            "Epoch: 7/10, Step: 472/938, Loss: 0.0011784586822614074\n",
            "Epoch: 7/10, Step: 473/938, Loss: 0.0035319840535521507\n",
            "Epoch: 7/10, Step: 474/938, Loss: 0.022520046681165695\n",
            "Epoch: 7/10, Step: 475/938, Loss: 0.0016943342052400112\n",
            "Epoch: 7/10, Step: 476/938, Loss: 0.00010552754974924028\n",
            "Epoch: 7/10, Step: 477/938, Loss: 0.001400534063577652\n",
            "Epoch: 7/10, Step: 478/938, Loss: 0.009966155514121056\n",
            "Epoch: 7/10, Step: 479/938, Loss: 0.0016899025067687035\n",
            "Epoch: 7/10, Step: 480/938, Loss: 0.0032115746289491653\n",
            "Epoch: 7/10, Step: 481/938, Loss: 0.000615007127635181\n",
            "Epoch: 7/10, Step: 482/938, Loss: 6.629893323406577e-05\n",
            "Epoch: 7/10, Step: 483/938, Loss: 0.016339844092726707\n",
            "Epoch: 7/10, Step: 484/938, Loss: 0.0009052727837115526\n",
            "Epoch: 7/10, Step: 485/938, Loss: 0.003220475511625409\n",
            "Epoch: 7/10, Step: 486/938, Loss: 0.00014139633276499808\n",
            "Epoch: 7/10, Step: 487/938, Loss: 0.00046014381223358214\n",
            "Epoch: 7/10, Step: 488/938, Loss: 0.00012825988233089447\n",
            "Epoch: 7/10, Step: 489/938, Loss: 0.014623446390032768\n",
            "Epoch: 7/10, Step: 490/938, Loss: 0.015677478164434433\n",
            "Epoch: 7/10, Step: 491/938, Loss: 0.0008751987479627132\n",
            "Epoch: 7/10, Step: 492/938, Loss: 0.04489091783761978\n",
            "Epoch: 7/10, Step: 493/938, Loss: 0.0044276476837694645\n",
            "Epoch: 7/10, Step: 494/938, Loss: 0.0017345871310681105\n",
            "Epoch: 7/10, Step: 495/938, Loss: 0.0009051549714058638\n",
            "Epoch: 7/10, Step: 496/938, Loss: 0.0020159815903753042\n",
            "Epoch: 7/10, Step: 497/938, Loss: 0.00022745052410755306\n",
            "Epoch: 7/10, Step: 498/938, Loss: 0.00045802892418578267\n",
            "Epoch: 7/10, Step: 499/938, Loss: 0.012074966914951801\n",
            "Epoch: 7/10, Step: 500/938, Loss: 0.0009702026145532727\n",
            "Epoch: 7/10, Step: 501/938, Loss: 0.06814777106046677\n",
            "Epoch: 7/10, Step: 502/938, Loss: 0.03892634063959122\n",
            "Epoch: 7/10, Step: 503/938, Loss: 0.000673219095915556\n",
            "Epoch: 7/10, Step: 504/938, Loss: 0.0036169521044939756\n",
            "Epoch: 7/10, Step: 505/938, Loss: 0.0014884071424603462\n",
            "Epoch: 7/10, Step: 506/938, Loss: 0.0006658837082795799\n",
            "Epoch: 7/10, Step: 507/938, Loss: 0.0417703278362751\n",
            "Epoch: 7/10, Step: 508/938, Loss: 0.004769043531268835\n",
            "Epoch: 7/10, Step: 509/938, Loss: 0.014711604453623295\n",
            "Epoch: 7/10, Step: 510/938, Loss: 0.0001998976367758587\n",
            "Epoch: 7/10, Step: 511/938, Loss: 0.00011456196079961956\n",
            "Epoch: 7/10, Step: 512/938, Loss: 9.352042252430692e-05\n",
            "Epoch: 7/10, Step: 513/938, Loss: 0.0015909461071714759\n",
            "Epoch: 7/10, Step: 514/938, Loss: 0.0001544473780086264\n",
            "Epoch: 7/10, Step: 515/938, Loss: 0.02881288155913353\n",
            "Epoch: 7/10, Step: 516/938, Loss: 0.003054329426959157\n",
            "Epoch: 7/10, Step: 517/938, Loss: 0.0009290962480008602\n",
            "Epoch: 7/10, Step: 518/938, Loss: 0.021469183266162872\n",
            "Epoch: 7/10, Step: 519/938, Loss: 0.0001439627376385033\n",
            "Epoch: 7/10, Step: 520/938, Loss: 0.10006135702133179\n",
            "Epoch: 7/10, Step: 521/938, Loss: 0.02675134874880314\n",
            "Epoch: 7/10, Step: 522/938, Loss: 0.005869755055755377\n",
            "Epoch: 7/10, Step: 523/938, Loss: 0.0011057783849537373\n",
            "Epoch: 7/10, Step: 524/938, Loss: 0.0007515564793720841\n",
            "Epoch: 7/10, Step: 525/938, Loss: 2.963454790005926e-05\n",
            "Epoch: 7/10, Step: 526/938, Loss: 0.00011114514927612618\n",
            "Epoch: 7/10, Step: 527/938, Loss: 0.105887271463871\n",
            "Epoch: 7/10, Step: 528/938, Loss: 0.0025078325998038054\n",
            "Epoch: 7/10, Step: 529/938, Loss: 0.0006508190999738872\n",
            "Epoch: 7/10, Step: 530/938, Loss: 7.82999413786456e-05\n",
            "Epoch: 7/10, Step: 531/938, Loss: 0.005607919301837683\n",
            "Epoch: 7/10, Step: 532/938, Loss: 0.06363940984010696\n",
            "Epoch: 7/10, Step: 533/938, Loss: 3.7606914702337235e-05\n",
            "Epoch: 7/10, Step: 534/938, Loss: 0.0185049120336771\n",
            "Epoch: 7/10, Step: 535/938, Loss: 0.05510858818888664\n",
            "Epoch: 7/10, Step: 536/938, Loss: 0.0014607396442443132\n",
            "Epoch: 7/10, Step: 537/938, Loss: 4.418354728841223e-05\n",
            "Epoch: 7/10, Step: 538/938, Loss: 0.0023767431266605854\n",
            "Epoch: 7/10, Step: 539/938, Loss: 0.0003393162041902542\n",
            "Epoch: 7/10, Step: 540/938, Loss: 0.006532005500048399\n",
            "Epoch: 7/10, Step: 541/938, Loss: 0.0026044456753879786\n",
            "Epoch: 7/10, Step: 542/938, Loss: 0.08527126908302307\n",
            "Epoch: 7/10, Step: 543/938, Loss: 0.12204015254974365\n",
            "Epoch: 7/10, Step: 544/938, Loss: 0.05241039767861366\n",
            "Epoch: 7/10, Step: 545/938, Loss: 0.013229909352958202\n",
            "Epoch: 7/10, Step: 546/938, Loss: 0.001075392123311758\n",
            "Epoch: 7/10, Step: 547/938, Loss: 0.00011042349797207862\n",
            "Epoch: 7/10, Step: 548/938, Loss: 0.014430742710828781\n",
            "Epoch: 7/10, Step: 549/938, Loss: 0.0028401659801602364\n",
            "Epoch: 7/10, Step: 550/938, Loss: 3.5705732443602756e-05\n",
            "Epoch: 7/10, Step: 551/938, Loss: 0.0009940816089510918\n",
            "Epoch: 7/10, Step: 552/938, Loss: 0.0021445294842123985\n",
            "Epoch: 7/10, Step: 553/938, Loss: 0.0006595303420908749\n",
            "Epoch: 7/10, Step: 554/938, Loss: 0.053945042192935944\n",
            "Epoch: 7/10, Step: 555/938, Loss: 0.0001687787880655378\n",
            "Epoch: 7/10, Step: 556/938, Loss: 0.008275858126580715\n",
            "Epoch: 7/10, Step: 557/938, Loss: 0.055851154029369354\n",
            "Epoch: 7/10, Step: 558/938, Loss: 0.06650066375732422\n",
            "Epoch: 7/10, Step: 559/938, Loss: 0.0073339310474693775\n",
            "Epoch: 7/10, Step: 560/938, Loss: 0.0081662368029356\n",
            "Epoch: 7/10, Step: 561/938, Loss: 0.027994170784950256\n",
            "Epoch: 7/10, Step: 562/938, Loss: 0.022838953882455826\n",
            "Epoch: 7/10, Step: 563/938, Loss: 0.05286315083503723\n",
            "Epoch: 7/10, Step: 564/938, Loss: 0.00020538260287139565\n",
            "Epoch: 7/10, Step: 565/938, Loss: 0.01140310987830162\n",
            "Epoch: 7/10, Step: 566/938, Loss: 0.00154799351003021\n",
            "Epoch: 7/10, Step: 567/938, Loss: 0.000180765928234905\n",
            "Epoch: 7/10, Step: 568/938, Loss: 0.00026788839022628963\n",
            "Epoch: 7/10, Step: 569/938, Loss: 0.0003687407588586211\n",
            "Epoch: 7/10, Step: 570/938, Loss: 0.00147729879245162\n",
            "Epoch: 7/10, Step: 571/938, Loss: 0.0003294666239526123\n",
            "Epoch: 7/10, Step: 572/938, Loss: 0.00033524009631946683\n",
            "Epoch: 7/10, Step: 573/938, Loss: 0.015663016587495804\n",
            "Epoch: 7/10, Step: 574/938, Loss: 7.613565685460344e-05\n",
            "Epoch: 7/10, Step: 575/938, Loss: 0.0013445308431982994\n",
            "Epoch: 7/10, Step: 576/938, Loss: 9.268693247577175e-05\n",
            "Epoch: 7/10, Step: 577/938, Loss: 0.0007210254552774131\n",
            "Epoch: 7/10, Step: 578/938, Loss: 0.1310024857521057\n",
            "Epoch: 7/10, Step: 579/938, Loss: 9.910827793646604e-05\n",
            "Epoch: 7/10, Step: 580/938, Loss: 0.0029919149819761515\n",
            "Epoch: 7/10, Step: 581/938, Loss: 0.01264273002743721\n",
            "Epoch: 7/10, Step: 582/938, Loss: 0.02610367350280285\n",
            "Epoch: 7/10, Step: 583/938, Loss: 0.001864322810433805\n",
            "Epoch: 7/10, Step: 584/938, Loss: 4.001944398623891e-05\n",
            "Epoch: 7/10, Step: 585/938, Loss: 4.126022759010084e-05\n",
            "Epoch: 7/10, Step: 586/938, Loss: 0.012602120637893677\n",
            "Epoch: 7/10, Step: 587/938, Loss: 0.014175884425640106\n",
            "Epoch: 7/10, Step: 588/938, Loss: 0.08990461379289627\n",
            "Epoch: 7/10, Step: 589/938, Loss: 0.0007215323275886476\n",
            "Epoch: 7/10, Step: 590/938, Loss: 0.0024189595133066177\n",
            "Epoch: 7/10, Step: 591/938, Loss: 0.0014953522477298975\n",
            "Epoch: 7/10, Step: 592/938, Loss: 0.0008048596791923046\n",
            "Epoch: 7/10, Step: 593/938, Loss: 0.010201433673501015\n",
            "Epoch: 7/10, Step: 594/938, Loss: 0.006398989353328943\n",
            "Epoch: 7/10, Step: 595/938, Loss: 0.0009301395621150732\n",
            "Epoch: 7/10, Step: 596/938, Loss: 0.0008201681775972247\n",
            "Epoch: 7/10, Step: 597/938, Loss: 0.001666738884523511\n",
            "Epoch: 7/10, Step: 598/938, Loss: 0.000470698723802343\n",
            "Epoch: 7/10, Step: 599/938, Loss: 0.008548100478947163\n",
            "Epoch: 7/10, Step: 600/938, Loss: 0.0012797184754163027\n",
            "Epoch: 7/10, Step: 601/938, Loss: 0.005021126940846443\n",
            "Epoch: 7/10, Step: 602/938, Loss: 0.004076709505170584\n",
            "Epoch: 7/10, Step: 603/938, Loss: 9.805255103856325e-05\n",
            "Epoch: 7/10, Step: 604/938, Loss: 0.00041999807581305504\n",
            "Epoch: 7/10, Step: 605/938, Loss: 0.0001802584301913157\n",
            "Epoch: 7/10, Step: 606/938, Loss: 0.02163776569068432\n",
            "Epoch: 7/10, Step: 607/938, Loss: 0.003587326966226101\n",
            "Epoch: 7/10, Step: 608/938, Loss: 6.5558087953832e-05\n",
            "Epoch: 7/10, Step: 609/938, Loss: 0.00010059592023026198\n",
            "Epoch: 7/10, Step: 610/938, Loss: 0.00029275883571244776\n",
            "Epoch: 7/10, Step: 611/938, Loss: 0.049277789890766144\n",
            "Epoch: 7/10, Step: 612/938, Loss: 0.0005880496464669704\n",
            "Epoch: 7/10, Step: 613/938, Loss: 4.722840094473213e-05\n",
            "Epoch: 7/10, Step: 614/938, Loss: 0.0009366506128571928\n",
            "Epoch: 7/10, Step: 615/938, Loss: 1.892688851512503e-05\n",
            "Epoch: 7/10, Step: 616/938, Loss: 0.0005890160100534558\n",
            "Epoch: 7/10, Step: 617/938, Loss: 3.7817779229953885e-05\n",
            "Epoch: 7/10, Step: 618/938, Loss: 0.0010313098318874836\n",
            "Epoch: 7/10, Step: 619/938, Loss: 0.010667015798389912\n",
            "Epoch: 7/10, Step: 620/938, Loss: 0.010119777172803879\n",
            "Epoch: 7/10, Step: 621/938, Loss: 5.621084710583091e-05\n",
            "Epoch: 7/10, Step: 622/938, Loss: 0.00011304319923510775\n",
            "Epoch: 7/10, Step: 623/938, Loss: 7.088735856086714e-06\n",
            "Epoch: 7/10, Step: 624/938, Loss: 0.0002897516533266753\n",
            "Epoch: 7/10, Step: 625/938, Loss: 0.0017500746762380004\n",
            "Epoch: 7/10, Step: 626/938, Loss: 0.0002778305788524449\n",
            "Epoch: 7/10, Step: 627/938, Loss: 0.005958524066954851\n",
            "Epoch: 7/10, Step: 628/938, Loss: 1.1281108527327888e-05\n",
            "Epoch: 7/10, Step: 629/938, Loss: 0.00015587340749334544\n",
            "Epoch: 7/10, Step: 630/938, Loss: 0.0012767023872584105\n",
            "Epoch: 7/10, Step: 631/938, Loss: 0.001664209645241499\n",
            "Epoch: 7/10, Step: 632/938, Loss: 0.000600101426243782\n",
            "Epoch: 7/10, Step: 633/938, Loss: 0.0036383653059601784\n",
            "Epoch: 7/10, Step: 634/938, Loss: 0.00017483223928138614\n",
            "Epoch: 7/10, Step: 635/938, Loss: 0.021062545478343964\n",
            "Epoch: 7/10, Step: 636/938, Loss: 0.002635989338159561\n",
            "Epoch: 7/10, Step: 637/938, Loss: 0.0010822524782270193\n",
            "Epoch: 7/10, Step: 638/938, Loss: 0.0027046063914895058\n",
            "Epoch: 7/10, Step: 639/938, Loss: 0.00818911474198103\n",
            "Epoch: 7/10, Step: 640/938, Loss: 0.005219829268753529\n",
            "Epoch: 7/10, Step: 641/938, Loss: 0.000248379452386871\n",
            "Epoch: 7/10, Step: 642/938, Loss: 0.0011677127331495285\n",
            "Epoch: 7/10, Step: 643/938, Loss: 0.021458134055137634\n",
            "Epoch: 7/10, Step: 644/938, Loss: 0.0005589670035988092\n",
            "Epoch: 7/10, Step: 645/938, Loss: 0.015361074358224869\n",
            "Epoch: 7/10, Step: 646/938, Loss: 0.0021032074000686407\n",
            "Epoch: 7/10, Step: 647/938, Loss: 0.01386644970625639\n",
            "Epoch: 7/10, Step: 648/938, Loss: 0.0003299923846498132\n",
            "Epoch: 7/10, Step: 649/938, Loss: 0.003054100787267089\n",
            "Epoch: 7/10, Step: 650/938, Loss: 0.0001346415519947186\n",
            "Epoch: 7/10, Step: 651/938, Loss: 0.09038154035806656\n",
            "Epoch: 7/10, Step: 652/938, Loss: 0.0010941190412268043\n",
            "Epoch: 7/10, Step: 653/938, Loss: 0.0011655638227239251\n",
            "Epoch: 7/10, Step: 654/938, Loss: 0.0016900573391467333\n",
            "Epoch: 7/10, Step: 655/938, Loss: 5.9775178669951856e-05\n",
            "Epoch: 7/10, Step: 656/938, Loss: 0.00028082303470000625\n",
            "Epoch: 7/10, Step: 657/938, Loss: 0.012155954726040363\n",
            "Epoch: 7/10, Step: 658/938, Loss: 0.02261223830282688\n",
            "Epoch: 7/10, Step: 659/938, Loss: 0.0076187714003026485\n",
            "Epoch: 7/10, Step: 660/938, Loss: 0.006231328006833792\n",
            "Epoch: 7/10, Step: 661/938, Loss: 0.0027683675289154053\n",
            "Epoch: 7/10, Step: 662/938, Loss: 0.0014708621893078089\n",
            "Epoch: 7/10, Step: 663/938, Loss: 0.004004241898655891\n",
            "Epoch: 7/10, Step: 664/938, Loss: 0.0034986475948244333\n",
            "Epoch: 7/10, Step: 665/938, Loss: 0.0011482668342068791\n",
            "Epoch: 7/10, Step: 666/938, Loss: 0.004776167683303356\n",
            "Epoch: 7/10, Step: 667/938, Loss: 0.03445044532418251\n",
            "Epoch: 7/10, Step: 668/938, Loss: 0.0002319886116310954\n",
            "Epoch: 7/10, Step: 669/938, Loss: 0.03307604044675827\n",
            "Epoch: 7/10, Step: 670/938, Loss: 0.08100154995918274\n",
            "Epoch: 7/10, Step: 671/938, Loss: 0.04166453704237938\n",
            "Epoch: 7/10, Step: 672/938, Loss: 0.00020020417287014425\n",
            "Epoch: 7/10, Step: 673/938, Loss: 0.0006919099832884967\n",
            "Epoch: 7/10, Step: 674/938, Loss: 0.0016487649409100413\n",
            "Epoch: 7/10, Step: 675/938, Loss: 0.027803469449281693\n",
            "Epoch: 7/10, Step: 676/938, Loss: 0.0013237247476354241\n",
            "Epoch: 7/10, Step: 677/938, Loss: 3.2171235943678766e-05\n",
            "Epoch: 7/10, Step: 678/938, Loss: 0.013776003383100033\n",
            "Epoch: 7/10, Step: 679/938, Loss: 0.0003091139951720834\n",
            "Epoch: 7/10, Step: 680/938, Loss: 0.0028127601835876703\n",
            "Epoch: 7/10, Step: 681/938, Loss: 7.897839532233775e-05\n",
            "Epoch: 7/10, Step: 682/938, Loss: 0.03433999419212341\n",
            "Epoch: 7/10, Step: 683/938, Loss: 0.004710799548774958\n",
            "Epoch: 7/10, Step: 684/938, Loss: 4.553758481051773e-05\n",
            "Epoch: 7/10, Step: 685/938, Loss: 0.002069904003292322\n",
            "Epoch: 7/10, Step: 686/938, Loss: 0.0020035880152136087\n",
            "Epoch: 7/10, Step: 687/938, Loss: 0.0017953235656023026\n",
            "Epoch: 7/10, Step: 688/938, Loss: 0.00030783688998781145\n",
            "Epoch: 7/10, Step: 689/938, Loss: 0.011143045499920845\n",
            "Epoch: 7/10, Step: 690/938, Loss: 0.0004905678215436637\n",
            "Epoch: 7/10, Step: 691/938, Loss: 0.003165661823004484\n",
            "Epoch: 7/10, Step: 692/938, Loss: 0.013447965495288372\n",
            "Epoch: 7/10, Step: 693/938, Loss: 0.0879165381193161\n",
            "Epoch: 7/10, Step: 694/938, Loss: 0.00014962871500756592\n",
            "Epoch: 7/10, Step: 695/938, Loss: 0.0034737358801066875\n",
            "Epoch: 7/10, Step: 696/938, Loss: 0.006987304892390966\n",
            "Epoch: 7/10, Step: 697/938, Loss: 0.0031564540695399046\n",
            "Epoch: 7/10, Step: 698/938, Loss: 0.0006920004962012172\n",
            "Epoch: 7/10, Step: 699/938, Loss: 0.008004617877304554\n",
            "Epoch: 7/10, Step: 700/938, Loss: 0.00315657164901495\n",
            "Epoch: 7/10, Step: 701/938, Loss: 0.005786880850791931\n",
            "Epoch: 7/10, Step: 702/938, Loss: 0.04833989217877388\n",
            "Epoch: 7/10, Step: 703/938, Loss: 0.00013940744975116104\n",
            "Epoch: 7/10, Step: 704/938, Loss: 8.368157432414591e-05\n",
            "Epoch: 7/10, Step: 705/938, Loss: 8.463943959213793e-05\n",
            "Epoch: 7/10, Step: 706/938, Loss: 0.0001953220198629424\n",
            "Epoch: 7/10, Step: 707/938, Loss: 0.000927935354411602\n",
            "Epoch: 7/10, Step: 708/938, Loss: 0.0005097881658002734\n",
            "Epoch: 7/10, Step: 709/938, Loss: 0.03792653977870941\n",
            "Epoch: 7/10, Step: 710/938, Loss: 0.0031566626857966185\n",
            "Epoch: 7/10, Step: 711/938, Loss: 0.00014457630459219217\n",
            "Epoch: 7/10, Step: 712/938, Loss: 0.0014733144780620933\n",
            "Epoch: 7/10, Step: 713/938, Loss: 0.008198969066143036\n",
            "Epoch: 7/10, Step: 714/938, Loss: 0.0002119018172379583\n",
            "Epoch: 7/10, Step: 715/938, Loss: 1.3197732187109068e-05\n",
            "Epoch: 7/10, Step: 716/938, Loss: 0.002230920596048236\n",
            "Epoch: 7/10, Step: 717/938, Loss: 0.0279984250664711\n",
            "Epoch: 7/10, Step: 718/938, Loss: 0.0008174799149855971\n",
            "Epoch: 7/10, Step: 719/938, Loss: 0.0048132361844182014\n",
            "Epoch: 7/10, Step: 720/938, Loss: 0.006095316726714373\n",
            "Epoch: 7/10, Step: 721/938, Loss: 0.07669822871685028\n",
            "Epoch: 7/10, Step: 722/938, Loss: 0.02326318249106407\n",
            "Epoch: 7/10, Step: 723/938, Loss: 0.0015957978321239352\n",
            "Epoch: 7/10, Step: 724/938, Loss: 0.023911742493510246\n",
            "Epoch: 7/10, Step: 725/938, Loss: 0.004535903688520193\n",
            "Epoch: 7/10, Step: 726/938, Loss: 0.0014355550520122051\n",
            "Epoch: 7/10, Step: 727/938, Loss: 0.0002698466705624014\n",
            "Epoch: 7/10, Step: 728/938, Loss: 0.0005390772130340338\n",
            "Epoch: 7/10, Step: 729/938, Loss: 0.0006313594640232623\n",
            "Epoch: 7/10, Step: 730/938, Loss: 3.2211642974289134e-05\n",
            "Epoch: 7/10, Step: 731/938, Loss: 0.0006669212016277015\n",
            "Epoch: 7/10, Step: 732/938, Loss: 9.28454683162272e-05\n",
            "Epoch: 7/10, Step: 733/938, Loss: 0.0026565606240183115\n",
            "Epoch: 7/10, Step: 734/938, Loss: 0.006104668136686087\n",
            "Epoch: 7/10, Step: 735/938, Loss: 0.011027631349861622\n",
            "Epoch: 7/10, Step: 736/938, Loss: 0.0018274805042892694\n",
            "Epoch: 7/10, Step: 737/938, Loss: 0.00737053994089365\n",
            "Epoch: 7/10, Step: 738/938, Loss: 0.02095353975892067\n",
            "Epoch: 7/10, Step: 739/938, Loss: 0.008227711543440819\n",
            "Epoch: 7/10, Step: 740/938, Loss: 0.0003491434908937663\n",
            "Epoch: 7/10, Step: 741/938, Loss: 0.10311292111873627\n",
            "Epoch: 7/10, Step: 742/938, Loss: 0.04452323541045189\n",
            "Epoch: 7/10, Step: 743/938, Loss: 0.0034262139815837145\n",
            "Epoch: 7/10, Step: 744/938, Loss: 2.1412590285763144e-05\n",
            "Epoch: 7/10, Step: 745/938, Loss: 0.001204557716846466\n",
            "Epoch: 7/10, Step: 746/938, Loss: 0.0005634760018438101\n",
            "Epoch: 7/10, Step: 747/938, Loss: 0.0016669548349455\n",
            "Epoch: 7/10, Step: 748/938, Loss: 0.00031424249755218625\n",
            "Epoch: 7/10, Step: 749/938, Loss: 0.0003161004278808832\n",
            "Epoch: 7/10, Step: 750/938, Loss: 0.0017044360283762217\n",
            "Epoch: 7/10, Step: 751/938, Loss: 0.0010731768561527133\n",
            "Epoch: 7/10, Step: 752/938, Loss: 0.04304725304245949\n",
            "Epoch: 7/10, Step: 753/938, Loss: 0.09146671742200851\n",
            "Epoch: 7/10, Step: 754/938, Loss: 0.012101919390261173\n",
            "Epoch: 7/10, Step: 755/938, Loss: 0.0015808361349627376\n",
            "Epoch: 7/10, Step: 756/938, Loss: 0.035046301782131195\n",
            "Epoch: 7/10, Step: 757/938, Loss: 0.022600403055548668\n",
            "Epoch: 7/10, Step: 758/938, Loss: 0.05617618188261986\n",
            "Epoch: 7/10, Step: 759/938, Loss: 0.06676590442657471\n",
            "Epoch: 7/10, Step: 760/938, Loss: 0.00623361999168992\n",
            "Epoch: 7/10, Step: 761/938, Loss: 0.0016968310810625553\n",
            "Epoch: 7/10, Step: 762/938, Loss: 0.0012491275556385517\n",
            "Epoch: 7/10, Step: 763/938, Loss: 0.020440489053726196\n",
            "Epoch: 7/10, Step: 764/938, Loss: 0.005248337052762508\n",
            "Epoch: 7/10, Step: 765/938, Loss: 0.00074861227767542\n",
            "Epoch: 7/10, Step: 766/938, Loss: 0.015727965161204338\n",
            "Epoch: 7/10, Step: 767/938, Loss: 0.00047245496534742415\n",
            "Epoch: 7/10, Step: 768/938, Loss: 0.00024631249834783375\n",
            "Epoch: 7/10, Step: 769/938, Loss: 0.001908273552544415\n",
            "Epoch: 7/10, Step: 770/938, Loss: 0.0005734049482271075\n",
            "Epoch: 7/10, Step: 771/938, Loss: 0.012958571314811707\n",
            "Epoch: 7/10, Step: 772/938, Loss: 0.011019030585885048\n",
            "Epoch: 7/10, Step: 773/938, Loss: 0.00494169257581234\n",
            "Epoch: 7/10, Step: 774/938, Loss: 0.00406385213136673\n",
            "Epoch: 7/10, Step: 775/938, Loss: 0.00019101041834801435\n",
            "Epoch: 7/10, Step: 776/938, Loss: 3.816391108557582e-05\n",
            "Epoch: 7/10, Step: 777/938, Loss: 5.7438774092588574e-05\n",
            "Epoch: 7/10, Step: 778/938, Loss: 0.0011571422219276428\n",
            "Epoch: 7/10, Step: 779/938, Loss: 0.0009036994306370616\n",
            "Epoch: 7/10, Step: 780/938, Loss: 1.5205464478640351e-05\n",
            "Epoch: 7/10, Step: 781/938, Loss: 0.000880013220012188\n",
            "Epoch: 7/10, Step: 782/938, Loss: 0.027522405609488487\n",
            "Epoch: 7/10, Step: 783/938, Loss: 9.532447438687086e-05\n",
            "Epoch: 7/10, Step: 784/938, Loss: 0.007725926116108894\n",
            "Epoch: 7/10, Step: 785/938, Loss: 0.0003823699080385268\n",
            "Epoch: 7/10, Step: 786/938, Loss: 0.015342837199568748\n",
            "Epoch: 7/10, Step: 787/938, Loss: 0.005288836546242237\n",
            "Epoch: 7/10, Step: 788/938, Loss: 0.02523898147046566\n",
            "Epoch: 7/10, Step: 789/938, Loss: 0.003980217967182398\n",
            "Epoch: 7/10, Step: 790/938, Loss: 0.00024445404415018857\n",
            "Epoch: 7/10, Step: 791/938, Loss: 0.10131198912858963\n",
            "Epoch: 7/10, Step: 792/938, Loss: 2.887350638047792e-05\n",
            "Epoch: 7/10, Step: 793/938, Loss: 0.002535027451813221\n",
            "Epoch: 7/10, Step: 794/938, Loss: 0.0001753583492245525\n",
            "Epoch: 7/10, Step: 795/938, Loss: 0.013087470084428787\n",
            "Epoch: 7/10, Step: 796/938, Loss: 0.0037129356060177088\n",
            "Epoch: 7/10, Step: 797/938, Loss: 0.0001665150630287826\n",
            "Epoch: 7/10, Step: 798/938, Loss: 0.0003657613415271044\n",
            "Epoch: 7/10, Step: 799/938, Loss: 7.03438272466883e-05\n",
            "Epoch: 7/10, Step: 800/938, Loss: 0.0005882075056433678\n",
            "Epoch: 7/10, Step: 801/938, Loss: 0.0010795571142807603\n",
            "Epoch: 7/10, Step: 802/938, Loss: 0.006476221606135368\n",
            "Epoch: 7/10, Step: 803/938, Loss: 0.0007439511828124523\n",
            "Epoch: 7/10, Step: 804/938, Loss: 0.020811330527067184\n",
            "Epoch: 7/10, Step: 805/938, Loss: 0.015972059220075607\n",
            "Epoch: 7/10, Step: 806/938, Loss: 7.97568864072673e-05\n",
            "Epoch: 7/10, Step: 807/938, Loss: 0.0036429769825190306\n",
            "Epoch: 7/10, Step: 808/938, Loss: 0.00037904136115685105\n",
            "Epoch: 7/10, Step: 809/938, Loss: 0.0007311698864214122\n",
            "Epoch: 7/10, Step: 810/938, Loss: 0.0007761743618175387\n",
            "Epoch: 7/10, Step: 811/938, Loss: 4.502969022723846e-05\n",
            "Epoch: 7/10, Step: 812/938, Loss: 0.00010319721332052723\n",
            "Epoch: 7/10, Step: 813/938, Loss: 0.0001120642336900346\n",
            "Epoch: 7/10, Step: 814/938, Loss: 0.007661659270524979\n",
            "Epoch: 7/10, Step: 815/938, Loss: 0.006296324543654919\n",
            "Epoch: 7/10, Step: 816/938, Loss: 0.0002453962806612253\n",
            "Epoch: 7/10, Step: 817/938, Loss: 0.0023411239963024855\n",
            "Epoch: 7/10, Step: 818/938, Loss: 0.013404112309217453\n",
            "Epoch: 7/10, Step: 819/938, Loss: 0.0003577228053472936\n",
            "Epoch: 7/10, Step: 820/938, Loss: 0.0020153671503067017\n",
            "Epoch: 7/10, Step: 821/938, Loss: 0.0019747610203921795\n",
            "Epoch: 7/10, Step: 822/938, Loss: 0.007046150043606758\n",
            "Epoch: 7/10, Step: 823/938, Loss: 2.461588883306831e-05\n",
            "Epoch: 7/10, Step: 824/938, Loss: 4.3718417146010324e-05\n",
            "Epoch: 7/10, Step: 825/938, Loss: 6.216068140929565e-05\n",
            "Epoch: 7/10, Step: 826/938, Loss: 0.051930513232946396\n",
            "Epoch: 7/10, Step: 827/938, Loss: 0.08600559085607529\n",
            "Epoch: 7/10, Step: 828/938, Loss: 0.006563534028828144\n",
            "Epoch: 7/10, Step: 829/938, Loss: 0.10818102210760117\n",
            "Epoch: 7/10, Step: 830/938, Loss: 4.914116652798839e-05\n",
            "Epoch: 7/10, Step: 831/938, Loss: 0.007561192382127047\n",
            "Epoch: 7/10, Step: 832/938, Loss: 0.031534865498542786\n",
            "Epoch: 7/10, Step: 833/938, Loss: 0.0014635853003710508\n",
            "Epoch: 7/10, Step: 834/938, Loss: 0.003480717306956649\n",
            "Epoch: 7/10, Step: 835/938, Loss: 3.082946568611078e-05\n",
            "Epoch: 7/10, Step: 836/938, Loss: 0.00015181279741227627\n",
            "Epoch: 7/10, Step: 837/938, Loss: 0.0010695535456761718\n",
            "Epoch: 7/10, Step: 838/938, Loss: 2.822082387865521e-05\n",
            "Epoch: 7/10, Step: 839/938, Loss: 0.008620241656899452\n",
            "Epoch: 7/10, Step: 840/938, Loss: 0.002198323840275407\n",
            "Epoch: 7/10, Step: 841/938, Loss: 0.002599021652713418\n",
            "Epoch: 7/10, Step: 842/938, Loss: 0.001425054739229381\n",
            "Epoch: 7/10, Step: 843/938, Loss: 0.007379164453595877\n",
            "Epoch: 7/10, Step: 844/938, Loss: 0.010804075747728348\n",
            "Epoch: 7/10, Step: 845/938, Loss: 0.056151535362005234\n",
            "Epoch: 7/10, Step: 846/938, Loss: 0.0008385287364944816\n",
            "Epoch: 7/10, Step: 847/938, Loss: 0.007336020935326815\n",
            "Epoch: 7/10, Step: 848/938, Loss: 0.0008684685453772545\n",
            "Epoch: 7/10, Step: 849/938, Loss: 3.7325749872252345e-05\n",
            "Epoch: 7/10, Step: 850/938, Loss: 0.0006368496106006205\n",
            "Epoch: 7/10, Step: 851/938, Loss: 8.902828267309815e-05\n",
            "Epoch: 7/10, Step: 852/938, Loss: 0.0007511714356951416\n",
            "Epoch: 7/10, Step: 853/938, Loss: 0.008015385828912258\n",
            "Epoch: 7/10, Step: 854/938, Loss: 0.018489917740225792\n",
            "Epoch: 7/10, Step: 855/938, Loss: 7.230428764160024e-06\n",
            "Epoch: 7/10, Step: 856/938, Loss: 0.005098159424960613\n",
            "Epoch: 7/10, Step: 857/938, Loss: 0.00012973306002095342\n",
            "Epoch: 7/10, Step: 858/938, Loss: 0.0006052713724784553\n",
            "Epoch: 7/10, Step: 859/938, Loss: 0.00017220214067492634\n",
            "Epoch: 7/10, Step: 860/938, Loss: 0.0017853432800620794\n",
            "Epoch: 7/10, Step: 861/938, Loss: 0.0026528651360422373\n",
            "Epoch: 7/10, Step: 862/938, Loss: 0.030714191496372223\n",
            "Epoch: 7/10, Step: 863/938, Loss: 4.049925701110624e-05\n",
            "Epoch: 7/10, Step: 864/938, Loss: 0.0029711900278925896\n",
            "Epoch: 7/10, Step: 865/938, Loss: 1.7093561837100424e-05\n",
            "Epoch: 7/10, Step: 866/938, Loss: 3.313662455184385e-05\n",
            "Epoch: 7/10, Step: 867/938, Loss: 5.064320066594519e-05\n",
            "Epoch: 7/10, Step: 868/938, Loss: 1.5843594155739993e-05\n",
            "Epoch: 7/10, Step: 869/938, Loss: 9.017015690915287e-05\n",
            "Epoch: 7/10, Step: 870/938, Loss: 0.006332899909466505\n",
            "Epoch: 7/10, Step: 871/938, Loss: 0.00323521182872355\n",
            "Epoch: 7/10, Step: 872/938, Loss: 0.0014244707999750972\n",
            "Epoch: 7/10, Step: 873/938, Loss: 0.05511651560664177\n",
            "Epoch: 7/10, Step: 874/938, Loss: 0.002268986776471138\n",
            "Epoch: 7/10, Step: 875/938, Loss: 5.634933040710166e-05\n",
            "Epoch: 7/10, Step: 876/938, Loss: 0.006188428495079279\n",
            "Epoch: 7/10, Step: 877/938, Loss: 0.0005648466758430004\n",
            "Epoch: 7/10, Step: 878/938, Loss: 0.0062547605484724045\n",
            "Epoch: 7/10, Step: 879/938, Loss: 0.00022520381025969982\n",
            "Epoch: 7/10, Step: 880/938, Loss: 0.001018970157019794\n",
            "Epoch: 7/10, Step: 881/938, Loss: 0.0058830371126532555\n",
            "Epoch: 7/10, Step: 882/938, Loss: 0.00021873631339985877\n",
            "Epoch: 7/10, Step: 883/938, Loss: 0.00046327305608429015\n",
            "Epoch: 7/10, Step: 884/938, Loss: 0.0033074654638767242\n",
            "Epoch: 7/10, Step: 885/938, Loss: 0.0008790717110969126\n",
            "Epoch: 7/10, Step: 886/938, Loss: 0.005807517096400261\n",
            "Epoch: 7/10, Step: 887/938, Loss: 5.990385398035869e-05\n",
            "Epoch: 7/10, Step: 888/938, Loss: 0.002907918067649007\n",
            "Epoch: 7/10, Step: 889/938, Loss: 0.00026839718339033425\n",
            "Epoch: 7/10, Step: 890/938, Loss: 0.00023726017388980836\n",
            "Epoch: 7/10, Step: 891/938, Loss: 0.00013649696484208107\n",
            "Epoch: 7/10, Step: 892/938, Loss: 0.000376007315935567\n",
            "Epoch: 7/10, Step: 893/938, Loss: 0.038018155843019485\n",
            "Epoch: 7/10, Step: 894/938, Loss: 0.009701546281576157\n",
            "Epoch: 7/10, Step: 895/938, Loss: 0.004360049031674862\n",
            "Epoch: 7/10, Step: 896/938, Loss: 0.00021264719543978572\n",
            "Epoch: 7/10, Step: 897/938, Loss: 0.00372000178322196\n",
            "Epoch: 7/10, Step: 898/938, Loss: 0.003634379943832755\n",
            "Epoch: 7/10, Step: 899/938, Loss: 0.02759900502860546\n",
            "Epoch: 7/10, Step: 900/938, Loss: 0.02462613582611084\n",
            "Epoch: 7/10, Step: 901/938, Loss: 0.00023954911739565432\n",
            "Epoch: 7/10, Step: 902/938, Loss: 0.00014224839105736464\n",
            "Epoch: 7/10, Step: 903/938, Loss: 0.0009082611068151891\n",
            "Epoch: 7/10, Step: 904/938, Loss: 0.0035364688374102116\n",
            "Epoch: 7/10, Step: 905/938, Loss: 0.00034964876249432564\n",
            "Epoch: 7/10, Step: 906/938, Loss: 0.004223760683089495\n",
            "Epoch: 7/10, Step: 907/938, Loss: 0.0009967887308448553\n",
            "Epoch: 7/10, Step: 908/938, Loss: 0.059059858322143555\n",
            "Epoch: 7/10, Step: 909/938, Loss: 0.000205817908863537\n",
            "Epoch: 7/10, Step: 910/938, Loss: 0.00037993164733052254\n",
            "Epoch: 7/10, Step: 911/938, Loss: 0.016156893223524094\n",
            "Epoch: 7/10, Step: 912/938, Loss: 0.0021026581525802612\n",
            "Epoch: 7/10, Step: 913/938, Loss: 0.004410864319652319\n",
            "Epoch: 7/10, Step: 914/938, Loss: 0.030125543475151062\n",
            "Epoch: 7/10, Step: 915/938, Loss: 0.00422541331499815\n",
            "Epoch: 7/10, Step: 916/938, Loss: 0.0025690176989883184\n",
            "Epoch: 7/10, Step: 917/938, Loss: 0.0004717549600172788\n",
            "Epoch: 7/10, Step: 918/938, Loss: 0.0007917387410998344\n",
            "Epoch: 7/10, Step: 919/938, Loss: 0.00010917177132796496\n",
            "Epoch: 7/10, Step: 920/938, Loss: 0.00022098785848356783\n",
            "Epoch: 7/10, Step: 921/938, Loss: 0.00021579733584076166\n",
            "Epoch: 7/10, Step: 922/938, Loss: 0.0014748035464435816\n",
            "Epoch: 7/10, Step: 923/938, Loss: 0.00016687657625880092\n",
            "Epoch: 7/10, Step: 924/938, Loss: 0.0002933706564363092\n",
            "Epoch: 7/10, Step: 925/938, Loss: 1.4122671927907504e-05\n",
            "Epoch: 7/10, Step: 926/938, Loss: 0.00021494795510079712\n",
            "Epoch: 7/10, Step: 927/938, Loss: 4.100686783203855e-05\n",
            "Epoch: 7/10, Step: 928/938, Loss: 0.0005653451080434024\n",
            "Epoch: 7/10, Step: 929/938, Loss: 7.494767942262115e-06\n",
            "Epoch: 7/10, Step: 930/938, Loss: 0.0001558037765789777\n",
            "Epoch: 7/10, Step: 931/938, Loss: 0.002675757510587573\n",
            "Epoch: 7/10, Step: 932/938, Loss: 0.0016542634693905711\n",
            "Epoch: 7/10, Step: 933/938, Loss: 6.433817179640755e-05\n",
            "Epoch: 7/10, Step: 934/938, Loss: 0.0011863301042467356\n",
            "Epoch: 7/10, Step: 935/938, Loss: 0.0035104218404740095\n",
            "Epoch: 7/10, Step: 936/938, Loss: 0.001002030330710113\n",
            "Epoch: 7/10, Step: 937/938, Loss: 0.0003114388673566282\n",
            "Epoch: 7/10, Step: 938/938, Loss: 0.015763400122523308\n",
            "Epoch: 8/10, Step: 1/938, Loss: 0.000911402516067028\n",
            "Epoch: 8/10, Step: 2/938, Loss: 0.0003473804099485278\n",
            "Epoch: 8/10, Step: 3/938, Loss: 0.0008003729744814336\n",
            "Epoch: 8/10, Step: 4/938, Loss: 0.0023500840179622173\n",
            "Epoch: 8/10, Step: 5/938, Loss: 7.272092625498772e-05\n",
            "Epoch: 8/10, Step: 6/938, Loss: 0.018457435071468353\n",
            "Epoch: 8/10, Step: 7/938, Loss: 0.0007418887689709663\n",
            "Epoch: 8/10, Step: 8/938, Loss: 0.001021847827360034\n",
            "Epoch: 8/10, Step: 9/938, Loss: 0.00628860667347908\n",
            "Epoch: 8/10, Step: 10/938, Loss: 1.0537115485931281e-05\n",
            "Epoch: 8/10, Step: 11/938, Loss: 0.00038662090082652867\n",
            "Epoch: 8/10, Step: 12/938, Loss: 8.656371937831864e-05\n",
            "Epoch: 8/10, Step: 13/938, Loss: 0.004182351753115654\n",
            "Epoch: 8/10, Step: 14/938, Loss: 9.918075375026092e-05\n",
            "Epoch: 8/10, Step: 15/938, Loss: 0.0015416573733091354\n",
            "Epoch: 8/10, Step: 16/938, Loss: 0.00013928202679380774\n",
            "Epoch: 8/10, Step: 17/938, Loss: 0.003557467134669423\n",
            "Epoch: 8/10, Step: 18/938, Loss: 0.0010907832765951753\n",
            "Epoch: 8/10, Step: 19/938, Loss: 0.0001390514662489295\n",
            "Epoch: 8/10, Step: 20/938, Loss: 6.286022835411131e-05\n",
            "Epoch: 8/10, Step: 21/938, Loss: 0.0013887151144444942\n",
            "Epoch: 8/10, Step: 22/938, Loss: 6.021348963258788e-05\n",
            "Epoch: 8/10, Step: 23/938, Loss: 2.6405317839817144e-05\n",
            "Epoch: 8/10, Step: 24/938, Loss: 5.038342351326719e-05\n",
            "Epoch: 8/10, Step: 25/938, Loss: 0.002395856427028775\n",
            "Epoch: 8/10, Step: 26/938, Loss: 0.004460104741156101\n",
            "Epoch: 8/10, Step: 27/938, Loss: 8.075586811173707e-05\n",
            "Epoch: 8/10, Step: 28/938, Loss: 0.007399624213576317\n",
            "Epoch: 8/10, Step: 29/938, Loss: 0.00022951688151806593\n",
            "Epoch: 8/10, Step: 30/938, Loss: 2.2296822862699628e-05\n",
            "Epoch: 8/10, Step: 31/938, Loss: 0.012751740403473377\n",
            "Epoch: 8/10, Step: 32/938, Loss: 0.00021690060384571552\n",
            "Epoch: 8/10, Step: 33/938, Loss: 0.0002878109226003289\n",
            "Epoch: 8/10, Step: 34/938, Loss: 0.00011088438623119146\n",
            "Epoch: 8/10, Step: 35/938, Loss: 0.0003952549013774842\n",
            "Epoch: 8/10, Step: 36/938, Loss: 0.015489879064261913\n",
            "Epoch: 8/10, Step: 37/938, Loss: 6.66416781314183e-06\n",
            "Epoch: 8/10, Step: 38/938, Loss: 0.001844070735387504\n",
            "Epoch: 8/10, Step: 39/938, Loss: 0.00033605020144023\n",
            "Epoch: 8/10, Step: 40/938, Loss: 5.016282739234157e-05\n",
            "Epoch: 8/10, Step: 41/938, Loss: 7.9476842074655e-05\n",
            "Epoch: 8/10, Step: 42/938, Loss: 0.0015793871134519577\n",
            "Epoch: 8/10, Step: 43/938, Loss: 3.8466820114990696e-05\n",
            "Epoch: 8/10, Step: 44/938, Loss: 0.0004055338795296848\n",
            "Epoch: 8/10, Step: 45/938, Loss: 0.0001530336303403601\n",
            "Epoch: 8/10, Step: 46/938, Loss: 6.599856715183705e-05\n",
            "Epoch: 8/10, Step: 47/938, Loss: 0.02456914633512497\n",
            "Epoch: 8/10, Step: 48/938, Loss: 0.00010374571138527244\n",
            "Epoch: 8/10, Step: 49/938, Loss: 0.12676653265953064\n",
            "Epoch: 8/10, Step: 50/938, Loss: 0.015394425950944424\n",
            "Epoch: 8/10, Step: 51/938, Loss: 0.0013146867277100682\n",
            "Epoch: 8/10, Step: 52/938, Loss: 4.507806079345755e-05\n",
            "Epoch: 8/10, Step: 53/938, Loss: 1.719622923701536e-05\n",
            "Epoch: 8/10, Step: 54/938, Loss: 8.722973143449053e-05\n",
            "Epoch: 8/10, Step: 55/938, Loss: 0.0008730412228032947\n",
            "Epoch: 8/10, Step: 56/938, Loss: 0.0003209438291378319\n",
            "Epoch: 8/10, Step: 57/938, Loss: 0.00025303816073574126\n",
            "Epoch: 8/10, Step: 58/938, Loss: 0.0025682509876787663\n",
            "Epoch: 8/10, Step: 59/938, Loss: 0.0001836197916418314\n",
            "Epoch: 8/10, Step: 60/938, Loss: 0.008433681912720203\n",
            "Epoch: 8/10, Step: 61/938, Loss: 0.0011102105490863323\n",
            "Epoch: 8/10, Step: 62/938, Loss: 0.0006905529298819602\n",
            "Epoch: 8/10, Step: 63/938, Loss: 0.0008746605599299073\n",
            "Epoch: 8/10, Step: 64/938, Loss: 0.0004607438459061086\n",
            "Epoch: 8/10, Step: 65/938, Loss: 0.0005034739733673632\n",
            "Epoch: 8/10, Step: 66/938, Loss: 0.0144661208614707\n",
            "Epoch: 8/10, Step: 67/938, Loss: 0.00292059313505888\n",
            "Epoch: 8/10, Step: 68/938, Loss: 0.0004357996513135731\n",
            "Epoch: 8/10, Step: 69/938, Loss: 0.00020485975255724043\n",
            "Epoch: 8/10, Step: 70/938, Loss: 0.00011061455734306946\n",
            "Epoch: 8/10, Step: 71/938, Loss: 0.00023734713613521308\n",
            "Epoch: 8/10, Step: 72/938, Loss: 6.073272743378766e-05\n",
            "Epoch: 8/10, Step: 73/938, Loss: 0.03452403470873833\n",
            "Epoch: 8/10, Step: 74/938, Loss: 4.8780813813209534e-05\n",
            "Epoch: 8/10, Step: 75/938, Loss: 0.0014641802990809083\n",
            "Epoch: 8/10, Step: 76/938, Loss: 0.002153153298422694\n",
            "Epoch: 8/10, Step: 77/938, Loss: 0.00015951553359627724\n",
            "Epoch: 8/10, Step: 78/938, Loss: 0.0009319897508248687\n",
            "Epoch: 8/10, Step: 79/938, Loss: 0.0066355024464428425\n",
            "Epoch: 8/10, Step: 80/938, Loss: 0.0007454414735548198\n",
            "Epoch: 8/10, Step: 81/938, Loss: 0.00034673139452934265\n",
            "Epoch: 8/10, Step: 82/938, Loss: 0.00039830105379223824\n",
            "Epoch: 8/10, Step: 83/938, Loss: 0.0006569526740349829\n",
            "Epoch: 8/10, Step: 84/938, Loss: 0.002692893613129854\n",
            "Epoch: 8/10, Step: 85/938, Loss: 0.0012238153722137213\n",
            "Epoch: 8/10, Step: 86/938, Loss: 0.020233605057001114\n",
            "Epoch: 8/10, Step: 87/938, Loss: 0.00022753454686608166\n",
            "Epoch: 8/10, Step: 88/938, Loss: 0.005264394450932741\n",
            "Epoch: 8/10, Step: 89/938, Loss: 0.00014340646157506853\n",
            "Epoch: 8/10, Step: 90/938, Loss: 9.205014794133604e-05\n",
            "Epoch: 8/10, Step: 91/938, Loss: 0.0005872062756679952\n",
            "Epoch: 8/10, Step: 92/938, Loss: 0.05155354365706444\n",
            "Epoch: 8/10, Step: 93/938, Loss: 0.048562128096818924\n",
            "Epoch: 8/10, Step: 94/938, Loss: 6.818807014496997e-05\n",
            "Epoch: 8/10, Step: 95/938, Loss: 7.232197731354972e-06\n",
            "Epoch: 8/10, Step: 96/938, Loss: 0.0026716783177107573\n",
            "Epoch: 8/10, Step: 97/938, Loss: 0.0008483657729811966\n",
            "Epoch: 8/10, Step: 98/938, Loss: 0.005024123005568981\n",
            "Epoch: 8/10, Step: 99/938, Loss: 1.2506221537478268e-05\n",
            "Epoch: 8/10, Step: 100/938, Loss: 0.0007862277561798692\n",
            "Epoch: 8/10, Step: 101/938, Loss: 0.02175721898674965\n",
            "Epoch: 8/10, Step: 102/938, Loss: 1.2137440535298083e-05\n",
            "Epoch: 8/10, Step: 103/938, Loss: 0.00043976324377581477\n",
            "Epoch: 8/10, Step: 104/938, Loss: 0.062002748250961304\n",
            "Epoch: 8/10, Step: 105/938, Loss: 5.811860683024861e-05\n",
            "Epoch: 8/10, Step: 106/938, Loss: 3.424179521971382e-05\n",
            "Epoch: 8/10, Step: 107/938, Loss: 0.026115519925951958\n",
            "Epoch: 8/10, Step: 108/938, Loss: 0.03019801527261734\n",
            "Epoch: 8/10, Step: 109/938, Loss: 0.0005929498001933098\n",
            "Epoch: 8/10, Step: 110/938, Loss: 0.003971044905483723\n",
            "Epoch: 8/10, Step: 111/938, Loss: 0.02297356352210045\n",
            "Epoch: 8/10, Step: 112/938, Loss: 0.0070082200691103935\n",
            "Epoch: 8/10, Step: 113/938, Loss: 0.00010943486995529383\n",
            "Epoch: 8/10, Step: 114/938, Loss: 0.0002470236213412136\n",
            "Epoch: 8/10, Step: 115/938, Loss: 9.975183638744056e-05\n",
            "Epoch: 8/10, Step: 116/938, Loss: 0.0977589413523674\n",
            "Epoch: 8/10, Step: 117/938, Loss: 0.0009880529250949621\n",
            "Epoch: 8/10, Step: 118/938, Loss: 0.00017996912356466055\n",
            "Epoch: 8/10, Step: 119/938, Loss: 0.008981861174106598\n",
            "Epoch: 8/10, Step: 120/938, Loss: 0.001695892191492021\n",
            "Epoch: 8/10, Step: 121/938, Loss: 0.0007448305259458721\n",
            "Epoch: 8/10, Step: 122/938, Loss: 0.0010405320208519697\n",
            "Epoch: 8/10, Step: 123/938, Loss: 0.00010098202619701624\n",
            "Epoch: 8/10, Step: 124/938, Loss: 0.00011194510443601757\n",
            "Epoch: 8/10, Step: 125/938, Loss: 0.0004863518988713622\n",
            "Epoch: 8/10, Step: 126/938, Loss: 0.002466506790369749\n",
            "Epoch: 8/10, Step: 127/938, Loss: 0.0009352221968583763\n",
            "Epoch: 8/10, Step: 128/938, Loss: 1.6193880583159626e-05\n",
            "Epoch: 8/10, Step: 129/938, Loss: 4.0964434447232634e-05\n",
            "Epoch: 8/10, Step: 130/938, Loss: 0.0003441951994318515\n",
            "Epoch: 8/10, Step: 131/938, Loss: 2.1321247913874686e-05\n",
            "Epoch: 8/10, Step: 132/938, Loss: 0.0022719770204275846\n",
            "Epoch: 8/10, Step: 133/938, Loss: 0.0038967588916420937\n",
            "Epoch: 8/10, Step: 134/938, Loss: 8.397002966376022e-05\n",
            "Epoch: 8/10, Step: 135/938, Loss: 0.024920418858528137\n",
            "Epoch: 8/10, Step: 136/938, Loss: 0.00048431335017085075\n",
            "Epoch: 8/10, Step: 137/938, Loss: 0.08936180919408798\n",
            "Epoch: 8/10, Step: 138/938, Loss: 0.0010736562544479966\n",
            "Epoch: 8/10, Step: 139/938, Loss: 0.004070005379617214\n",
            "Epoch: 8/10, Step: 140/938, Loss: 0.007544951047748327\n",
            "Epoch: 8/10, Step: 141/938, Loss: 0.0027406143490225077\n",
            "Epoch: 8/10, Step: 142/938, Loss: 0.0005848709843121469\n",
            "Epoch: 8/10, Step: 143/938, Loss: 0.012074128724634647\n",
            "Epoch: 8/10, Step: 144/938, Loss: 0.006679085083305836\n",
            "Epoch: 8/10, Step: 145/938, Loss: 8.93797114258632e-05\n",
            "Epoch: 8/10, Step: 146/938, Loss: 0.0017722664633765817\n",
            "Epoch: 8/10, Step: 147/938, Loss: 0.00013813652913086116\n",
            "Epoch: 8/10, Step: 148/938, Loss: 1.6084602975752205e-05\n",
            "Epoch: 8/10, Step: 149/938, Loss: 2.7167325242771767e-05\n",
            "Epoch: 8/10, Step: 150/938, Loss: 9.6770869276952e-05\n",
            "Epoch: 8/10, Step: 151/938, Loss: 0.030857320874929428\n",
            "Epoch: 8/10, Step: 152/938, Loss: 0.003238437930122018\n",
            "Epoch: 8/10, Step: 153/938, Loss: 0.0014965488808229566\n",
            "Epoch: 8/10, Step: 154/938, Loss: 0.027949374169111252\n",
            "Epoch: 8/10, Step: 155/938, Loss: 0.0034293364733457565\n",
            "Epoch: 8/10, Step: 156/938, Loss: 0.00029985798755660653\n",
            "Epoch: 8/10, Step: 157/938, Loss: 0.0026532381307333708\n",
            "Epoch: 8/10, Step: 158/938, Loss: 0.00012655634782277048\n",
            "Epoch: 8/10, Step: 159/938, Loss: 0.004424238111823797\n",
            "Epoch: 8/10, Step: 160/938, Loss: 0.00024164409842342138\n",
            "Epoch: 8/10, Step: 161/938, Loss: 0.0001036949033732526\n",
            "Epoch: 8/10, Step: 162/938, Loss: 0.007561081554740667\n",
            "Epoch: 8/10, Step: 163/938, Loss: 0.0020520202815532684\n",
            "Epoch: 8/10, Step: 164/938, Loss: 0.00010572826431598514\n",
            "Epoch: 8/10, Step: 165/938, Loss: 2.9426497349049896e-05\n",
            "Epoch: 8/10, Step: 166/938, Loss: 4.5961693103890866e-05\n",
            "Epoch: 8/10, Step: 167/938, Loss: 0.0007113523315638304\n",
            "Epoch: 8/10, Step: 168/938, Loss: 0.11983325332403183\n",
            "Epoch: 8/10, Step: 169/938, Loss: 0.008788242936134338\n",
            "Epoch: 8/10, Step: 170/938, Loss: 0.004543112125247717\n",
            "Epoch: 8/10, Step: 171/938, Loss: 0.00015615423035342246\n",
            "Epoch: 8/10, Step: 172/938, Loss: 8.482410339638591e-05\n",
            "Epoch: 8/10, Step: 173/938, Loss: 4.713021553470753e-05\n",
            "Epoch: 8/10, Step: 174/938, Loss: 0.0034782260190695524\n",
            "Epoch: 8/10, Step: 175/938, Loss: 0.02041359804570675\n",
            "Epoch: 8/10, Step: 176/938, Loss: 0.02129402756690979\n",
            "Epoch: 8/10, Step: 177/938, Loss: 0.003500047605484724\n",
            "Epoch: 8/10, Step: 178/938, Loss: 1.4708311937283725e-05\n",
            "Epoch: 8/10, Step: 179/938, Loss: 0.0009809460025280714\n",
            "Epoch: 8/10, Step: 180/938, Loss: 0.05135674029588699\n",
            "Epoch: 8/10, Step: 181/938, Loss: 0.05169658362865448\n",
            "Epoch: 8/10, Step: 182/938, Loss: 7.80970513005741e-05\n",
            "Epoch: 8/10, Step: 183/938, Loss: 9.426030737813562e-05\n",
            "Epoch: 8/10, Step: 184/938, Loss: 0.0039862231351435184\n",
            "Epoch: 8/10, Step: 185/938, Loss: 0.0013175442581996322\n",
            "Epoch: 8/10, Step: 186/938, Loss: 0.0030744634568691254\n",
            "Epoch: 8/10, Step: 187/938, Loss: 0.007325491402298212\n",
            "Epoch: 8/10, Step: 188/938, Loss: 0.0017794010927900672\n",
            "Epoch: 8/10, Step: 189/938, Loss: 0.0008924800786189735\n",
            "Epoch: 8/10, Step: 190/938, Loss: 0.016536707058548927\n",
            "Epoch: 8/10, Step: 191/938, Loss: 0.006976505275815725\n",
            "Epoch: 8/10, Step: 192/938, Loss: 0.004370498470962048\n",
            "Epoch: 8/10, Step: 193/938, Loss: 0.000495832588057965\n",
            "Epoch: 8/10, Step: 194/938, Loss: 0.0008671054383739829\n",
            "Epoch: 8/10, Step: 195/938, Loss: 0.00012763903941959143\n",
            "Epoch: 8/10, Step: 196/938, Loss: 0.18744470179080963\n",
            "Epoch: 8/10, Step: 197/938, Loss: 0.002069702371954918\n",
            "Epoch: 8/10, Step: 198/938, Loss: 0.001665701624006033\n",
            "Epoch: 8/10, Step: 199/938, Loss: 0.06276552379131317\n",
            "Epoch: 8/10, Step: 200/938, Loss: 0.0005472411867231131\n",
            "Epoch: 8/10, Step: 201/938, Loss: 0.014680072665214539\n",
            "Epoch: 8/10, Step: 202/938, Loss: 0.005924420431256294\n",
            "Epoch: 8/10, Step: 203/938, Loss: 0.036438390612602234\n",
            "Epoch: 8/10, Step: 204/938, Loss: 0.04456660896539688\n",
            "Epoch: 8/10, Step: 205/938, Loss: 0.0007702995790168643\n",
            "Epoch: 8/10, Step: 206/938, Loss: 0.001137336017563939\n",
            "Epoch: 8/10, Step: 207/938, Loss: 2.396008130745031e-05\n",
            "Epoch: 8/10, Step: 208/938, Loss: 0.021312616765499115\n",
            "Epoch: 8/10, Step: 209/938, Loss: 0.0006767311133444309\n",
            "Epoch: 8/10, Step: 210/938, Loss: 2.6143165086978115e-05\n",
            "Epoch: 8/10, Step: 211/938, Loss: 0.004560218658298254\n",
            "Epoch: 8/10, Step: 212/938, Loss: 0.0030411104671657085\n",
            "Epoch: 8/10, Step: 213/938, Loss: 0.00959019735455513\n",
            "Epoch: 8/10, Step: 214/938, Loss: 0.0010306739713996649\n",
            "Epoch: 8/10, Step: 215/938, Loss: 0.013129254803061485\n",
            "Epoch: 8/10, Step: 216/938, Loss: 0.0009935932466760278\n",
            "Epoch: 8/10, Step: 217/938, Loss: 0.0027616487350314856\n",
            "Epoch: 8/10, Step: 218/938, Loss: 0.0003090514801442623\n",
            "Epoch: 8/10, Step: 219/938, Loss: 7.900142372818664e-05\n",
            "Epoch: 8/10, Step: 220/938, Loss: 0.0019066992681473494\n",
            "Epoch: 8/10, Step: 221/938, Loss: 0.00027862400747835636\n",
            "Epoch: 8/10, Step: 222/938, Loss: 0.0004949111607857049\n",
            "Epoch: 8/10, Step: 223/938, Loss: 0.00038747137296013534\n",
            "Epoch: 8/10, Step: 224/938, Loss: 0.0007995082996785641\n",
            "Epoch: 8/10, Step: 225/938, Loss: 0.0009758491651155055\n",
            "Epoch: 8/10, Step: 226/938, Loss: 0.00011948202882194892\n",
            "Epoch: 8/10, Step: 227/938, Loss: 0.0005356871988624334\n",
            "Epoch: 8/10, Step: 228/938, Loss: 0.005479374434798956\n",
            "Epoch: 8/10, Step: 229/938, Loss: 0.0009923094185069203\n",
            "Epoch: 8/10, Step: 230/938, Loss: 1.5726627680123784e-05\n",
            "Epoch: 8/10, Step: 231/938, Loss: 0.00020874272740911692\n",
            "Epoch: 8/10, Step: 232/938, Loss: 0.02134021185338497\n",
            "Epoch: 8/10, Step: 233/938, Loss: 0.00017662654863670468\n",
            "Epoch: 8/10, Step: 234/938, Loss: 0.0025312453508377075\n",
            "Epoch: 8/10, Step: 235/938, Loss: 0.00356987863779068\n",
            "Epoch: 8/10, Step: 236/938, Loss: 0.0007882898789830506\n",
            "Epoch: 8/10, Step: 237/938, Loss: 0.00034074802533723414\n",
            "Epoch: 8/10, Step: 238/938, Loss: 3.265383929829113e-05\n",
            "Epoch: 8/10, Step: 239/938, Loss: 0.006848192773759365\n",
            "Epoch: 8/10, Step: 240/938, Loss: 0.062262918800115585\n",
            "Epoch: 8/10, Step: 241/938, Loss: 0.12448357045650482\n",
            "Epoch: 8/10, Step: 242/938, Loss: 0.0020941433031111956\n",
            "Epoch: 8/10, Step: 243/938, Loss: 0.004420597571879625\n",
            "Epoch: 8/10, Step: 244/938, Loss: 0.0003670328878797591\n",
            "Epoch: 8/10, Step: 245/938, Loss: 9.483352914685383e-05\n",
            "Epoch: 8/10, Step: 246/938, Loss: 0.01334814727306366\n",
            "Epoch: 8/10, Step: 247/938, Loss: 0.00503227673470974\n",
            "Epoch: 8/10, Step: 248/938, Loss: 1.7860496882349253e-05\n",
            "Epoch: 8/10, Step: 249/938, Loss: 0.00015787978190928698\n",
            "Epoch: 8/10, Step: 250/938, Loss: 0.0006164668593555689\n",
            "Epoch: 8/10, Step: 251/938, Loss: 0.09034420549869537\n",
            "Epoch: 8/10, Step: 252/938, Loss: 6.829587073298171e-05\n",
            "Epoch: 8/10, Step: 253/938, Loss: 0.020733458921313286\n",
            "Epoch: 8/10, Step: 254/938, Loss: 0.0002831407473422587\n",
            "Epoch: 8/10, Step: 255/938, Loss: 0.011397581547498703\n",
            "Epoch: 8/10, Step: 256/938, Loss: 0.003752768039703369\n",
            "Epoch: 8/10, Step: 257/938, Loss: 0.02404492348432541\n",
            "Epoch: 8/10, Step: 258/938, Loss: 0.009818486869335175\n",
            "Epoch: 8/10, Step: 259/938, Loss: 0.0003185701207257807\n",
            "Epoch: 8/10, Step: 260/938, Loss: 0.0001469082199037075\n",
            "Epoch: 8/10, Step: 261/938, Loss: 6.226142431842163e-05\n",
            "Epoch: 8/10, Step: 262/938, Loss: 0.0036181833129376173\n",
            "Epoch: 8/10, Step: 263/938, Loss: 0.005220760125666857\n",
            "Epoch: 8/10, Step: 264/938, Loss: 4.229054320603609e-05\n",
            "Epoch: 8/10, Step: 265/938, Loss: 0.0001895445166155696\n",
            "Epoch: 8/10, Step: 266/938, Loss: 1.0355681297369301e-05\n",
            "Epoch: 8/10, Step: 267/938, Loss: 6.208980630617589e-05\n",
            "Epoch: 8/10, Step: 268/938, Loss: 1.0936191756627522e-05\n",
            "Epoch: 8/10, Step: 269/938, Loss: 0.01619494892656803\n",
            "Epoch: 8/10, Step: 270/938, Loss: 0.014696428552269936\n",
            "Epoch: 8/10, Step: 271/938, Loss: 0.058391768485307693\n",
            "Epoch: 8/10, Step: 272/938, Loss: 0.0010912130819633603\n",
            "Epoch: 8/10, Step: 273/938, Loss: 0.00028749631019309163\n",
            "Epoch: 8/10, Step: 274/938, Loss: 0.00040297844680026174\n",
            "Epoch: 8/10, Step: 275/938, Loss: 0.002347436500713229\n",
            "Epoch: 8/10, Step: 276/938, Loss: 0.001144101726822555\n",
            "Epoch: 8/10, Step: 277/938, Loss: 2.8935719456057996e-05\n",
            "Epoch: 8/10, Step: 278/938, Loss: 0.0005682868650183082\n",
            "Epoch: 8/10, Step: 279/938, Loss: 0.0002189881488448009\n",
            "Epoch: 8/10, Step: 280/938, Loss: 0.022256607189774513\n",
            "Epoch: 8/10, Step: 281/938, Loss: 0.028551867231726646\n",
            "Epoch: 8/10, Step: 282/938, Loss: 0.0037813838571310043\n",
            "Epoch: 8/10, Step: 283/938, Loss: 0.0026138750836253166\n",
            "Epoch: 8/10, Step: 284/938, Loss: 2.9206614271970466e-05\n",
            "Epoch: 8/10, Step: 285/938, Loss: 0.007669195532798767\n",
            "Epoch: 8/10, Step: 286/938, Loss: 0.007465059403330088\n",
            "Epoch: 8/10, Step: 287/938, Loss: 0.0060114506632089615\n",
            "Epoch: 8/10, Step: 288/938, Loss: 4.905210516881198e-05\n",
            "Epoch: 8/10, Step: 289/938, Loss: 0.002230901038274169\n",
            "Epoch: 8/10, Step: 290/938, Loss: 0.00030530421645380557\n",
            "Epoch: 8/10, Step: 291/938, Loss: 0.014005313627421856\n",
            "Epoch: 8/10, Step: 292/938, Loss: 0.00024309640866704285\n",
            "Epoch: 8/10, Step: 293/938, Loss: 0.007759941276162863\n",
            "Epoch: 8/10, Step: 294/938, Loss: 3.629785351222381e-05\n",
            "Epoch: 8/10, Step: 295/938, Loss: 0.0008504334837198257\n",
            "Epoch: 8/10, Step: 296/938, Loss: 0.09670865535736084\n",
            "Epoch: 8/10, Step: 297/938, Loss: 0.0004707102198153734\n",
            "Epoch: 8/10, Step: 298/938, Loss: 0.05274287238717079\n",
            "Epoch: 8/10, Step: 299/938, Loss: 2.2071864805184305e-05\n",
            "Epoch: 8/10, Step: 300/938, Loss: 0.002072912873700261\n",
            "Epoch: 8/10, Step: 301/938, Loss: 0.018461447209119797\n",
            "Epoch: 8/10, Step: 302/938, Loss: 0.00016863731434568763\n",
            "Epoch: 8/10, Step: 303/938, Loss: 0.04406105726957321\n",
            "Epoch: 8/10, Step: 304/938, Loss: 0.00010298671259079129\n",
            "Epoch: 8/10, Step: 305/938, Loss: 1.6581701856921427e-05\n",
            "Epoch: 8/10, Step: 306/938, Loss: 0.0017855485202744603\n",
            "Epoch: 8/10, Step: 307/938, Loss: 0.00020622539159376174\n",
            "Epoch: 8/10, Step: 308/938, Loss: 0.0032399373594671488\n",
            "Epoch: 8/10, Step: 309/938, Loss: 0.004390859045088291\n",
            "Epoch: 8/10, Step: 310/938, Loss: 0.005838446784764528\n",
            "Epoch: 8/10, Step: 311/938, Loss: 0.0031490090768784285\n",
            "Epoch: 8/10, Step: 312/938, Loss: 0.0013638793025165796\n",
            "Epoch: 8/10, Step: 313/938, Loss: 0.00087391008855775\n",
            "Epoch: 8/10, Step: 314/938, Loss: 0.0008128459448926151\n",
            "Epoch: 8/10, Step: 315/938, Loss: 8.314870501635596e-05\n",
            "Epoch: 8/10, Step: 316/938, Loss: 0.0007205141591839492\n",
            "Epoch: 8/10, Step: 317/938, Loss: 7.11945176590234e-05\n",
            "Epoch: 8/10, Step: 318/938, Loss: 0.0005075742374174297\n",
            "Epoch: 8/10, Step: 319/938, Loss: 0.0026944444980472326\n",
            "Epoch: 8/10, Step: 320/938, Loss: 0.0008755940943956375\n",
            "Epoch: 8/10, Step: 321/938, Loss: 0.00013308234338182956\n",
            "Epoch: 8/10, Step: 322/938, Loss: 1.5258659004757646e-05\n",
            "Epoch: 8/10, Step: 323/938, Loss: 6.551556725753471e-05\n",
            "Epoch: 8/10, Step: 324/938, Loss: 0.000173951979377307\n",
            "Epoch: 8/10, Step: 325/938, Loss: 0.0041322652250528336\n",
            "Epoch: 8/10, Step: 326/938, Loss: 0.00021549954544752836\n",
            "Epoch: 8/10, Step: 327/938, Loss: 0.001614393899217248\n",
            "Epoch: 8/10, Step: 328/938, Loss: 0.0025763476733118296\n",
            "Epoch: 8/10, Step: 329/938, Loss: 0.001457374426536262\n",
            "Epoch: 8/10, Step: 330/938, Loss: 0.0029058167710900307\n",
            "Epoch: 8/10, Step: 331/938, Loss: 0.00018270040163770318\n",
            "Epoch: 8/10, Step: 332/938, Loss: 0.0005222500767558813\n",
            "Epoch: 8/10, Step: 333/938, Loss: 0.0035991400945931673\n",
            "Epoch: 8/10, Step: 334/938, Loss: 0.00010170078166993335\n",
            "Epoch: 8/10, Step: 335/938, Loss: 0.004892564378678799\n",
            "Epoch: 8/10, Step: 336/938, Loss: 0.00022297530085779727\n",
            "Epoch: 8/10, Step: 337/938, Loss: 0.016537243500351906\n",
            "Epoch: 8/10, Step: 338/938, Loss: 6.458489951910451e-05\n",
            "Epoch: 8/10, Step: 339/938, Loss: 0.000810011406429112\n",
            "Epoch: 8/10, Step: 340/938, Loss: 0.011609122157096863\n",
            "Epoch: 8/10, Step: 341/938, Loss: 5.788639555248665e-06\n",
            "Epoch: 8/10, Step: 342/938, Loss: 0.0012515949783846736\n",
            "Epoch: 8/10, Step: 343/938, Loss: 0.00010678398393793032\n",
            "Epoch: 8/10, Step: 344/938, Loss: 0.0004314142861403525\n",
            "Epoch: 8/10, Step: 345/938, Loss: 0.00037173970486037433\n",
            "Epoch: 8/10, Step: 346/938, Loss: 0.00013548583956435323\n",
            "Epoch: 8/10, Step: 347/938, Loss: 0.033357296139001846\n",
            "Epoch: 8/10, Step: 348/938, Loss: 0.0014578462578356266\n",
            "Epoch: 8/10, Step: 349/938, Loss: 0.02533763274550438\n",
            "Epoch: 8/10, Step: 350/938, Loss: 4.767215432366356e-05\n",
            "Epoch: 8/10, Step: 351/938, Loss: 0.004290210548788309\n",
            "Epoch: 8/10, Step: 352/938, Loss: 3.0131437597447075e-05\n",
            "Epoch: 8/10, Step: 353/938, Loss: 5.2697247156174853e-05\n",
            "Epoch: 8/10, Step: 354/938, Loss: 0.0001032292639138177\n",
            "Epoch: 8/10, Step: 355/938, Loss: 0.0006106336950324476\n",
            "Epoch: 8/10, Step: 356/938, Loss: 5.1999853894812986e-05\n",
            "Epoch: 8/10, Step: 357/938, Loss: 0.0004028427938465029\n",
            "Epoch: 8/10, Step: 358/938, Loss: 0.02103116363286972\n",
            "Epoch: 8/10, Step: 359/938, Loss: 0.00037324585719034076\n",
            "Epoch: 8/10, Step: 360/938, Loss: 0.0006153698777779937\n",
            "Epoch: 8/10, Step: 361/938, Loss: 0.001269871718250215\n",
            "Epoch: 8/10, Step: 362/938, Loss: 0.0007822489133104682\n",
            "Epoch: 8/10, Step: 363/938, Loss: 0.021217118948698044\n",
            "Epoch: 8/10, Step: 364/938, Loss: 0.0015711495652794838\n",
            "Epoch: 8/10, Step: 365/938, Loss: 0.0219844039529562\n",
            "Epoch: 8/10, Step: 366/938, Loss: 0.002672548172995448\n",
            "Epoch: 8/10, Step: 367/938, Loss: 0.00020408463024068624\n",
            "Epoch: 8/10, Step: 368/938, Loss: 0.013762855902314186\n",
            "Epoch: 8/10, Step: 369/938, Loss: 0.007222876884043217\n",
            "Epoch: 8/10, Step: 370/938, Loss: 0.0065881856717169285\n",
            "Epoch: 8/10, Step: 371/938, Loss: 0.0003007539198733866\n",
            "Epoch: 8/10, Step: 372/938, Loss: 0.00010925024253083393\n",
            "Epoch: 8/10, Step: 373/938, Loss: 0.014250330626964569\n",
            "Epoch: 8/10, Step: 374/938, Loss: 4.488751437747851e-05\n",
            "Epoch: 8/10, Step: 375/938, Loss: 4.6540517359972e-05\n",
            "Epoch: 8/10, Step: 376/938, Loss: 0.0016768850618973374\n",
            "Epoch: 8/10, Step: 377/938, Loss: 2.311116986675188e-05\n",
            "Epoch: 8/10, Step: 378/938, Loss: 0.015947215259075165\n",
            "Epoch: 8/10, Step: 379/938, Loss: 0.00020563331781886518\n",
            "Epoch: 8/10, Step: 380/938, Loss: 1.9780934508162318e-06\n",
            "Epoch: 8/10, Step: 381/938, Loss: 0.0002569134521763772\n",
            "Epoch: 8/10, Step: 382/938, Loss: 1.6540179785806686e-06\n",
            "Epoch: 8/10, Step: 383/938, Loss: 4.8029920435510576e-05\n",
            "Epoch: 8/10, Step: 384/938, Loss: 0.0016435296274721622\n",
            "Epoch: 8/10, Step: 385/938, Loss: 0.00021005369490012527\n",
            "Epoch: 8/10, Step: 386/938, Loss: 0.00026427392731420696\n",
            "Epoch: 8/10, Step: 387/938, Loss: 9.899799624690786e-05\n",
            "Epoch: 8/10, Step: 388/938, Loss: 0.00016420066822320223\n",
            "Epoch: 8/10, Step: 389/938, Loss: 0.019498759880661964\n",
            "Epoch: 8/10, Step: 390/938, Loss: 4.7629819164285436e-05\n",
            "Epoch: 8/10, Step: 391/938, Loss: 0.0007429749239236116\n",
            "Epoch: 8/10, Step: 392/938, Loss: 0.056787777692079544\n",
            "Epoch: 8/10, Step: 393/938, Loss: 0.05846735090017319\n",
            "Epoch: 8/10, Step: 394/938, Loss: 2.5327630282845348e-05\n",
            "Epoch: 8/10, Step: 395/938, Loss: 0.0004234332300256938\n",
            "Epoch: 8/10, Step: 396/938, Loss: 2.7512893211678602e-05\n",
            "Epoch: 8/10, Step: 397/938, Loss: 0.022830266505479813\n",
            "Epoch: 8/10, Step: 398/938, Loss: 0.0014862597454339266\n",
            "Epoch: 8/10, Step: 399/938, Loss: 0.002989040222018957\n",
            "Epoch: 8/10, Step: 400/938, Loss: 0.00017638753342907876\n",
            "Epoch: 8/10, Step: 401/938, Loss: 3.622980511863716e-05\n",
            "Epoch: 8/10, Step: 402/938, Loss: 0.0016675012884661555\n",
            "Epoch: 8/10, Step: 403/938, Loss: 0.0019229915924370289\n",
            "Epoch: 8/10, Step: 404/938, Loss: 0.020181497558951378\n",
            "Epoch: 8/10, Step: 405/938, Loss: 0.0034430359955877066\n",
            "Epoch: 8/10, Step: 406/938, Loss: 0.0039450847543776035\n",
            "Epoch: 8/10, Step: 407/938, Loss: 0.00032974063651636243\n",
            "Epoch: 8/10, Step: 408/938, Loss: 0.00477502541616559\n",
            "Epoch: 8/10, Step: 409/938, Loss: 0.0003842333098873496\n",
            "Epoch: 8/10, Step: 410/938, Loss: 0.05521085113286972\n",
            "Epoch: 8/10, Step: 411/938, Loss: 0.006039422936737537\n",
            "Epoch: 8/10, Step: 412/938, Loss: 0.00023795584274921566\n",
            "Epoch: 8/10, Step: 413/938, Loss: 0.0005597375566139817\n",
            "Epoch: 8/10, Step: 414/938, Loss: 0.005862448364496231\n",
            "Epoch: 8/10, Step: 415/938, Loss: 0.00032826661481522024\n",
            "Epoch: 8/10, Step: 416/938, Loss: 0.007642096374183893\n",
            "Epoch: 8/10, Step: 417/938, Loss: 3.423077578190714e-05\n",
            "Epoch: 8/10, Step: 418/938, Loss: 9.744177077664062e-05\n",
            "Epoch: 8/10, Step: 419/938, Loss: 0.045117467641830444\n",
            "Epoch: 8/10, Step: 420/938, Loss: 0.0003230598522350192\n",
            "Epoch: 8/10, Step: 421/938, Loss: 0.006223520264029503\n",
            "Epoch: 8/10, Step: 422/938, Loss: 0.0022762571461498737\n",
            "Epoch: 8/10, Step: 423/938, Loss: 0.00010156313510378823\n",
            "Epoch: 8/10, Step: 424/938, Loss: 9.527465590508655e-05\n",
            "Epoch: 8/10, Step: 425/938, Loss: 0.00043699759407900274\n",
            "Epoch: 8/10, Step: 426/938, Loss: 0.011924155056476593\n",
            "Epoch: 8/10, Step: 427/938, Loss: 0.0003723129048012197\n",
            "Epoch: 8/10, Step: 428/938, Loss: 0.00040440057637169957\n",
            "Epoch: 8/10, Step: 429/938, Loss: 0.04081226512789726\n",
            "Epoch: 8/10, Step: 430/938, Loss: 0.001566846389323473\n",
            "Epoch: 8/10, Step: 431/938, Loss: 0.0018110561650246382\n",
            "Epoch: 8/10, Step: 432/938, Loss: 0.0014374906895682216\n",
            "Epoch: 8/10, Step: 433/938, Loss: 0.018174240365624428\n",
            "Epoch: 8/10, Step: 434/938, Loss: 0.0018636789172887802\n",
            "Epoch: 8/10, Step: 435/938, Loss: 0.011814583092927933\n",
            "Epoch: 8/10, Step: 436/938, Loss: 0.0009168265969492495\n",
            "Epoch: 8/10, Step: 437/938, Loss: 3.31828705384396e-05\n",
            "Epoch: 8/10, Step: 438/938, Loss: 0.009730948135256767\n",
            "Epoch: 8/10, Step: 439/938, Loss: 0.0006425409810617566\n",
            "Epoch: 8/10, Step: 440/938, Loss: 0.00010023389768321067\n",
            "Epoch: 8/10, Step: 441/938, Loss: 0.00026713282568380237\n",
            "Epoch: 8/10, Step: 442/938, Loss: 0.002925272099673748\n",
            "Epoch: 8/10, Step: 443/938, Loss: 0.00037909328239038587\n",
            "Epoch: 8/10, Step: 444/938, Loss: 0.008746818639338017\n",
            "Epoch: 8/10, Step: 445/938, Loss: 0.0007687061442993581\n",
            "Epoch: 8/10, Step: 446/938, Loss: 3.2057061616797e-05\n",
            "Epoch: 8/10, Step: 447/938, Loss: 0.0003079637244809419\n",
            "Epoch: 8/10, Step: 448/938, Loss: 0.033785704523324966\n",
            "Epoch: 8/10, Step: 449/938, Loss: 0.01245887205004692\n",
            "Epoch: 8/10, Step: 450/938, Loss: 0.016048967838287354\n",
            "Epoch: 8/10, Step: 451/938, Loss: 0.0006805425509810448\n",
            "Epoch: 8/10, Step: 452/938, Loss: 0.0011012644972652197\n",
            "Epoch: 8/10, Step: 453/938, Loss: 1.1156073924212251e-05\n",
            "Epoch: 8/10, Step: 454/938, Loss: 0.00016100710490718484\n",
            "Epoch: 8/10, Step: 455/938, Loss: 0.00037906388752162457\n",
            "Epoch: 8/10, Step: 456/938, Loss: 0.0004334374680183828\n",
            "Epoch: 8/10, Step: 457/938, Loss: 0.0010378641309216619\n",
            "Epoch: 8/10, Step: 458/938, Loss: 0.011347687803208828\n",
            "Epoch: 8/10, Step: 459/938, Loss: 0.0010009512770920992\n",
            "Epoch: 8/10, Step: 460/938, Loss: 0.0002464892459101975\n",
            "Epoch: 8/10, Step: 461/938, Loss: 0.00013784394832327962\n",
            "Epoch: 8/10, Step: 462/938, Loss: 6.274872703215806e-06\n",
            "Epoch: 8/10, Step: 463/938, Loss: 0.00010160019883187488\n",
            "Epoch: 8/10, Step: 464/938, Loss: 0.0008321388158947229\n",
            "Epoch: 8/10, Step: 465/938, Loss: 0.0012609701370820403\n",
            "Epoch: 8/10, Step: 466/938, Loss: 0.0002514057559892535\n",
            "Epoch: 8/10, Step: 467/938, Loss: 4.493477536016144e-05\n",
            "Epoch: 8/10, Step: 468/938, Loss: 0.0013326584594324231\n",
            "Epoch: 8/10, Step: 469/938, Loss: 0.0009078147122636437\n",
            "Epoch: 8/10, Step: 470/938, Loss: 0.0006482488824985921\n",
            "Epoch: 8/10, Step: 471/938, Loss: 0.00045252771815285087\n",
            "Epoch: 8/10, Step: 472/938, Loss: 0.007950128987431526\n",
            "Epoch: 8/10, Step: 473/938, Loss: 0.00044658681144937873\n",
            "Epoch: 8/10, Step: 474/938, Loss: 0.00021901277068536729\n",
            "Epoch: 8/10, Step: 475/938, Loss: 0.00026291023823432624\n",
            "Epoch: 8/10, Step: 476/938, Loss: 0.02609766274690628\n",
            "Epoch: 8/10, Step: 477/938, Loss: 0.001362794078886509\n",
            "Epoch: 8/10, Step: 478/938, Loss: 7.831341463315766e-06\n",
            "Epoch: 8/10, Step: 479/938, Loss: 0.07080858945846558\n",
            "Epoch: 8/10, Step: 480/938, Loss: 0.0021725469268858433\n",
            "Epoch: 8/10, Step: 481/938, Loss: 0.00010863403440453112\n",
            "Epoch: 8/10, Step: 482/938, Loss: 7.92353821452707e-05\n",
            "Epoch: 8/10, Step: 483/938, Loss: 0.008602715097367764\n",
            "Epoch: 8/10, Step: 484/938, Loss: 0.00021212940919212997\n",
            "Epoch: 8/10, Step: 485/938, Loss: 3.767107773455791e-05\n",
            "Epoch: 8/10, Step: 486/938, Loss: 0.00048496670206077397\n",
            "Epoch: 8/10, Step: 487/938, Loss: 4.365928907645866e-05\n",
            "Epoch: 8/10, Step: 488/938, Loss: 6.84806946082972e-05\n",
            "Epoch: 8/10, Step: 489/938, Loss: 3.7570076528936625e-05\n",
            "Epoch: 8/10, Step: 490/938, Loss: 0.010834798216819763\n",
            "Epoch: 8/10, Step: 491/938, Loss: 4.9931742978515103e-05\n",
            "Epoch: 8/10, Step: 492/938, Loss: 8.185421756934375e-05\n",
            "Epoch: 8/10, Step: 493/938, Loss: 0.004015542101114988\n",
            "Epoch: 8/10, Step: 494/938, Loss: 0.06296897679567337\n",
            "Epoch: 8/10, Step: 495/938, Loss: 0.009751129895448685\n",
            "Epoch: 8/10, Step: 496/938, Loss: 0.0010446012020111084\n",
            "Epoch: 8/10, Step: 497/938, Loss: 0.00026009598514065146\n",
            "Epoch: 8/10, Step: 498/938, Loss: 0.015871092677116394\n",
            "Epoch: 8/10, Step: 499/938, Loss: 0.00015934927796479315\n",
            "Epoch: 8/10, Step: 500/938, Loss: 0.0074729593470692635\n",
            "Epoch: 8/10, Step: 501/938, Loss: 0.0006347146118059754\n",
            "Epoch: 8/10, Step: 502/938, Loss: 6.025400216458365e-05\n",
            "Epoch: 8/10, Step: 503/938, Loss: 0.05363735556602478\n",
            "Epoch: 8/10, Step: 504/938, Loss: 0.0004139132215641439\n",
            "Epoch: 8/10, Step: 505/938, Loss: 0.007146146148443222\n",
            "Epoch: 8/10, Step: 506/938, Loss: 0.0073058223351836205\n",
            "Epoch: 8/10, Step: 507/938, Loss: 0.022400304675102234\n",
            "Epoch: 8/10, Step: 508/938, Loss: 0.00017675419803708792\n",
            "Epoch: 8/10, Step: 509/938, Loss: 0.0003686976560857147\n",
            "Epoch: 8/10, Step: 510/938, Loss: 0.000573860015720129\n",
            "Epoch: 8/10, Step: 511/938, Loss: 3.341969568282366e-05\n",
            "Epoch: 8/10, Step: 512/938, Loss: 0.0013241677079349756\n",
            "Epoch: 8/10, Step: 513/938, Loss: 0.000676399446092546\n",
            "Epoch: 8/10, Step: 514/938, Loss: 0.0021696900948882103\n",
            "Epoch: 8/10, Step: 515/938, Loss: 0.0011327080428600311\n",
            "Epoch: 8/10, Step: 516/938, Loss: 0.003181010950356722\n",
            "Epoch: 8/10, Step: 517/938, Loss: 0.00012837775284424424\n",
            "Epoch: 8/10, Step: 518/938, Loss: 0.0006043257308192551\n",
            "Epoch: 8/10, Step: 519/938, Loss: 0.016640635207295418\n",
            "Epoch: 8/10, Step: 520/938, Loss: 2.0632287487387657e-05\n",
            "Epoch: 8/10, Step: 521/938, Loss: 0.0002962829894386232\n",
            "Epoch: 8/10, Step: 522/938, Loss: 0.0003811641363427043\n",
            "Epoch: 8/10, Step: 523/938, Loss: 0.0012525400379672647\n",
            "Epoch: 8/10, Step: 524/938, Loss: 0.00036541541339829564\n",
            "Epoch: 8/10, Step: 525/938, Loss: 0.03224901854991913\n",
            "Epoch: 8/10, Step: 526/938, Loss: 0.0008686170913279057\n",
            "Epoch: 8/10, Step: 527/938, Loss: 0.006024048198014498\n",
            "Epoch: 8/10, Step: 528/938, Loss: 5.820072328788228e-05\n",
            "Epoch: 8/10, Step: 529/938, Loss: 0.0010937964543700218\n",
            "Epoch: 8/10, Step: 530/938, Loss: 0.00013835953723173589\n",
            "Epoch: 8/10, Step: 531/938, Loss: 0.0014253307599574327\n",
            "Epoch: 8/10, Step: 532/938, Loss: 0.0003478915605228394\n",
            "Epoch: 8/10, Step: 533/938, Loss: 0.0016487134853377938\n",
            "Epoch: 8/10, Step: 534/938, Loss: 0.0001444518711650744\n",
            "Epoch: 8/10, Step: 535/938, Loss: 1.632513158256188e-05\n",
            "Epoch: 8/10, Step: 536/938, Loss: 8.076900121523067e-05\n",
            "Epoch: 8/10, Step: 537/938, Loss: 0.006102538201957941\n",
            "Epoch: 8/10, Step: 538/938, Loss: 0.036212578415870667\n",
            "Epoch: 8/10, Step: 539/938, Loss: 0.0035270957741886377\n",
            "Epoch: 8/10, Step: 540/938, Loss: 5.954485823167488e-05\n",
            "Epoch: 8/10, Step: 541/938, Loss: 5.5143755162134767e-05\n",
            "Epoch: 8/10, Step: 542/938, Loss: 0.0008530794875696301\n",
            "Epoch: 8/10, Step: 543/938, Loss: 3.344488504808396e-05\n",
            "Epoch: 8/10, Step: 544/938, Loss: 0.00014254273264668882\n",
            "Epoch: 8/10, Step: 545/938, Loss: 0.03131108358502388\n",
            "Epoch: 8/10, Step: 546/938, Loss: 0.0025840422604233027\n",
            "Epoch: 8/10, Step: 547/938, Loss: 0.013077914714813232\n",
            "Epoch: 8/10, Step: 548/938, Loss: 0.016691263765096664\n",
            "Epoch: 8/10, Step: 549/938, Loss: 0.0027023705188184977\n",
            "Epoch: 8/10, Step: 550/938, Loss: 0.010649674572050571\n",
            "Epoch: 8/10, Step: 551/938, Loss: 3.3371678000548854e-05\n",
            "Epoch: 8/10, Step: 552/938, Loss: 2.5921739506884478e-05\n",
            "Epoch: 8/10, Step: 553/938, Loss: 0.000977354939095676\n",
            "Epoch: 8/10, Step: 554/938, Loss: 1.1252570402575657e-05\n",
            "Epoch: 8/10, Step: 555/938, Loss: 6.455280527006835e-05\n",
            "Epoch: 8/10, Step: 556/938, Loss: 1.673697443038691e-05\n",
            "Epoch: 8/10, Step: 557/938, Loss: 0.0025475467555224895\n",
            "Epoch: 8/10, Step: 558/938, Loss: 0.00011995340173598379\n",
            "Epoch: 8/10, Step: 559/938, Loss: 0.053786180913448334\n",
            "Epoch: 8/10, Step: 560/938, Loss: 0.000567849725484848\n",
            "Epoch: 8/10, Step: 561/938, Loss: 0.00703837163746357\n",
            "Epoch: 8/10, Step: 562/938, Loss: 0.06535866111516953\n",
            "Epoch: 8/10, Step: 563/938, Loss: 2.5368324713781476e-05\n",
            "Epoch: 8/10, Step: 564/938, Loss: 0.0014120745472609997\n",
            "Epoch: 8/10, Step: 565/938, Loss: 0.00024950853548943996\n",
            "Epoch: 8/10, Step: 566/938, Loss: 0.046842873096466064\n",
            "Epoch: 8/10, Step: 567/938, Loss: 0.0006761800614185631\n",
            "Epoch: 8/10, Step: 568/938, Loss: 4.698262637248263e-05\n",
            "Epoch: 8/10, Step: 569/938, Loss: 0.0024221704807132483\n",
            "Epoch: 8/10, Step: 570/938, Loss: 0.0372372530400753\n",
            "Epoch: 8/10, Step: 571/938, Loss: 2.6553316274657845e-05\n",
            "Epoch: 8/10, Step: 572/938, Loss: 0.00022530867136083543\n",
            "Epoch: 8/10, Step: 573/938, Loss: 5.314861482474953e-05\n",
            "Epoch: 8/10, Step: 574/938, Loss: 0.0004974217736162245\n",
            "Epoch: 8/10, Step: 575/938, Loss: 0.009663029573857784\n",
            "Epoch: 8/10, Step: 576/938, Loss: 7.273052688105963e-06\n",
            "Epoch: 8/10, Step: 577/938, Loss: 0.029149537906050682\n",
            "Epoch: 8/10, Step: 578/938, Loss: 0.0005844850093126297\n",
            "Epoch: 8/10, Step: 579/938, Loss: 0.10056371241807938\n",
            "Epoch: 8/10, Step: 580/938, Loss: 0.0002234310086350888\n",
            "Epoch: 8/10, Step: 581/938, Loss: 0.01667832024395466\n",
            "Epoch: 8/10, Step: 582/938, Loss: 0.01125534437596798\n",
            "Epoch: 8/10, Step: 583/938, Loss: 1.4616909538744949e-05\n",
            "Epoch: 8/10, Step: 584/938, Loss: 0.024432552978396416\n",
            "Epoch: 8/10, Step: 585/938, Loss: 0.0001703286834526807\n",
            "Epoch: 8/10, Step: 586/938, Loss: 0.0004631472984328866\n",
            "Epoch: 8/10, Step: 587/938, Loss: 0.022324208170175552\n",
            "Epoch: 8/10, Step: 588/938, Loss: 0.017546948045492172\n",
            "Epoch: 8/10, Step: 589/938, Loss: 0.00043342227581888437\n",
            "Epoch: 8/10, Step: 590/938, Loss: 0.00022292397625278682\n",
            "Epoch: 8/10, Step: 591/938, Loss: 0.00010053928417619318\n",
            "Epoch: 8/10, Step: 592/938, Loss: 0.000265326612861827\n",
            "Epoch: 8/10, Step: 593/938, Loss: 0.10020101070404053\n",
            "Epoch: 8/10, Step: 594/938, Loss: 0.008759694173932076\n",
            "Epoch: 8/10, Step: 595/938, Loss: 0.0001253164664376527\n",
            "Epoch: 8/10, Step: 596/938, Loss: 0.03186705708503723\n",
            "Epoch: 8/10, Step: 597/938, Loss: 0.0004587478470057249\n",
            "Epoch: 8/10, Step: 598/938, Loss: 0.007007638458162546\n",
            "Epoch: 8/10, Step: 599/938, Loss: 1.8054002794087864e-05\n",
            "Epoch: 8/10, Step: 600/938, Loss: 0.003998630680143833\n",
            "Epoch: 8/10, Step: 601/938, Loss: 0.0011824987595900893\n",
            "Epoch: 8/10, Step: 602/938, Loss: 0.007950016297399998\n",
            "Epoch: 8/10, Step: 603/938, Loss: 0.001857523457147181\n",
            "Epoch: 8/10, Step: 604/938, Loss: 0.00020097185915801674\n",
            "Epoch: 8/10, Step: 605/938, Loss: 0.0003279307275079191\n",
            "Epoch: 8/10, Step: 606/938, Loss: 0.0006654795724898577\n",
            "Epoch: 8/10, Step: 607/938, Loss: 0.0014750403352081776\n",
            "Epoch: 8/10, Step: 608/938, Loss: 0.0002884448040276766\n",
            "Epoch: 8/10, Step: 609/938, Loss: 7.127499702619389e-05\n",
            "Epoch: 8/10, Step: 610/938, Loss: 0.00034993398003280163\n",
            "Epoch: 8/10, Step: 611/938, Loss: 0.0001558856456540525\n",
            "Epoch: 8/10, Step: 612/938, Loss: 0.0007230598130263388\n",
            "Epoch: 8/10, Step: 613/938, Loss: 0.018211817368865013\n",
            "Epoch: 8/10, Step: 614/938, Loss: 0.01241141464561224\n",
            "Epoch: 8/10, Step: 615/938, Loss: 0.0005769392591901124\n",
            "Epoch: 8/10, Step: 616/938, Loss: 0.0007395499851554632\n",
            "Epoch: 8/10, Step: 617/938, Loss: 0.02775055542588234\n",
            "Epoch: 8/10, Step: 618/938, Loss: 0.00450629647821188\n",
            "Epoch: 8/10, Step: 619/938, Loss: 0.00013754048268310726\n",
            "Epoch: 8/10, Step: 620/938, Loss: 0.00116463762242347\n",
            "Epoch: 8/10, Step: 621/938, Loss: 0.006324088666588068\n",
            "Epoch: 8/10, Step: 622/938, Loss: 0.040443744510412216\n",
            "Epoch: 8/10, Step: 623/938, Loss: 0.000451950152637437\n",
            "Epoch: 8/10, Step: 624/938, Loss: 5.5181939387694e-05\n",
            "Epoch: 8/10, Step: 625/938, Loss: 0.0011137275723740458\n",
            "Epoch: 8/10, Step: 626/938, Loss: 0.002664357889443636\n",
            "Epoch: 8/10, Step: 627/938, Loss: 5.642970427288674e-05\n",
            "Epoch: 8/10, Step: 628/938, Loss: 0.005542828235775232\n",
            "Epoch: 8/10, Step: 629/938, Loss: 0.020273717120289803\n",
            "Epoch: 8/10, Step: 630/938, Loss: 9.323640551883727e-05\n",
            "Epoch: 8/10, Step: 631/938, Loss: 0.03291645273566246\n",
            "Epoch: 8/10, Step: 632/938, Loss: 6.934491830179468e-05\n",
            "Epoch: 8/10, Step: 633/938, Loss: 0.0006405970780178905\n",
            "Epoch: 8/10, Step: 634/938, Loss: 0.00012029174831695855\n",
            "Epoch: 8/10, Step: 635/938, Loss: 0.00020134366059210151\n",
            "Epoch: 8/10, Step: 636/938, Loss: 0.07793256640434265\n",
            "Epoch: 8/10, Step: 637/938, Loss: 0.00038627319736406207\n",
            "Epoch: 8/10, Step: 638/938, Loss: 5.389644138631411e-05\n",
            "Epoch: 8/10, Step: 639/938, Loss: 0.00011615623952820897\n",
            "Epoch: 8/10, Step: 640/938, Loss: 0.0009552892879582942\n",
            "Epoch: 8/10, Step: 641/938, Loss: 0.0013528969138860703\n",
            "Epoch: 8/10, Step: 642/938, Loss: 0.028742849826812744\n",
            "Epoch: 8/10, Step: 643/938, Loss: 0.019230356439948082\n",
            "Epoch: 8/10, Step: 644/938, Loss: 0.0011741728521883488\n",
            "Epoch: 8/10, Step: 645/938, Loss: 0.004336258862167597\n",
            "Epoch: 8/10, Step: 646/938, Loss: 0.03216575086116791\n",
            "Epoch: 8/10, Step: 647/938, Loss: 0.002818610053509474\n",
            "Epoch: 8/10, Step: 648/938, Loss: 0.0002010740718105808\n",
            "Epoch: 8/10, Step: 649/938, Loss: 0.0033116424456238747\n",
            "Epoch: 8/10, Step: 650/938, Loss: 0.04144543781876564\n",
            "Epoch: 8/10, Step: 651/938, Loss: 0.00288544618524611\n",
            "Epoch: 8/10, Step: 652/938, Loss: 5.793078526039608e-05\n",
            "Epoch: 8/10, Step: 653/938, Loss: 0.0001833935675676912\n",
            "Epoch: 8/10, Step: 654/938, Loss: 0.02240920066833496\n",
            "Epoch: 8/10, Step: 655/938, Loss: 0.0008372444426640868\n",
            "Epoch: 8/10, Step: 656/938, Loss: 0.00014944370195735246\n",
            "Epoch: 8/10, Step: 657/938, Loss: 2.75754264293937e-05\n",
            "Epoch: 8/10, Step: 658/938, Loss: 0.0014322743518278003\n",
            "Epoch: 8/10, Step: 659/938, Loss: 0.11291273683309555\n",
            "Epoch: 8/10, Step: 660/938, Loss: 5.913624590903055e-06\n",
            "Epoch: 8/10, Step: 661/938, Loss: 6.15297321928665e-05\n",
            "Epoch: 8/10, Step: 662/938, Loss: 2.3583437723573297e-05\n",
            "Epoch: 8/10, Step: 663/938, Loss: 1.7219233996002004e-05\n",
            "Epoch: 8/10, Step: 664/938, Loss: 0.000263480469584465\n",
            "Epoch: 8/10, Step: 665/938, Loss: 1.0334661965316627e-05\n",
            "Epoch: 8/10, Step: 666/938, Loss: 0.15942345559597015\n",
            "Epoch: 8/10, Step: 667/938, Loss: 0.0020295092836022377\n",
            "Epoch: 8/10, Step: 668/938, Loss: 0.003184544388204813\n",
            "Epoch: 8/10, Step: 669/938, Loss: 0.01251615583896637\n",
            "Epoch: 8/10, Step: 670/938, Loss: 6.292266334639862e-05\n",
            "Epoch: 8/10, Step: 671/938, Loss: 0.00033637642627581954\n",
            "Epoch: 8/10, Step: 672/938, Loss: 0.00012824544683098793\n",
            "Epoch: 8/10, Step: 673/938, Loss: 0.0015148165402933955\n",
            "Epoch: 8/10, Step: 674/938, Loss: 0.05873778462409973\n",
            "Epoch: 8/10, Step: 675/938, Loss: 8.19471970316954e-05\n",
            "Epoch: 8/10, Step: 676/938, Loss: 0.09035327285528183\n",
            "Epoch: 8/10, Step: 677/938, Loss: 0.00013132912863511592\n",
            "Epoch: 8/10, Step: 678/938, Loss: 0.005045575555413961\n",
            "Epoch: 8/10, Step: 679/938, Loss: 0.00013933425361756235\n",
            "Epoch: 8/10, Step: 680/938, Loss: 0.036668650805950165\n",
            "Epoch: 8/10, Step: 681/938, Loss: 0.0009726784192025661\n",
            "Epoch: 8/10, Step: 682/938, Loss: 0.007537778001278639\n",
            "Epoch: 8/10, Step: 683/938, Loss: 0.01290240976959467\n",
            "Epoch: 8/10, Step: 684/938, Loss: 0.01694534346461296\n",
            "Epoch: 8/10, Step: 685/938, Loss: 0.00012698756472673267\n",
            "Epoch: 8/10, Step: 686/938, Loss: 0.07288961857557297\n",
            "Epoch: 8/10, Step: 687/938, Loss: 0.0010139296064153314\n",
            "Epoch: 8/10, Step: 688/938, Loss: 0.00042475949157960713\n",
            "Epoch: 8/10, Step: 689/938, Loss: 0.01568547822535038\n",
            "Epoch: 8/10, Step: 690/938, Loss: 0.010231704451143742\n",
            "Epoch: 8/10, Step: 691/938, Loss: 0.00010913726146100089\n",
            "Epoch: 8/10, Step: 692/938, Loss: 0.03675880283117294\n",
            "Epoch: 8/10, Step: 693/938, Loss: 0.0005909546744078398\n",
            "Epoch: 8/10, Step: 694/938, Loss: 0.0002402552345301956\n",
            "Epoch: 8/10, Step: 695/938, Loss: 0.04199539124965668\n",
            "Epoch: 8/10, Step: 696/938, Loss: 0.010450351051986217\n",
            "Epoch: 8/10, Step: 697/938, Loss: 2.6801455533131957e-05\n",
            "Epoch: 8/10, Step: 698/938, Loss: 0.0008925849106162786\n",
            "Epoch: 8/10, Step: 699/938, Loss: 0.0010680307168513536\n",
            "Epoch: 8/10, Step: 700/938, Loss: 1.352263552689692e-05\n",
            "Epoch: 8/10, Step: 701/938, Loss: 1.749186048982665e-05\n",
            "Epoch: 8/10, Step: 702/938, Loss: 0.04096798598766327\n",
            "Epoch: 8/10, Step: 703/938, Loss: 0.0012239937204867601\n",
            "Epoch: 8/10, Step: 704/938, Loss: 0.0005904790014028549\n",
            "Epoch: 8/10, Step: 705/938, Loss: 0.020137593150138855\n",
            "Epoch: 8/10, Step: 706/938, Loss: 8.403773244936019e-05\n",
            "Epoch: 8/10, Step: 707/938, Loss: 0.0002094510564347729\n",
            "Epoch: 8/10, Step: 708/938, Loss: 0.00028530845884233713\n",
            "Epoch: 8/10, Step: 709/938, Loss: 0.0005666656070388854\n",
            "Epoch: 8/10, Step: 710/938, Loss: 0.002001758897677064\n",
            "Epoch: 8/10, Step: 711/938, Loss: 1.8715018086368218e-05\n",
            "Epoch: 8/10, Step: 712/938, Loss: 5.151653749635443e-05\n",
            "Epoch: 8/10, Step: 713/938, Loss: 1.962378155440092e-05\n",
            "Epoch: 8/10, Step: 714/938, Loss: 0.0013875087024644017\n",
            "Epoch: 8/10, Step: 715/938, Loss: 0.0003259794902987778\n",
            "Epoch: 8/10, Step: 716/938, Loss: 0.011646305210888386\n",
            "Epoch: 8/10, Step: 717/938, Loss: 0.0024801339022815228\n",
            "Epoch: 8/10, Step: 718/938, Loss: 0.03853327035903931\n",
            "Epoch: 8/10, Step: 719/938, Loss: 0.010754294693470001\n",
            "Epoch: 8/10, Step: 720/938, Loss: 2.6180130589636974e-05\n",
            "Epoch: 8/10, Step: 721/938, Loss: 0.0017524672439321876\n",
            "Epoch: 8/10, Step: 722/938, Loss: 0.0009301674435846508\n",
            "Epoch: 8/10, Step: 723/938, Loss: 0.0046558985486626625\n",
            "Epoch: 8/10, Step: 724/938, Loss: 0.0010729738278314471\n",
            "Epoch: 8/10, Step: 725/938, Loss: 0.00017101605772040784\n",
            "Epoch: 8/10, Step: 726/938, Loss: 0.0009564271313138306\n",
            "Epoch: 8/10, Step: 727/938, Loss: 0.0007557126809842885\n",
            "Epoch: 8/10, Step: 728/938, Loss: 0.0049718390218913555\n",
            "Epoch: 8/10, Step: 729/938, Loss: 0.0003777354140765965\n",
            "Epoch: 8/10, Step: 730/938, Loss: 0.038787487894296646\n",
            "Epoch: 8/10, Step: 731/938, Loss: 0.03883850574493408\n",
            "Epoch: 8/10, Step: 732/938, Loss: 0.0001962091337190941\n",
            "Epoch: 8/10, Step: 733/938, Loss: 0.015928879380226135\n",
            "Epoch: 8/10, Step: 734/938, Loss: 0.000350715359672904\n",
            "Epoch: 8/10, Step: 735/938, Loss: 0.024450769647955894\n",
            "Epoch: 8/10, Step: 736/938, Loss: 0.00010646211012499407\n",
            "Epoch: 8/10, Step: 737/938, Loss: 0.0003369068435858935\n",
            "Epoch: 8/10, Step: 738/938, Loss: 0.0004781995667144656\n",
            "Epoch: 8/10, Step: 739/938, Loss: 0.0026766916271299124\n",
            "Epoch: 8/10, Step: 740/938, Loss: 0.02319515496492386\n",
            "Epoch: 8/10, Step: 741/938, Loss: 0.00012122598855057731\n",
            "Epoch: 8/10, Step: 742/938, Loss: 0.00013134817709214985\n",
            "Epoch: 8/10, Step: 743/938, Loss: 2.5698829631437548e-05\n",
            "Epoch: 8/10, Step: 744/938, Loss: 5.9291793149895966e-05\n",
            "Epoch: 8/10, Step: 745/938, Loss: 0.00046884798211976886\n",
            "Epoch: 8/10, Step: 746/938, Loss: 0.00035551731707528234\n",
            "Epoch: 8/10, Step: 747/938, Loss: 0.00013800765736959875\n",
            "Epoch: 8/10, Step: 748/938, Loss: 0.01032073050737381\n",
            "Epoch: 8/10, Step: 749/938, Loss: 0.004441149532794952\n",
            "Epoch: 8/10, Step: 750/938, Loss: 0.000392366957385093\n",
            "Epoch: 8/10, Step: 751/938, Loss: 0.0013901828788220882\n",
            "Epoch: 8/10, Step: 752/938, Loss: 0.005731281824409962\n",
            "Epoch: 8/10, Step: 753/938, Loss: 0.0015975015703588724\n",
            "Epoch: 8/10, Step: 754/938, Loss: 0.004749371204525232\n",
            "Epoch: 8/10, Step: 755/938, Loss: 0.0040896255522966385\n",
            "Epoch: 8/10, Step: 756/938, Loss: 0.00014268724771682173\n",
            "Epoch: 8/10, Step: 757/938, Loss: 0.0032857765909284353\n",
            "Epoch: 8/10, Step: 758/938, Loss: 0.0007481324719265103\n",
            "Epoch: 8/10, Step: 759/938, Loss: 0.000231628175242804\n",
            "Epoch: 8/10, Step: 760/938, Loss: 1.5360317775048316e-05\n",
            "Epoch: 8/10, Step: 761/938, Loss: 0.01194254495203495\n",
            "Epoch: 8/10, Step: 762/938, Loss: 0.04733537137508392\n",
            "Epoch: 8/10, Step: 763/938, Loss: 1.4975544218032155e-06\n",
            "Epoch: 8/10, Step: 764/938, Loss: 0.0003372549545019865\n",
            "Epoch: 8/10, Step: 765/938, Loss: 7.401999755529687e-05\n",
            "Epoch: 8/10, Step: 766/938, Loss: 5.2456209232332185e-05\n",
            "Epoch: 8/10, Step: 767/938, Loss: 7.16859576641582e-05\n",
            "Epoch: 8/10, Step: 768/938, Loss: 0.00022571219597011805\n",
            "Epoch: 8/10, Step: 769/938, Loss: 0.01313853170722723\n",
            "Epoch: 8/10, Step: 770/938, Loss: 4.7690289648016915e-05\n",
            "Epoch: 8/10, Step: 771/938, Loss: 0.000358969991793856\n",
            "Epoch: 8/10, Step: 772/938, Loss: 9.129113459493965e-05\n",
            "Epoch: 8/10, Step: 773/938, Loss: 4.336899291956797e-05\n",
            "Epoch: 8/10, Step: 774/938, Loss: 0.0035235907416790724\n",
            "Epoch: 8/10, Step: 775/938, Loss: 0.0019291676580905914\n",
            "Epoch: 8/10, Step: 776/938, Loss: 0.0019766567274928093\n",
            "Epoch: 8/10, Step: 777/938, Loss: 0.00015283044194802642\n",
            "Epoch: 8/10, Step: 778/938, Loss: 0.00378796155564487\n",
            "Epoch: 8/10, Step: 779/938, Loss: 2.511417005734984e-05\n",
            "Epoch: 8/10, Step: 780/938, Loss: 0.001025466830469668\n",
            "Epoch: 8/10, Step: 781/938, Loss: 0.008535709232091904\n",
            "Epoch: 8/10, Step: 782/938, Loss: 0.0006029290379956365\n",
            "Epoch: 8/10, Step: 783/938, Loss: 0.0014940291875973344\n",
            "Epoch: 8/10, Step: 784/938, Loss: 0.000155881600221619\n",
            "Epoch: 8/10, Step: 785/938, Loss: 0.006123068742454052\n",
            "Epoch: 8/10, Step: 786/938, Loss: 0.0014961609849706292\n",
            "Epoch: 8/10, Step: 787/938, Loss: 4.020289998152293e-05\n",
            "Epoch: 8/10, Step: 788/938, Loss: 0.004463868215680122\n",
            "Epoch: 8/10, Step: 789/938, Loss: 2.0581746866810136e-06\n",
            "Epoch: 8/10, Step: 790/938, Loss: 4.156813884037547e-05\n",
            "Epoch: 8/10, Step: 791/938, Loss: 0.0740554928779602\n",
            "Epoch: 8/10, Step: 792/938, Loss: 0.0008265469805337489\n",
            "Epoch: 8/10, Step: 793/938, Loss: 0.0005311150453053415\n",
            "Epoch: 8/10, Step: 794/938, Loss: 0.0003397803520783782\n",
            "Epoch: 8/10, Step: 795/938, Loss: 0.0009501738240942359\n",
            "Epoch: 8/10, Step: 796/938, Loss: 6.708200817229226e-05\n",
            "Epoch: 8/10, Step: 797/938, Loss: 0.00046665396075695753\n",
            "Epoch: 8/10, Step: 798/938, Loss: 0.0007194802747108042\n",
            "Epoch: 8/10, Step: 799/938, Loss: 8.999597775982693e-05\n",
            "Epoch: 8/10, Step: 800/938, Loss: 0.0006402706494554877\n",
            "Epoch: 8/10, Step: 801/938, Loss: 2.228644189017359e-05\n",
            "Epoch: 8/10, Step: 802/938, Loss: 0.00013915725867263973\n",
            "Epoch: 8/10, Step: 803/938, Loss: 0.0011209261137992144\n",
            "Epoch: 8/10, Step: 804/938, Loss: 0.00040055601857602596\n",
            "Epoch: 8/10, Step: 805/938, Loss: 0.0009430353529751301\n",
            "Epoch: 8/10, Step: 806/938, Loss: 6.920710438862443e-05\n",
            "Epoch: 8/10, Step: 807/938, Loss: 1.2114907804061659e-05\n",
            "Epoch: 8/10, Step: 808/938, Loss: 0.00011234104022150859\n",
            "Epoch: 8/10, Step: 809/938, Loss: 0.00012171238631708547\n",
            "Epoch: 8/10, Step: 810/938, Loss: 0.004025008529424667\n",
            "Epoch: 8/10, Step: 811/938, Loss: 0.000205205287784338\n",
            "Epoch: 8/10, Step: 812/938, Loss: 0.0008863168768584728\n",
            "Epoch: 8/10, Step: 813/938, Loss: 0.0020976532250642776\n",
            "Epoch: 8/10, Step: 814/938, Loss: 2.9680739316972904e-05\n",
            "Epoch: 8/10, Step: 815/938, Loss: 0.0005919139366596937\n",
            "Epoch: 8/10, Step: 816/938, Loss: 6.725804996676743e-05\n",
            "Epoch: 8/10, Step: 817/938, Loss: 0.02192125841975212\n",
            "Epoch: 8/10, Step: 818/938, Loss: 0.011189261451363564\n",
            "Epoch: 8/10, Step: 819/938, Loss: 0.013363135047256947\n",
            "Epoch: 8/10, Step: 820/938, Loss: 0.00011566701141418889\n",
            "Epoch: 8/10, Step: 821/938, Loss: 0.00404181657359004\n",
            "Epoch: 8/10, Step: 822/938, Loss: 0.00025183428078889847\n",
            "Epoch: 8/10, Step: 823/938, Loss: 0.1566496193408966\n",
            "Epoch: 8/10, Step: 824/938, Loss: 0.00019685209554154426\n",
            "Epoch: 8/10, Step: 825/938, Loss: 5.1511629862943664e-05\n",
            "Epoch: 8/10, Step: 826/938, Loss: 0.00020576150564011186\n",
            "Epoch: 8/10, Step: 827/938, Loss: 0.0004288373456802219\n",
            "Epoch: 8/10, Step: 828/938, Loss: 0.00017876857600640506\n",
            "Epoch: 8/10, Step: 829/938, Loss: 0.0033516553230583668\n",
            "Epoch: 8/10, Step: 830/938, Loss: 0.0029631566721946\n",
            "Epoch: 8/10, Step: 831/938, Loss: 6.439474964281544e-05\n",
            "Epoch: 8/10, Step: 832/938, Loss: 0.00011019268276868388\n",
            "Epoch: 8/10, Step: 833/938, Loss: 0.0013930769637227058\n",
            "Epoch: 8/10, Step: 834/938, Loss: 0.0003435587859712541\n",
            "Epoch: 8/10, Step: 835/938, Loss: 0.0025678053498268127\n",
            "Epoch: 8/10, Step: 836/938, Loss: 0.002085698302835226\n",
            "Epoch: 8/10, Step: 837/938, Loss: 0.032810747623443604\n",
            "Epoch: 8/10, Step: 838/938, Loss: 0.03226707503199577\n",
            "Epoch: 8/10, Step: 839/938, Loss: 0.09842733293771744\n",
            "Epoch: 8/10, Step: 840/938, Loss: 0.0018367588054388762\n",
            "Epoch: 8/10, Step: 841/938, Loss: 0.006943968124687672\n",
            "Epoch: 8/10, Step: 842/938, Loss: 0.00010887689131777734\n",
            "Epoch: 8/10, Step: 843/938, Loss: 0.013600436970591545\n",
            "Epoch: 8/10, Step: 844/938, Loss: 0.16047437489032745\n",
            "Epoch: 8/10, Step: 845/938, Loss: 0.000339770398568362\n",
            "Epoch: 8/10, Step: 846/938, Loss: 0.00043071320396848023\n",
            "Epoch: 8/10, Step: 847/938, Loss: 0.0011184093309566379\n",
            "Epoch: 8/10, Step: 848/938, Loss: 8.454983617411926e-05\n",
            "Epoch: 8/10, Step: 849/938, Loss: 0.00046058872248977423\n",
            "Epoch: 8/10, Step: 850/938, Loss: 0.0031125727109611034\n",
            "Epoch: 8/10, Step: 851/938, Loss: 0.014171894639730453\n",
            "Epoch: 8/10, Step: 852/938, Loss: 1.2590410733537283e-05\n",
            "Epoch: 8/10, Step: 853/938, Loss: 0.007871471345424652\n",
            "Epoch: 8/10, Step: 854/938, Loss: 0.0009113730629906058\n",
            "Epoch: 8/10, Step: 855/938, Loss: 0.040257442742586136\n",
            "Epoch: 8/10, Step: 856/938, Loss: 0.0013774731196463108\n",
            "Epoch: 8/10, Step: 857/938, Loss: 0.0001296944246860221\n",
            "Epoch: 8/10, Step: 858/938, Loss: 3.409760392969474e-05\n",
            "Epoch: 8/10, Step: 859/938, Loss: 0.005277440883219242\n",
            "Epoch: 8/10, Step: 860/938, Loss: 0.0010726761538535357\n",
            "Epoch: 8/10, Step: 861/938, Loss: 0.005758483428508043\n",
            "Epoch: 8/10, Step: 862/938, Loss: 0.00024883003789000213\n",
            "Epoch: 8/10, Step: 863/938, Loss: 0.13489432632923126\n",
            "Epoch: 8/10, Step: 864/938, Loss: 0.002112129470333457\n",
            "Epoch: 8/10, Step: 865/938, Loss: 0.0045395768247544765\n",
            "Epoch: 8/10, Step: 866/938, Loss: 0.000106915453216061\n",
            "Epoch: 8/10, Step: 867/938, Loss: 0.00015813282516319305\n",
            "Epoch: 8/10, Step: 868/938, Loss: 0.00027647422393783927\n",
            "Epoch: 8/10, Step: 869/938, Loss: 0.0010894723236560822\n",
            "Epoch: 8/10, Step: 870/938, Loss: 1.0647707313182764e-05\n",
            "Epoch: 8/10, Step: 871/938, Loss: 0.0025105152744799852\n",
            "Epoch: 8/10, Step: 872/938, Loss: 0.0023596202954649925\n",
            "Epoch: 8/10, Step: 873/938, Loss: 3.343806019984186e-05\n",
            "Epoch: 8/10, Step: 874/938, Loss: 9.872766531771049e-05\n",
            "Epoch: 8/10, Step: 875/938, Loss: 0.0007003410719335079\n",
            "Epoch: 8/10, Step: 876/938, Loss: 0.0006859186687506735\n",
            "Epoch: 8/10, Step: 877/938, Loss: 0.0002630117232911289\n",
            "Epoch: 8/10, Step: 878/938, Loss: 0.009568609297275543\n",
            "Epoch: 8/10, Step: 879/938, Loss: 0.004299687221646309\n",
            "Epoch: 8/10, Step: 880/938, Loss: 0.00036426750011742115\n",
            "Epoch: 8/10, Step: 881/938, Loss: 0.0004401531768962741\n",
            "Epoch: 8/10, Step: 882/938, Loss: 8.117136894725263e-05\n",
            "Epoch: 8/10, Step: 883/938, Loss: 0.00019026786321774125\n",
            "Epoch: 8/10, Step: 884/938, Loss: 0.008656719699501991\n",
            "Epoch: 8/10, Step: 885/938, Loss: 0.09149444103240967\n",
            "Epoch: 8/10, Step: 886/938, Loss: 0.018712831661105156\n",
            "Epoch: 8/10, Step: 887/938, Loss: 8.140269346768036e-05\n",
            "Epoch: 8/10, Step: 888/938, Loss: 0.0006442015874199569\n",
            "Epoch: 8/10, Step: 889/938, Loss: 0.0036409583408385515\n",
            "Epoch: 8/10, Step: 890/938, Loss: 0.08898988366127014\n",
            "Epoch: 8/10, Step: 891/938, Loss: 0.07644040882587433\n",
            "Epoch: 8/10, Step: 892/938, Loss: 0.00029856013134121895\n",
            "Epoch: 8/10, Step: 893/938, Loss: 0.023076601326465607\n",
            "Epoch: 8/10, Step: 894/938, Loss: 0.0016745042521506548\n",
            "Epoch: 8/10, Step: 895/938, Loss: 0.047212760895490646\n",
            "Epoch: 8/10, Step: 896/938, Loss: 0.050410326570272446\n",
            "Epoch: 8/10, Step: 897/938, Loss: 3.112521153525449e-05\n",
            "Epoch: 8/10, Step: 898/938, Loss: 0.0003166234237141907\n",
            "Epoch: 8/10, Step: 899/938, Loss: 0.0015908248024061322\n",
            "Epoch: 8/10, Step: 900/938, Loss: 0.04960406944155693\n",
            "Epoch: 8/10, Step: 901/938, Loss: 0.00028101273346692324\n",
            "Epoch: 8/10, Step: 902/938, Loss: 0.00028755259700119495\n",
            "Epoch: 8/10, Step: 903/938, Loss: 0.0038163766730576754\n",
            "Epoch: 8/10, Step: 904/938, Loss: 0.00014813886082265526\n",
            "Epoch: 8/10, Step: 905/938, Loss: 0.0007539334474131465\n",
            "Epoch: 8/10, Step: 906/938, Loss: 8.647728100186214e-05\n",
            "Epoch: 8/10, Step: 907/938, Loss: 0.00016238581156358123\n",
            "Epoch: 8/10, Step: 908/938, Loss: 0.0029936477076262236\n",
            "Epoch: 8/10, Step: 909/938, Loss: 0.00012130715185776353\n",
            "Epoch: 8/10, Step: 910/938, Loss: 0.0010914579033851624\n",
            "Epoch: 8/10, Step: 911/938, Loss: 0.00046955287689343095\n",
            "Epoch: 8/10, Step: 912/938, Loss: 0.0007564667612314224\n",
            "Epoch: 8/10, Step: 913/938, Loss: 0.0003836931718979031\n",
            "Epoch: 8/10, Step: 914/938, Loss: 0.0001587725564604625\n",
            "Epoch: 8/10, Step: 915/938, Loss: 5.667757068295032e-05\n",
            "Epoch: 8/10, Step: 916/938, Loss: 0.0035800973419100046\n",
            "Epoch: 8/10, Step: 917/938, Loss: 0.0003229315625503659\n",
            "Epoch: 8/10, Step: 918/938, Loss: 0.0010659241816028953\n",
            "Epoch: 8/10, Step: 919/938, Loss: 0.008273925632238388\n",
            "Epoch: 8/10, Step: 920/938, Loss: 6.668818969046697e-05\n",
            "Epoch: 8/10, Step: 921/938, Loss: 0.0013126154663041234\n",
            "Epoch: 8/10, Step: 922/938, Loss: 0.00040382426232099533\n",
            "Epoch: 8/10, Step: 923/938, Loss: 0.0023118231911212206\n",
            "Epoch: 8/10, Step: 924/938, Loss: 0.001570443855598569\n",
            "Epoch: 8/10, Step: 925/938, Loss: 5.0720445869956166e-05\n",
            "Epoch: 8/10, Step: 926/938, Loss: 0.001276135561056435\n",
            "Epoch: 8/10, Step: 927/938, Loss: 0.01933435909450054\n",
            "Epoch: 8/10, Step: 928/938, Loss: 0.00028524926165118814\n",
            "Epoch: 8/10, Step: 929/938, Loss: 1.877376598713454e-05\n",
            "Epoch: 8/10, Step: 930/938, Loss: 0.004216414410620928\n",
            "Epoch: 8/10, Step: 931/938, Loss: 0.011908633634448051\n",
            "Epoch: 8/10, Step: 932/938, Loss: 2.8489721444202587e-05\n",
            "Epoch: 8/10, Step: 933/938, Loss: 0.0031636201310902834\n",
            "Epoch: 8/10, Step: 934/938, Loss: 0.00022490427363663912\n",
            "Epoch: 8/10, Step: 935/938, Loss: 0.021385012194514275\n",
            "Epoch: 8/10, Step: 936/938, Loss: 0.005737238563597202\n",
            "Epoch: 8/10, Step: 937/938, Loss: 0.005230744369328022\n",
            "Epoch: 8/10, Step: 938/938, Loss: 0.00021947588538751006\n",
            "Epoch: 9/10, Step: 1/938, Loss: 0.0006053499528206885\n",
            "Epoch: 9/10, Step: 2/938, Loss: 3.09359711536672e-05\n",
            "Epoch: 9/10, Step: 3/938, Loss: 0.05046983063220978\n",
            "Epoch: 9/10, Step: 4/938, Loss: 0.00012184760998934507\n",
            "Epoch: 9/10, Step: 5/938, Loss: 0.003351747989654541\n",
            "Epoch: 9/10, Step: 6/938, Loss: 0.001246543019078672\n",
            "Epoch: 9/10, Step: 7/938, Loss: 0.0005170924123376608\n",
            "Epoch: 9/10, Step: 8/938, Loss: 0.0004068842390552163\n",
            "Epoch: 9/10, Step: 9/938, Loss: 0.01786937564611435\n",
            "Epoch: 9/10, Step: 10/938, Loss: 0.0011483965208753943\n",
            "Epoch: 9/10, Step: 11/938, Loss: 0.004000943154096603\n",
            "Epoch: 9/10, Step: 12/938, Loss: 2.0914434571750462e-05\n",
            "Epoch: 9/10, Step: 13/938, Loss: 0.0011308036046102643\n",
            "Epoch: 9/10, Step: 14/938, Loss: 0.0010307534830644727\n",
            "Epoch: 9/10, Step: 15/938, Loss: 0.001118360087275505\n",
            "Epoch: 9/10, Step: 16/938, Loss: 7.515380275435746e-06\n",
            "Epoch: 9/10, Step: 17/938, Loss: 0.0007134556653909385\n",
            "Epoch: 9/10, Step: 18/938, Loss: 6.199145718710497e-05\n",
            "Epoch: 9/10, Step: 19/938, Loss: 1.6025562217691913e-05\n",
            "Epoch: 9/10, Step: 20/938, Loss: 0.00018766921130008996\n",
            "Epoch: 9/10, Step: 21/938, Loss: 0.017907757312059402\n",
            "Epoch: 9/10, Step: 22/938, Loss: 2.0114064682275057e-05\n",
            "Epoch: 9/10, Step: 23/938, Loss: 0.00012296243221499026\n",
            "Epoch: 9/10, Step: 24/938, Loss: 0.0019255602965131402\n",
            "Epoch: 9/10, Step: 25/938, Loss: 1.0677842510631308e-05\n",
            "Epoch: 9/10, Step: 26/938, Loss: 0.0057300846092402935\n",
            "Epoch: 9/10, Step: 27/938, Loss: 0.00018883634766098112\n",
            "Epoch: 9/10, Step: 28/938, Loss: 0.0001829552638810128\n",
            "Epoch: 9/10, Step: 29/938, Loss: 0.02231764793395996\n",
            "Epoch: 9/10, Step: 30/938, Loss: 0.000538692285772413\n",
            "Epoch: 9/10, Step: 31/938, Loss: 0.00041507964488118887\n",
            "Epoch: 9/10, Step: 32/938, Loss: 3.3625987271079794e-05\n",
            "Epoch: 9/10, Step: 33/938, Loss: 0.044926464557647705\n",
            "Epoch: 9/10, Step: 34/938, Loss: 0.0005930832703597844\n",
            "Epoch: 9/10, Step: 35/938, Loss: 0.0004818738088943064\n",
            "Epoch: 9/10, Step: 36/938, Loss: 0.003236300079151988\n",
            "Epoch: 9/10, Step: 37/938, Loss: 0.00021760203526355326\n",
            "Epoch: 9/10, Step: 38/938, Loss: 0.001977349864318967\n",
            "Epoch: 9/10, Step: 39/938, Loss: 0.0065471334382891655\n",
            "Epoch: 9/10, Step: 40/938, Loss: 0.00012943476031068712\n",
            "Epoch: 9/10, Step: 41/938, Loss: 0.008281542919576168\n",
            "Epoch: 9/10, Step: 42/938, Loss: 0.0005505253793671727\n",
            "Epoch: 9/10, Step: 43/938, Loss: 4.886991882813163e-05\n",
            "Epoch: 9/10, Step: 44/938, Loss: 0.0006303551490418613\n",
            "Epoch: 9/10, Step: 45/938, Loss: 0.0004568596777971834\n",
            "Epoch: 9/10, Step: 46/938, Loss: 0.006387237459421158\n",
            "Epoch: 9/10, Step: 47/938, Loss: 0.0027669481933116913\n",
            "Epoch: 9/10, Step: 48/938, Loss: 0.009341508150100708\n",
            "Epoch: 9/10, Step: 49/938, Loss: 0.0006683666142635047\n",
            "Epoch: 9/10, Step: 50/938, Loss: 8.311813871841878e-05\n",
            "Epoch: 9/10, Step: 51/938, Loss: 0.004122675396502018\n",
            "Epoch: 9/10, Step: 52/938, Loss: 0.002636035205796361\n",
            "Epoch: 9/10, Step: 53/938, Loss: 0.0037075732834637165\n",
            "Epoch: 9/10, Step: 54/938, Loss: 3.4971293644048274e-05\n",
            "Epoch: 9/10, Step: 55/938, Loss: 6.114457210060209e-05\n",
            "Epoch: 9/10, Step: 56/938, Loss: 1.0874691724893637e-05\n",
            "Epoch: 9/10, Step: 57/938, Loss: 3.1254189707397018e-06\n",
            "Epoch: 9/10, Step: 58/938, Loss: 0.011861972510814667\n",
            "Epoch: 9/10, Step: 59/938, Loss: 0.00017580678104422987\n",
            "Epoch: 9/10, Step: 60/938, Loss: 0.0009673171443864703\n",
            "Epoch: 9/10, Step: 61/938, Loss: 0.0005073925131000578\n",
            "Epoch: 9/10, Step: 62/938, Loss: 0.004879966843873262\n",
            "Epoch: 9/10, Step: 63/938, Loss: 7.28483937564306e-05\n",
            "Epoch: 9/10, Step: 64/938, Loss: 0.000201565824681893\n",
            "Epoch: 9/10, Step: 65/938, Loss: 9.865088213700801e-05\n",
            "Epoch: 9/10, Step: 66/938, Loss: 0.009932240471243858\n",
            "Epoch: 9/10, Step: 67/938, Loss: 0.00015084075857885182\n",
            "Epoch: 9/10, Step: 68/938, Loss: 0.0016535237664356828\n",
            "Epoch: 9/10, Step: 69/938, Loss: 3.4365053579676896e-05\n",
            "Epoch: 9/10, Step: 70/938, Loss: 2.7058564228354953e-05\n",
            "Epoch: 9/10, Step: 71/938, Loss: 0.0011096431408077478\n",
            "Epoch: 9/10, Step: 72/938, Loss: 0.00018615587032400072\n",
            "Epoch: 9/10, Step: 73/938, Loss: 0.0053999717347323895\n",
            "Epoch: 9/10, Step: 74/938, Loss: 5.825114931212738e-05\n",
            "Epoch: 9/10, Step: 75/938, Loss: 0.0017342634964734316\n",
            "Epoch: 9/10, Step: 76/938, Loss: 0.011537736281752586\n",
            "Epoch: 9/10, Step: 77/938, Loss: 0.0032974996138364077\n",
            "Epoch: 9/10, Step: 78/938, Loss: 0.00041867265827022493\n",
            "Epoch: 9/10, Step: 79/938, Loss: 0.00010159943485632539\n",
            "Epoch: 9/10, Step: 80/938, Loss: 0.00013937029871158302\n",
            "Epoch: 9/10, Step: 81/938, Loss: 8.723394421394914e-05\n",
            "Epoch: 9/10, Step: 82/938, Loss: 0.0018877560505643487\n",
            "Epoch: 9/10, Step: 83/938, Loss: 0.006850108504295349\n",
            "Epoch: 9/10, Step: 84/938, Loss: 0.0009608574910089374\n",
            "Epoch: 9/10, Step: 85/938, Loss: 4.1039726056624204e-05\n",
            "Epoch: 9/10, Step: 86/938, Loss: 4.7256828111130744e-05\n",
            "Epoch: 9/10, Step: 87/938, Loss: 0.03745502233505249\n",
            "Epoch: 9/10, Step: 88/938, Loss: 0.001375853200443089\n",
            "Epoch: 9/10, Step: 89/938, Loss: 0.00037820261786691844\n",
            "Epoch: 9/10, Step: 90/938, Loss: 0.0004328781215008348\n",
            "Epoch: 9/10, Step: 91/938, Loss: 0.004133505281060934\n",
            "Epoch: 9/10, Step: 92/938, Loss: 0.0021434961818158627\n",
            "Epoch: 9/10, Step: 93/938, Loss: 0.0012899225112050772\n",
            "Epoch: 9/10, Step: 94/938, Loss: 0.00021862713037990034\n",
            "Epoch: 9/10, Step: 95/938, Loss: 0.004737389739602804\n",
            "Epoch: 9/10, Step: 96/938, Loss: 2.2300104319583625e-05\n",
            "Epoch: 9/10, Step: 97/938, Loss: 0.0007294752867892385\n",
            "Epoch: 9/10, Step: 98/938, Loss: 0.00016162228712346405\n",
            "Epoch: 9/10, Step: 99/938, Loss: 2.5612867830204777e-05\n",
            "Epoch: 9/10, Step: 100/938, Loss: 8.155936666298658e-05\n",
            "Epoch: 9/10, Step: 101/938, Loss: 7.167865260271356e-05\n",
            "Epoch: 9/10, Step: 102/938, Loss: 0.0008365965913981199\n",
            "Epoch: 9/10, Step: 103/938, Loss: 0.0020690278615802526\n",
            "Epoch: 9/10, Step: 104/938, Loss: 0.00014858998474664986\n",
            "Epoch: 9/10, Step: 105/938, Loss: 0.0002844066184479743\n",
            "Epoch: 9/10, Step: 106/938, Loss: 0.00047697959234938025\n",
            "Epoch: 9/10, Step: 107/938, Loss: 4.580712266033515e-05\n",
            "Epoch: 9/10, Step: 108/938, Loss: 2.7349924494046718e-05\n",
            "Epoch: 9/10, Step: 109/938, Loss: 0.02188689075410366\n",
            "Epoch: 9/10, Step: 110/938, Loss: 0.0012774586211889982\n",
            "Epoch: 9/10, Step: 111/938, Loss: 0.004364985041320324\n",
            "Epoch: 9/10, Step: 112/938, Loss: 0.0005555289681069553\n",
            "Epoch: 9/10, Step: 113/938, Loss: 0.0010999098885804415\n",
            "Epoch: 9/10, Step: 114/938, Loss: 0.0030979355797171593\n",
            "Epoch: 9/10, Step: 115/938, Loss: 5.0960683438461274e-05\n",
            "Epoch: 9/10, Step: 116/938, Loss: 2.0172818040009588e-05\n",
            "Epoch: 9/10, Step: 117/938, Loss: 0.016853606328368187\n",
            "Epoch: 9/10, Step: 118/938, Loss: 8.631760283606127e-05\n",
            "Epoch: 9/10, Step: 119/938, Loss: 0.0049351900815963745\n",
            "Epoch: 9/10, Step: 120/938, Loss: 4.977993739885278e-05\n",
            "Epoch: 9/10, Step: 121/938, Loss: 0.0001794120908016339\n",
            "Epoch: 9/10, Step: 122/938, Loss: 4.166574581176974e-05\n",
            "Epoch: 9/10, Step: 123/938, Loss: 6.337702507153153e-05\n",
            "Epoch: 9/10, Step: 124/938, Loss: 0.0036713078152388334\n",
            "Epoch: 9/10, Step: 125/938, Loss: 3.046373421966564e-05\n",
            "Epoch: 9/10, Step: 126/938, Loss: 0.004619495011866093\n",
            "Epoch: 9/10, Step: 127/938, Loss: 0.0008143937448039651\n",
            "Epoch: 9/10, Step: 128/938, Loss: 0.00042926828609779477\n",
            "Epoch: 9/10, Step: 129/938, Loss: 0.0012433668598532677\n",
            "Epoch: 9/10, Step: 130/938, Loss: 0.00020040376693941653\n",
            "Epoch: 9/10, Step: 131/938, Loss: 0.0015873315278440714\n",
            "Epoch: 9/10, Step: 132/938, Loss: 5.1014517339353915e-06\n",
            "Epoch: 9/10, Step: 133/938, Loss: 0.017887750640511513\n",
            "Epoch: 9/10, Step: 134/938, Loss: 0.00022720226843375713\n",
            "Epoch: 9/10, Step: 135/938, Loss: 1.2889710887975525e-05\n",
            "Epoch: 9/10, Step: 136/938, Loss: 8.220471499953419e-06\n",
            "Epoch: 9/10, Step: 137/938, Loss: 1.5196173990261741e-05\n",
            "Epoch: 9/10, Step: 138/938, Loss: 9.116920409724116e-06\n",
            "Epoch: 9/10, Step: 139/938, Loss: 0.0003295318747404963\n",
            "Epoch: 9/10, Step: 140/938, Loss: 0.0005652232794091105\n",
            "Epoch: 9/10, Step: 141/938, Loss: 8.632222488813568e-06\n",
            "Epoch: 9/10, Step: 142/938, Loss: 9.697078894532751e-06\n",
            "Epoch: 9/10, Step: 143/938, Loss: 0.00013438327005133033\n",
            "Epoch: 9/10, Step: 144/938, Loss: 0.0020077789667993784\n",
            "Epoch: 9/10, Step: 145/938, Loss: 0.00011150462523801252\n",
            "Epoch: 9/10, Step: 146/938, Loss: 0.0001243683509528637\n",
            "Epoch: 9/10, Step: 147/938, Loss: 5.516374949365854e-05\n",
            "Epoch: 9/10, Step: 148/938, Loss: 2.402258905931376e-05\n",
            "Epoch: 9/10, Step: 149/938, Loss: 0.00043180619832128286\n",
            "Epoch: 9/10, Step: 150/938, Loss: 0.002283638110384345\n",
            "Epoch: 9/10, Step: 151/938, Loss: 0.00029472759342752397\n",
            "Epoch: 9/10, Step: 152/938, Loss: 1.2876324944954831e-05\n",
            "Epoch: 9/10, Step: 153/938, Loss: 0.0001244799350388348\n",
            "Epoch: 9/10, Step: 154/938, Loss: 0.00018617200839798898\n",
            "Epoch: 9/10, Step: 155/938, Loss: 0.00013071182183921337\n",
            "Epoch: 9/10, Step: 156/938, Loss: 7.311108493013307e-05\n",
            "Epoch: 9/10, Step: 157/938, Loss: 0.0008479265961796045\n",
            "Epoch: 9/10, Step: 158/938, Loss: 0.003925737459212542\n",
            "Epoch: 9/10, Step: 159/938, Loss: 8.11656627774937e-06\n",
            "Epoch: 9/10, Step: 160/938, Loss: 0.008010339923202991\n",
            "Epoch: 9/10, Step: 161/938, Loss: 0.0001661772112129256\n",
            "Epoch: 9/10, Step: 162/938, Loss: 1.0718145858845674e-05\n",
            "Epoch: 9/10, Step: 163/938, Loss: 0.0001160091778729111\n",
            "Epoch: 9/10, Step: 164/938, Loss: 0.0009458945132791996\n",
            "Epoch: 9/10, Step: 165/938, Loss: 0.0002860328822862357\n",
            "Epoch: 9/10, Step: 166/938, Loss: 0.0001094731705961749\n",
            "Epoch: 9/10, Step: 167/938, Loss: 1.625353252165951e-05\n",
            "Epoch: 9/10, Step: 168/938, Loss: 0.0007664455333724618\n",
            "Epoch: 9/10, Step: 169/938, Loss: 0.001135517843067646\n",
            "Epoch: 9/10, Step: 170/938, Loss: 7.735752296866849e-05\n",
            "Epoch: 9/10, Step: 171/938, Loss: 0.004620361141860485\n",
            "Epoch: 9/10, Step: 172/938, Loss: 0.002344195730984211\n",
            "Epoch: 9/10, Step: 173/938, Loss: 0.0007978993817232549\n",
            "Epoch: 9/10, Step: 174/938, Loss: 0.00021809891040902585\n",
            "Epoch: 9/10, Step: 175/938, Loss: 0.0011028689332306385\n",
            "Epoch: 9/10, Step: 176/938, Loss: 0.0012082220055162907\n",
            "Epoch: 9/10, Step: 177/938, Loss: 0.00048644019989296794\n",
            "Epoch: 9/10, Step: 178/938, Loss: 0.003488330403342843\n",
            "Epoch: 9/10, Step: 179/938, Loss: 7.709059718763456e-05\n",
            "Epoch: 9/10, Step: 180/938, Loss: 0.03980894759297371\n",
            "Epoch: 9/10, Step: 181/938, Loss: 7.699798516114242e-06\n",
            "Epoch: 9/10, Step: 182/938, Loss: 8.297616659547202e-06\n",
            "Epoch: 9/10, Step: 183/938, Loss: 0.00011583049490582198\n",
            "Epoch: 9/10, Step: 184/938, Loss: 0.0006220062496140599\n",
            "Epoch: 9/10, Step: 185/938, Loss: 0.0018778154626488686\n",
            "Epoch: 9/10, Step: 186/938, Loss: 0.028900830075144768\n",
            "Epoch: 9/10, Step: 187/938, Loss: 0.018923334777355194\n",
            "Epoch: 9/10, Step: 188/938, Loss: 0.0010120634688064456\n",
            "Epoch: 9/10, Step: 189/938, Loss: 0.0008379225619137287\n",
            "Epoch: 9/10, Step: 190/938, Loss: 0.003719507483765483\n",
            "Epoch: 9/10, Step: 191/938, Loss: 0.000440892850747332\n",
            "Epoch: 9/10, Step: 192/938, Loss: 0.0037679909728467464\n",
            "Epoch: 9/10, Step: 193/938, Loss: 0.00027401227271184325\n",
            "Epoch: 9/10, Step: 194/938, Loss: 0.0012414910597726703\n",
            "Epoch: 9/10, Step: 195/938, Loss: 0.00018627080135047436\n",
            "Epoch: 9/10, Step: 196/938, Loss: 0.0013704349985346198\n",
            "Epoch: 9/10, Step: 197/938, Loss: 3.98756965296343e-05\n",
            "Epoch: 9/10, Step: 198/938, Loss: 0.012287793681025505\n",
            "Epoch: 9/10, Step: 199/938, Loss: 0.00026103854179382324\n",
            "Epoch: 9/10, Step: 200/938, Loss: 0.00011341225763317198\n",
            "Epoch: 9/10, Step: 201/938, Loss: 7.744888716842979e-05\n",
            "Epoch: 9/10, Step: 202/938, Loss: 1.43049476264423e-06\n",
            "Epoch: 9/10, Step: 203/938, Loss: 0.00011815519246738404\n",
            "Epoch: 9/10, Step: 204/938, Loss: 0.00015450069622602314\n",
            "Epoch: 9/10, Step: 205/938, Loss: 0.00013202481204643846\n",
            "Epoch: 9/10, Step: 206/938, Loss: 0.00010417969315312803\n",
            "Epoch: 9/10, Step: 207/938, Loss: 0.014310582540929317\n",
            "Epoch: 9/10, Step: 208/938, Loss: 0.00046393496450036764\n",
            "Epoch: 9/10, Step: 209/938, Loss: 4.1443166992394254e-05\n",
            "Epoch: 9/10, Step: 210/938, Loss: 1.2873898413090501e-05\n",
            "Epoch: 9/10, Step: 211/938, Loss: 5.896805669181049e-05\n",
            "Epoch: 9/10, Step: 212/938, Loss: 0.0002477720845490694\n",
            "Epoch: 9/10, Step: 213/938, Loss: 3.757094236789271e-05\n",
            "Epoch: 9/10, Step: 214/938, Loss: 0.007952306419610977\n",
            "Epoch: 9/10, Step: 215/938, Loss: 0.0001123287802329287\n",
            "Epoch: 9/10, Step: 216/938, Loss: 0.00010594906780170277\n",
            "Epoch: 9/10, Step: 217/938, Loss: 2.193131331296172e-05\n",
            "Epoch: 9/10, Step: 218/938, Loss: 0.0012671983567997813\n",
            "Epoch: 9/10, Step: 219/938, Loss: 0.001057707122527063\n",
            "Epoch: 9/10, Step: 220/938, Loss: 0.00010599289817037061\n",
            "Epoch: 9/10, Step: 221/938, Loss: 0.000309799681417644\n",
            "Epoch: 9/10, Step: 222/938, Loss: 0.00016457177116535604\n",
            "Epoch: 9/10, Step: 223/938, Loss: 0.004646127577871084\n",
            "Epoch: 9/10, Step: 224/938, Loss: 0.0032259062863886356\n",
            "Epoch: 9/10, Step: 225/938, Loss: 0.0001733953831717372\n",
            "Epoch: 9/10, Step: 226/938, Loss: 0.0026032007299363613\n",
            "Epoch: 9/10, Step: 227/938, Loss: 0.006976194214075804\n",
            "Epoch: 9/10, Step: 228/938, Loss: 0.00012352170597296208\n",
            "Epoch: 9/10, Step: 229/938, Loss: 0.0013715659733861685\n",
            "Epoch: 9/10, Step: 230/938, Loss: 0.0024001821875572205\n",
            "Epoch: 9/10, Step: 231/938, Loss: 0.0007513936725445092\n",
            "Epoch: 9/10, Step: 232/938, Loss: 0.0018145086942240596\n",
            "Epoch: 9/10, Step: 233/938, Loss: 0.0001313487155130133\n",
            "Epoch: 9/10, Step: 234/938, Loss: 0.0047356244176626205\n",
            "Epoch: 9/10, Step: 235/938, Loss: 0.0049882023595273495\n",
            "Epoch: 9/10, Step: 236/938, Loss: 0.001981120789423585\n",
            "Epoch: 9/10, Step: 237/938, Loss: 0.006736505776643753\n",
            "Epoch: 9/10, Step: 238/938, Loss: 4.68186080979649e-05\n",
            "Epoch: 9/10, Step: 239/938, Loss: 0.0006703085382468998\n",
            "Epoch: 9/10, Step: 240/938, Loss: 0.0014636736596003175\n",
            "Epoch: 9/10, Step: 241/938, Loss: 1.2572358173201792e-05\n",
            "Epoch: 9/10, Step: 242/938, Loss: 0.0001766328205121681\n",
            "Epoch: 9/10, Step: 243/938, Loss: 3.054498165511177e-06\n",
            "Epoch: 9/10, Step: 244/938, Loss: 3.052374813705683e-05\n",
            "Epoch: 9/10, Step: 245/938, Loss: 0.004652758128941059\n",
            "Epoch: 9/10, Step: 246/938, Loss: 0.00015850565978325903\n",
            "Epoch: 9/10, Step: 247/938, Loss: 0.011402647942304611\n",
            "Epoch: 9/10, Step: 248/938, Loss: 0.0008127991459332407\n",
            "Epoch: 9/10, Step: 249/938, Loss: 0.0011839356739073992\n",
            "Epoch: 9/10, Step: 250/938, Loss: 0.00017616381228435785\n",
            "Epoch: 9/10, Step: 251/938, Loss: 0.00018727558199316263\n",
            "Epoch: 9/10, Step: 252/938, Loss: 7.712210390309338e-06\n",
            "Epoch: 9/10, Step: 253/938, Loss: 0.0005045859725214541\n",
            "Epoch: 9/10, Step: 254/938, Loss: 0.0013046637177467346\n",
            "Epoch: 9/10, Step: 255/938, Loss: 4.230508056934923e-05\n",
            "Epoch: 9/10, Step: 256/938, Loss: 0.00926002487540245\n",
            "Epoch: 9/10, Step: 257/938, Loss: 0.001308531267568469\n",
            "Epoch: 9/10, Step: 258/938, Loss: 0.00015579554019495845\n",
            "Epoch: 9/10, Step: 259/938, Loss: 7.825942157069221e-05\n",
            "Epoch: 9/10, Step: 260/938, Loss: 0.00040228560101240873\n",
            "Epoch: 9/10, Step: 261/938, Loss: 0.0002972987131215632\n",
            "Epoch: 9/10, Step: 262/938, Loss: 0.009237867780029774\n",
            "Epoch: 9/10, Step: 263/938, Loss: 0.006624404340982437\n",
            "Epoch: 9/10, Step: 264/938, Loss: 1.6283242075587623e-05\n",
            "Epoch: 9/10, Step: 265/938, Loss: 0.0055787754245102406\n",
            "Epoch: 9/10, Step: 266/938, Loss: 0.00013085559476166964\n",
            "Epoch: 9/10, Step: 267/938, Loss: 1.661218448134605e-05\n",
            "Epoch: 9/10, Step: 268/938, Loss: 0.00284676905721426\n",
            "Epoch: 9/10, Step: 269/938, Loss: 9.950200910679996e-05\n",
            "Epoch: 9/10, Step: 270/938, Loss: 8.450917812297121e-05\n",
            "Epoch: 9/10, Step: 271/938, Loss: 6.531981398438802e-06\n",
            "Epoch: 9/10, Step: 272/938, Loss: 0.003313500666990876\n",
            "Epoch: 9/10, Step: 273/938, Loss: 0.020280567929148674\n",
            "Epoch: 9/10, Step: 274/938, Loss: 0.0013371002860367298\n",
            "Epoch: 9/10, Step: 275/938, Loss: 0.0005664572236128151\n",
            "Epoch: 9/10, Step: 276/938, Loss: 0.0001869131374405697\n",
            "Epoch: 9/10, Step: 277/938, Loss: 5.372953455662355e-05\n",
            "Epoch: 9/10, Step: 278/938, Loss: 0.00042268208926543593\n",
            "Epoch: 9/10, Step: 279/938, Loss: 0.0009772810153663158\n",
            "Epoch: 9/10, Step: 280/938, Loss: 0.1977795958518982\n",
            "Epoch: 9/10, Step: 281/938, Loss: 7.671448656765278e-06\n",
            "Epoch: 9/10, Step: 282/938, Loss: 0.00016855279682204127\n",
            "Epoch: 9/10, Step: 283/938, Loss: 1.5903162420727313e-05\n",
            "Epoch: 9/10, Step: 284/938, Loss: 0.012914028950035572\n",
            "Epoch: 9/10, Step: 285/938, Loss: 0.000678972399327904\n",
            "Epoch: 9/10, Step: 286/938, Loss: 8.333627920364961e-05\n",
            "Epoch: 9/10, Step: 287/938, Loss: 0.012150632217526436\n",
            "Epoch: 9/10, Step: 288/938, Loss: 0.000532549514900893\n",
            "Epoch: 9/10, Step: 289/938, Loss: 2.56854673352791e-06\n",
            "Epoch: 9/10, Step: 290/938, Loss: 2.8570946597028524e-05\n",
            "Epoch: 9/10, Step: 291/938, Loss: 0.0007182590779848397\n",
            "Epoch: 9/10, Step: 292/938, Loss: 5.5147898819996044e-05\n",
            "Epoch: 9/10, Step: 293/938, Loss: 0.0023123673163354397\n",
            "Epoch: 9/10, Step: 294/938, Loss: 3.1680785468779504e-05\n",
            "Epoch: 9/10, Step: 295/938, Loss: 0.00010628867312334478\n",
            "Epoch: 9/10, Step: 296/938, Loss: 0.00023703141778241843\n",
            "Epoch: 9/10, Step: 297/938, Loss: 0.007515675853937864\n",
            "Epoch: 9/10, Step: 298/938, Loss: 0.0009261667728424072\n",
            "Epoch: 9/10, Step: 299/938, Loss: 0.0022303673904389143\n",
            "Epoch: 9/10, Step: 300/938, Loss: 0.00018950144294649363\n",
            "Epoch: 9/10, Step: 301/938, Loss: 3.073046536883339e-05\n",
            "Epoch: 9/10, Step: 302/938, Loss: 2.0215818949509412e-05\n",
            "Epoch: 9/10, Step: 303/938, Loss: 0.0005938087124377489\n",
            "Epoch: 9/10, Step: 304/938, Loss: 0.0017969761975109577\n",
            "Epoch: 9/10, Step: 305/938, Loss: 0.0030211852863430977\n",
            "Epoch: 9/10, Step: 306/938, Loss: 0.030924241989850998\n",
            "Epoch: 9/10, Step: 307/938, Loss: 0.00010147183638764545\n",
            "Epoch: 9/10, Step: 308/938, Loss: 0.002808572957292199\n",
            "Epoch: 9/10, Step: 309/938, Loss: 7.652292697457597e-05\n",
            "Epoch: 9/10, Step: 310/938, Loss: 5.539658377529122e-05\n",
            "Epoch: 9/10, Step: 311/938, Loss: 5.977572072879411e-05\n",
            "Epoch: 9/10, Step: 312/938, Loss: 2.2803071260568686e-05\n",
            "Epoch: 9/10, Step: 313/938, Loss: 5.5546574003528804e-05\n",
            "Epoch: 9/10, Step: 314/938, Loss: 2.2897891540196724e-05\n",
            "Epoch: 9/10, Step: 315/938, Loss: 0.0013085842365399003\n",
            "Epoch: 9/10, Step: 316/938, Loss: 0.000612152274698019\n",
            "Epoch: 9/10, Step: 317/938, Loss: 0.00015897199045866728\n",
            "Epoch: 9/10, Step: 318/938, Loss: 0.0001715875550871715\n",
            "Epoch: 9/10, Step: 319/938, Loss: 0.0001385021605528891\n",
            "Epoch: 9/10, Step: 320/938, Loss: 7.300361903617159e-05\n",
            "Epoch: 9/10, Step: 321/938, Loss: 0.00025752000510692596\n",
            "Epoch: 9/10, Step: 322/938, Loss: 3.03257711493643e-05\n",
            "Epoch: 9/10, Step: 323/938, Loss: 1.7319269318250008e-05\n",
            "Epoch: 9/10, Step: 324/938, Loss: 0.0010463808430358768\n",
            "Epoch: 9/10, Step: 325/938, Loss: 0.0005870772292837501\n",
            "Epoch: 9/10, Step: 326/938, Loss: 0.00024387467419728637\n",
            "Epoch: 9/10, Step: 327/938, Loss: 0.00022726702445652336\n",
            "Epoch: 9/10, Step: 328/938, Loss: 7.074838504195213e-05\n",
            "Epoch: 9/10, Step: 329/938, Loss: 0.00013167178258299828\n",
            "Epoch: 9/10, Step: 330/938, Loss: 2.0810621208511293e-05\n",
            "Epoch: 9/10, Step: 331/938, Loss: 0.00014112411008682102\n",
            "Epoch: 9/10, Step: 332/938, Loss: 7.616735092597082e-05\n",
            "Epoch: 9/10, Step: 333/938, Loss: 6.278705404838547e-05\n",
            "Epoch: 9/10, Step: 334/938, Loss: 0.0012103047920390964\n",
            "Epoch: 9/10, Step: 335/938, Loss: 0.0017197646666318178\n",
            "Epoch: 9/10, Step: 336/938, Loss: 5.9501318901311606e-05\n",
            "Epoch: 9/10, Step: 337/938, Loss: 0.00043058631126768887\n",
            "Epoch: 9/10, Step: 338/938, Loss: 0.010737799108028412\n",
            "Epoch: 9/10, Step: 339/938, Loss: 0.0008241853211075068\n",
            "Epoch: 9/10, Step: 340/938, Loss: 0.020063623785972595\n",
            "Epoch: 9/10, Step: 341/938, Loss: 0.00916743278503418\n",
            "Epoch: 9/10, Step: 342/938, Loss: 0.059552595019340515\n",
            "Epoch: 9/10, Step: 343/938, Loss: 9.069836960406974e-05\n",
            "Epoch: 9/10, Step: 344/938, Loss: 2.2832840841147117e-05\n",
            "Epoch: 9/10, Step: 345/938, Loss: 1.896923095046077e-05\n",
            "Epoch: 9/10, Step: 346/938, Loss: 0.00028445699717849493\n",
            "Epoch: 9/10, Step: 347/938, Loss: 0.007540167309343815\n",
            "Epoch: 9/10, Step: 348/938, Loss: 0.0006250567967072129\n",
            "Epoch: 9/10, Step: 349/938, Loss: 0.001183386193588376\n",
            "Epoch: 9/10, Step: 350/938, Loss: 0.0006595921004191041\n",
            "Epoch: 9/10, Step: 351/938, Loss: 7.420437759719789e-05\n",
            "Epoch: 9/10, Step: 352/938, Loss: 0.00017669363296590745\n",
            "Epoch: 9/10, Step: 353/938, Loss: 6.323608249658719e-05\n",
            "Epoch: 9/10, Step: 354/938, Loss: 0.008337831124663353\n",
            "Epoch: 9/10, Step: 355/938, Loss: 0.0002952604554593563\n",
            "Epoch: 9/10, Step: 356/938, Loss: 0.0013641065452247858\n",
            "Epoch: 9/10, Step: 357/938, Loss: 1.3005571418034378e-05\n",
            "Epoch: 9/10, Step: 358/938, Loss: 0.006356837693601847\n",
            "Epoch: 9/10, Step: 359/938, Loss: 0.0007179477252066135\n",
            "Epoch: 9/10, Step: 360/938, Loss: 0.0012110579991713166\n",
            "Epoch: 9/10, Step: 361/938, Loss: 0.0014841215452179313\n",
            "Epoch: 9/10, Step: 362/938, Loss: 0.0022991024889051914\n",
            "Epoch: 9/10, Step: 363/938, Loss: 0.0024208826944231987\n",
            "Epoch: 9/10, Step: 364/938, Loss: 0.00012523152690846473\n",
            "Epoch: 9/10, Step: 365/938, Loss: 0.0007125855190679431\n",
            "Epoch: 9/10, Step: 366/938, Loss: 0.0028621105011552572\n",
            "Epoch: 9/10, Step: 367/938, Loss: 0.012078086845576763\n",
            "Epoch: 9/10, Step: 368/938, Loss: 0.002020718529820442\n",
            "Epoch: 9/10, Step: 369/938, Loss: 0.02522725611925125\n",
            "Epoch: 9/10, Step: 370/938, Loss: 0.009765056893229485\n",
            "Epoch: 9/10, Step: 371/938, Loss: 0.001085195573978126\n",
            "Epoch: 9/10, Step: 372/938, Loss: 0.00010939143976429477\n",
            "Epoch: 9/10, Step: 373/938, Loss: 0.01272581797093153\n",
            "Epoch: 9/10, Step: 374/938, Loss: 0.00022098314366303384\n",
            "Epoch: 9/10, Step: 375/938, Loss: 0.02626432105898857\n",
            "Epoch: 9/10, Step: 376/938, Loss: 0.0001269391505047679\n",
            "Epoch: 9/10, Step: 377/938, Loss: 0.005219588056206703\n",
            "Epoch: 9/10, Step: 378/938, Loss: 1.4193129572959151e-05\n",
            "Epoch: 9/10, Step: 379/938, Loss: 7.873948197811842e-05\n",
            "Epoch: 9/10, Step: 380/938, Loss: 0.0013122216332703829\n",
            "Epoch: 9/10, Step: 381/938, Loss: 0.00010507004481041804\n",
            "Epoch: 9/10, Step: 382/938, Loss: 0.0006205782992765307\n",
            "Epoch: 9/10, Step: 383/938, Loss: 0.00019417714793235064\n",
            "Epoch: 9/10, Step: 384/938, Loss: 0.03969435766339302\n",
            "Epoch: 9/10, Step: 385/938, Loss: 0.0013213271740823984\n",
            "Epoch: 9/10, Step: 386/938, Loss: 0.00014612640370614827\n",
            "Epoch: 9/10, Step: 387/938, Loss: 0.0005326395039446652\n",
            "Epoch: 9/10, Step: 388/938, Loss: 2.5305087547167204e-05\n",
            "Epoch: 9/10, Step: 389/938, Loss: 2.7966296329395846e-05\n",
            "Epoch: 9/10, Step: 390/938, Loss: 0.0028064814396202564\n",
            "Epoch: 9/10, Step: 391/938, Loss: 0.00013181172835174948\n",
            "Epoch: 9/10, Step: 392/938, Loss: 0.00042168598156422377\n",
            "Epoch: 9/10, Step: 393/938, Loss: 4.61694726254791e-05\n",
            "Epoch: 9/10, Step: 394/938, Loss: 0.05166364461183548\n",
            "Epoch: 9/10, Step: 395/938, Loss: 0.0002281969937030226\n",
            "Epoch: 9/10, Step: 396/938, Loss: 5.770110146841034e-05\n",
            "Epoch: 9/10, Step: 397/938, Loss: 9.688775026006624e-05\n",
            "Epoch: 9/10, Step: 398/938, Loss: 0.011414118111133575\n",
            "Epoch: 9/10, Step: 399/938, Loss: 0.0026652924716472626\n",
            "Epoch: 9/10, Step: 400/938, Loss: 0.03070320375263691\n",
            "Epoch: 9/10, Step: 401/938, Loss: 0.012465080246329308\n",
            "Epoch: 9/10, Step: 402/938, Loss: 7.665115117561072e-05\n",
            "Epoch: 9/10, Step: 403/938, Loss: 0.0018610155675560236\n",
            "Epoch: 9/10, Step: 404/938, Loss: 0.00037016638088971376\n",
            "Epoch: 9/10, Step: 405/938, Loss: 0.00017487957666162401\n",
            "Epoch: 9/10, Step: 406/938, Loss: 0.006272195838391781\n",
            "Epoch: 9/10, Step: 407/938, Loss: 0.00024691535509191453\n",
            "Epoch: 9/10, Step: 408/938, Loss: 5.375731780077331e-05\n",
            "Epoch: 9/10, Step: 409/938, Loss: 0.0013497407780960202\n",
            "Epoch: 9/10, Step: 410/938, Loss: 0.0009468962089158595\n",
            "Epoch: 9/10, Step: 411/938, Loss: 1.489595615566941e-05\n",
            "Epoch: 9/10, Step: 412/938, Loss: 1.014676581689855e-05\n",
            "Epoch: 9/10, Step: 413/938, Loss: 5.556780524784699e-05\n",
            "Epoch: 9/10, Step: 414/938, Loss: 6.0291317822702695e-06\n",
            "Epoch: 9/10, Step: 415/938, Loss: 0.008377761580049992\n",
            "Epoch: 9/10, Step: 416/938, Loss: 0.005003007594496012\n",
            "Epoch: 9/10, Step: 417/938, Loss: 9.412699728272855e-05\n",
            "Epoch: 9/10, Step: 418/938, Loss: 0.007088624406605959\n",
            "Epoch: 9/10, Step: 419/938, Loss: 1.3848894013790414e-05\n",
            "Epoch: 9/10, Step: 420/938, Loss: 0.00022386506316252053\n",
            "Epoch: 9/10, Step: 421/938, Loss: 0.007218002341687679\n",
            "Epoch: 9/10, Step: 422/938, Loss: 9.947226499207318e-05\n",
            "Epoch: 9/10, Step: 423/938, Loss: 0.009659851901233196\n",
            "Epoch: 9/10, Step: 424/938, Loss: 0.0004366133944131434\n",
            "Epoch: 9/10, Step: 425/938, Loss: 0.0013865878572687507\n",
            "Epoch: 9/10, Step: 426/938, Loss: 0.0007384822238236666\n",
            "Epoch: 9/10, Step: 427/938, Loss: 0.00011785665265051648\n",
            "Epoch: 9/10, Step: 428/938, Loss: 0.000956360949203372\n",
            "Epoch: 9/10, Step: 429/938, Loss: 0.0006914549157954752\n",
            "Epoch: 9/10, Step: 430/938, Loss: 0.0003920805174857378\n",
            "Epoch: 9/10, Step: 431/938, Loss: 0.0002908269816543907\n",
            "Epoch: 9/10, Step: 432/938, Loss: 0.0262803565710783\n",
            "Epoch: 9/10, Step: 433/938, Loss: 0.007735762745141983\n",
            "Epoch: 9/10, Step: 434/938, Loss: 2.1854188162251376e-05\n",
            "Epoch: 9/10, Step: 435/938, Loss: 0.008632805198431015\n",
            "Epoch: 9/10, Step: 436/938, Loss: 0.003715753788128495\n",
            "Epoch: 9/10, Step: 437/938, Loss: 0.00016163787222467363\n",
            "Epoch: 9/10, Step: 438/938, Loss: 0.0010470477864146233\n",
            "Epoch: 9/10, Step: 439/938, Loss: 6.098189624026418e-05\n",
            "Epoch: 9/10, Step: 440/938, Loss: 4.9547452363185585e-05\n",
            "Epoch: 9/10, Step: 441/938, Loss: 0.041180018335580826\n",
            "Epoch: 9/10, Step: 442/938, Loss: 0.01761511154472828\n",
            "Epoch: 9/10, Step: 443/938, Loss: 0.006100906524807215\n",
            "Epoch: 9/10, Step: 444/938, Loss: 0.03781501576304436\n",
            "Epoch: 9/10, Step: 445/938, Loss: 0.0009686848497949541\n",
            "Epoch: 9/10, Step: 446/938, Loss: 4.9404323362978175e-05\n",
            "Epoch: 9/10, Step: 447/938, Loss: 7.921655924292281e-05\n",
            "Epoch: 9/10, Step: 448/938, Loss: 3.712539910338819e-05\n",
            "Epoch: 9/10, Step: 449/938, Loss: 2.6628058549249545e-05\n",
            "Epoch: 9/10, Step: 450/938, Loss: 0.0015063328901305795\n",
            "Epoch: 9/10, Step: 451/938, Loss: 0.000417917559389025\n",
            "Epoch: 9/10, Step: 452/938, Loss: 7.23607954569161e-05\n",
            "Epoch: 9/10, Step: 453/938, Loss: 0.03299786150455475\n",
            "Epoch: 9/10, Step: 454/938, Loss: 0.00232735020108521\n",
            "Epoch: 9/10, Step: 455/938, Loss: 0.00010230524640064687\n",
            "Epoch: 9/10, Step: 456/938, Loss: 0.03672825172543526\n",
            "Epoch: 9/10, Step: 457/938, Loss: 0.0002728294930420816\n",
            "Epoch: 9/10, Step: 458/938, Loss: 4.28809980803635e-05\n",
            "Epoch: 9/10, Step: 459/938, Loss: 0.0011581126600503922\n",
            "Epoch: 9/10, Step: 460/938, Loss: 3.692113750730641e-05\n",
            "Epoch: 9/10, Step: 461/938, Loss: 0.00019236383377574384\n",
            "Epoch: 9/10, Step: 462/938, Loss: 0.015685340389609337\n",
            "Epoch: 9/10, Step: 463/938, Loss: 0.00012479507131502032\n",
            "Epoch: 9/10, Step: 464/938, Loss: 0.00014271307736635208\n",
            "Epoch: 9/10, Step: 465/938, Loss: 5.237395453150384e-05\n",
            "Epoch: 9/10, Step: 466/938, Loss: 0.05535709857940674\n",
            "Epoch: 9/10, Step: 467/938, Loss: 0.0008924626745283604\n",
            "Epoch: 9/10, Step: 468/938, Loss: 0.00016383000183850527\n",
            "Epoch: 9/10, Step: 469/938, Loss: 0.002482437528669834\n",
            "Epoch: 9/10, Step: 470/938, Loss: 4.875687227468006e-05\n",
            "Epoch: 9/10, Step: 471/938, Loss: 5.428939766716212e-05\n",
            "Epoch: 9/10, Step: 472/938, Loss: 2.227638105978258e-05\n",
            "Epoch: 9/10, Step: 473/938, Loss: 0.005415775813162327\n",
            "Epoch: 9/10, Step: 474/938, Loss: 0.00026543860440142453\n",
            "Epoch: 9/10, Step: 475/938, Loss: 0.0014707506634294987\n",
            "Epoch: 9/10, Step: 476/938, Loss: 0.0013881076592952013\n",
            "Epoch: 9/10, Step: 477/938, Loss: 9.95177761069499e-05\n",
            "Epoch: 9/10, Step: 478/938, Loss: 0.003533383831381798\n",
            "Epoch: 9/10, Step: 479/938, Loss: 0.002199257258325815\n",
            "Epoch: 9/10, Step: 480/938, Loss: 0.0003296687500551343\n",
            "Epoch: 9/10, Step: 481/938, Loss: 0.0002159604919143021\n",
            "Epoch: 9/10, Step: 482/938, Loss: 0.010382786393165588\n",
            "Epoch: 9/10, Step: 483/938, Loss: 0.00352363265119493\n",
            "Epoch: 9/10, Step: 484/938, Loss: 0.00024186883820220828\n",
            "Epoch: 9/10, Step: 485/938, Loss: 0.046140480786561966\n",
            "Epoch: 9/10, Step: 486/938, Loss: 0.00028042506892234087\n",
            "Epoch: 9/10, Step: 487/938, Loss: 0.00026150894700549543\n",
            "Epoch: 9/10, Step: 488/938, Loss: 0.00029954672208987176\n",
            "Epoch: 9/10, Step: 489/938, Loss: 0.006180186290293932\n",
            "Epoch: 9/10, Step: 490/938, Loss: 1.6624875570414588e-05\n",
            "Epoch: 9/10, Step: 491/938, Loss: 0.0005215497803874314\n",
            "Epoch: 9/10, Step: 492/938, Loss: 0.00029923944384790957\n",
            "Epoch: 9/10, Step: 493/938, Loss: 1.978074033104349e-05\n",
            "Epoch: 9/10, Step: 494/938, Loss: 0.0003937179280910641\n",
            "Epoch: 9/10, Step: 495/938, Loss: 8.450534369330853e-05\n",
            "Epoch: 9/10, Step: 496/938, Loss: 2.14386022889812e-06\n",
            "Epoch: 9/10, Step: 497/938, Loss: 0.015217146836221218\n",
            "Epoch: 9/10, Step: 498/938, Loss: 0.006562317721545696\n",
            "Epoch: 9/10, Step: 499/938, Loss: 0.0004977270727977157\n",
            "Epoch: 9/10, Step: 500/938, Loss: 1.4640263543697074e-06\n",
            "Epoch: 9/10, Step: 501/938, Loss: 0.017947882413864136\n",
            "Epoch: 9/10, Step: 502/938, Loss: 0.00022693235951010138\n",
            "Epoch: 9/10, Step: 503/938, Loss: 0.009001322090625763\n",
            "Epoch: 9/10, Step: 504/938, Loss: 0.0005133089725859463\n",
            "Epoch: 9/10, Step: 505/938, Loss: 0.0033480501733720303\n",
            "Epoch: 9/10, Step: 506/938, Loss: 4.705416358774528e-05\n",
            "Epoch: 9/10, Step: 507/938, Loss: 0.00047593319322913885\n",
            "Epoch: 9/10, Step: 508/938, Loss: 4.7009725676616654e-05\n",
            "Epoch: 9/10, Step: 509/938, Loss: 3.020451003976632e-05\n",
            "Epoch: 9/10, Step: 510/938, Loss: 9.535847493680194e-05\n",
            "Epoch: 9/10, Step: 511/938, Loss: 0.0005377670750021935\n",
            "Epoch: 9/10, Step: 512/938, Loss: 7.101983646862209e-05\n",
            "Epoch: 9/10, Step: 513/938, Loss: 0.00011440489470260218\n",
            "Epoch: 9/10, Step: 514/938, Loss: 0.0020054690539836884\n",
            "Epoch: 9/10, Step: 515/938, Loss: 0.015223938040435314\n",
            "Epoch: 9/10, Step: 516/938, Loss: 0.0004321344313211739\n",
            "Epoch: 9/10, Step: 517/938, Loss: 0.0002489965409040451\n",
            "Epoch: 9/10, Step: 518/938, Loss: 5.6691214922466315e-06\n",
            "Epoch: 9/10, Step: 519/938, Loss: 3.087200821028091e-05\n",
            "Epoch: 9/10, Step: 520/938, Loss: 7.340087449847488e-06\n",
            "Epoch: 9/10, Step: 521/938, Loss: 0.00014227523934096098\n",
            "Epoch: 9/10, Step: 522/938, Loss: 0.00020510031026788056\n",
            "Epoch: 9/10, Step: 523/938, Loss: 7.525048886236618e-07\n",
            "Epoch: 9/10, Step: 524/938, Loss: 0.0024915621615946293\n",
            "Epoch: 9/10, Step: 525/938, Loss: 7.169330638134852e-05\n",
            "Epoch: 9/10, Step: 526/938, Loss: 0.000958998512942344\n",
            "Epoch: 9/10, Step: 527/938, Loss: 0.00020297791343182325\n",
            "Epoch: 9/10, Step: 528/938, Loss: 0.006823982112109661\n",
            "Epoch: 9/10, Step: 529/938, Loss: 0.0001098914653994143\n",
            "Epoch: 9/10, Step: 530/938, Loss: 2.1382595605246024e-06\n",
            "Epoch: 9/10, Step: 531/938, Loss: 0.0018425410380586982\n",
            "Epoch: 9/10, Step: 532/938, Loss: 0.0002942581195384264\n",
            "Epoch: 9/10, Step: 533/938, Loss: 8.871196041582152e-05\n",
            "Epoch: 9/10, Step: 534/938, Loss: 5.9786043493659236e-06\n",
            "Epoch: 9/10, Step: 535/938, Loss: 6.40746748103993e-07\n",
            "Epoch: 9/10, Step: 536/938, Loss: 5.580789365922101e-05\n",
            "Epoch: 9/10, Step: 537/938, Loss: 8.470335160382092e-05\n",
            "Epoch: 9/10, Step: 538/938, Loss: 2.4507045964128338e-05\n",
            "Epoch: 9/10, Step: 539/938, Loss: 1.9169096049154177e-05\n",
            "Epoch: 9/10, Step: 540/938, Loss: 0.0010659571271389723\n",
            "Epoch: 9/10, Step: 541/938, Loss: 0.0020438027568161488\n",
            "Epoch: 9/10, Step: 542/938, Loss: 9.968307131202891e-05\n",
            "Epoch: 9/10, Step: 543/938, Loss: 0.0004043026128783822\n",
            "Epoch: 9/10, Step: 544/938, Loss: 0.001191037124954164\n",
            "Epoch: 9/10, Step: 545/938, Loss: 0.00014651571109425277\n",
            "Epoch: 9/10, Step: 546/938, Loss: 0.025755474343895912\n",
            "Epoch: 9/10, Step: 547/938, Loss: 0.0004600337124429643\n",
            "Epoch: 9/10, Step: 548/938, Loss: 8.853203325998038e-05\n",
            "Epoch: 9/10, Step: 549/938, Loss: 0.00010098583879880607\n",
            "Epoch: 9/10, Step: 550/938, Loss: 2.532708822400309e-05\n",
            "Epoch: 9/10, Step: 551/938, Loss: 6.097013829275966e-05\n",
            "Epoch: 9/10, Step: 552/938, Loss: 0.001882852171547711\n",
            "Epoch: 9/10, Step: 553/938, Loss: 0.00021054630633443594\n",
            "Epoch: 9/10, Step: 554/938, Loss: 0.0007602329715155065\n",
            "Epoch: 9/10, Step: 555/938, Loss: 8.433285256614909e-05\n",
            "Epoch: 9/10, Step: 556/938, Loss: 0.0022228900343179703\n",
            "Epoch: 9/10, Step: 557/938, Loss: 0.0004350865201558918\n",
            "Epoch: 9/10, Step: 558/938, Loss: 6.9876446104899514e-06\n",
            "Epoch: 9/10, Step: 559/938, Loss: 0.0006606628885492682\n",
            "Epoch: 9/10, Step: 560/938, Loss: 0.00019326835172250867\n",
            "Epoch: 9/10, Step: 561/938, Loss: 0.0005957222892902792\n",
            "Epoch: 9/10, Step: 562/938, Loss: 0.010909836739301682\n",
            "Epoch: 9/10, Step: 563/938, Loss: 7.649092003703117e-05\n",
            "Epoch: 9/10, Step: 564/938, Loss: 0.028383605182170868\n",
            "Epoch: 9/10, Step: 565/938, Loss: 0.0008352046133950353\n",
            "Epoch: 9/10, Step: 566/938, Loss: 0.0006101017934270203\n",
            "Epoch: 9/10, Step: 567/938, Loss: 0.00015015358803793788\n",
            "Epoch: 9/10, Step: 568/938, Loss: 0.00855579786002636\n",
            "Epoch: 9/10, Step: 569/938, Loss: 2.24258255911991e-05\n",
            "Epoch: 9/10, Step: 570/938, Loss: 0.0008590586367063224\n",
            "Epoch: 9/10, Step: 571/938, Loss: 6.130497058620676e-05\n",
            "Epoch: 9/10, Step: 572/938, Loss: 0.00190010666847229\n",
            "Epoch: 9/10, Step: 573/938, Loss: 0.00038851096178404987\n",
            "Epoch: 9/10, Step: 574/938, Loss: 0.00020167698676232249\n",
            "Epoch: 9/10, Step: 575/938, Loss: 7.827154331607744e-05\n",
            "Epoch: 9/10, Step: 576/938, Loss: 2.2499939404951874e-06\n",
            "Epoch: 9/10, Step: 577/938, Loss: 2.674050301720854e-05\n",
            "Epoch: 9/10, Step: 578/938, Loss: 7.883645594120026e-06\n",
            "Epoch: 9/10, Step: 579/938, Loss: 2.7599955501500517e-05\n",
            "Epoch: 9/10, Step: 580/938, Loss: 7.913527952041477e-06\n",
            "Epoch: 9/10, Step: 581/938, Loss: 7.338168870774098e-06\n",
            "Epoch: 9/10, Step: 582/938, Loss: 5.1513106882339343e-05\n",
            "Epoch: 9/10, Step: 583/938, Loss: 0.00020071440667379647\n",
            "Epoch: 9/10, Step: 584/938, Loss: 0.05971294268965721\n",
            "Epoch: 9/10, Step: 585/938, Loss: 0.001121510285884142\n",
            "Epoch: 9/10, Step: 586/938, Loss: 0.0006377031677402556\n",
            "Epoch: 9/10, Step: 587/938, Loss: 0.0009276207420043647\n",
            "Epoch: 9/10, Step: 588/938, Loss: 1.0103836757480167e-05\n",
            "Epoch: 9/10, Step: 589/938, Loss: 0.010779512114822865\n",
            "Epoch: 9/10, Step: 590/938, Loss: 0.00021784902492072433\n",
            "Epoch: 9/10, Step: 591/938, Loss: 0.0025067573878914118\n",
            "Epoch: 9/10, Step: 592/938, Loss: 0.003898827824741602\n",
            "Epoch: 9/10, Step: 593/938, Loss: 7.798154547344893e-05\n",
            "Epoch: 9/10, Step: 594/938, Loss: 3.1366096209239913e-06\n",
            "Epoch: 9/10, Step: 595/938, Loss: 0.003151237266138196\n",
            "Epoch: 9/10, Step: 596/938, Loss: 3.86742249247618e-05\n",
            "Epoch: 9/10, Step: 597/938, Loss: 0.006835481617599726\n",
            "Epoch: 9/10, Step: 598/938, Loss: 0.0001600052637513727\n",
            "Epoch: 9/10, Step: 599/938, Loss: 0.0027805231511592865\n",
            "Epoch: 9/10, Step: 600/938, Loss: 3.4245356800965965e-05\n",
            "Epoch: 9/10, Step: 601/938, Loss: 8.801188960205764e-05\n",
            "Epoch: 9/10, Step: 602/938, Loss: 5.131217221787665e-06\n",
            "Epoch: 9/10, Step: 603/938, Loss: 0.056209906935691833\n",
            "Epoch: 9/10, Step: 604/938, Loss: 0.0006744824349880219\n",
            "Epoch: 9/10, Step: 605/938, Loss: 0.0017115127993747592\n",
            "Epoch: 9/10, Step: 606/938, Loss: 6.636192665609997e-06\n",
            "Epoch: 9/10, Step: 607/938, Loss: 0.028613479807972908\n",
            "Epoch: 9/10, Step: 608/938, Loss: 0.00025158212520182133\n",
            "Epoch: 9/10, Step: 609/938, Loss: 4.233350409776904e-05\n",
            "Epoch: 9/10, Step: 610/938, Loss: 0.00519599299877882\n",
            "Epoch: 9/10, Step: 611/938, Loss: 0.00037029714439995587\n",
            "Epoch: 9/10, Step: 612/938, Loss: 0.0007655342924408615\n",
            "Epoch: 9/10, Step: 613/938, Loss: 0.0034938461612910032\n",
            "Epoch: 9/10, Step: 614/938, Loss: 0.061862602829933167\n",
            "Epoch: 9/10, Step: 615/938, Loss: 0.004147584084421396\n",
            "Epoch: 9/10, Step: 616/938, Loss: 0.0017499204259365797\n",
            "Epoch: 9/10, Step: 617/938, Loss: 8.907690062187612e-05\n",
            "Epoch: 9/10, Step: 618/938, Loss: 2.4716853204154177e-06\n",
            "Epoch: 9/10, Step: 619/938, Loss: 0.00017129446496255696\n",
            "Epoch: 9/10, Step: 620/938, Loss: 1.9522165530361235e-05\n",
            "Epoch: 9/10, Step: 621/938, Loss: 0.0003548562526702881\n",
            "Epoch: 9/10, Step: 622/938, Loss: 0.012935090810060501\n",
            "Epoch: 9/10, Step: 623/938, Loss: 0.003775023389607668\n",
            "Epoch: 9/10, Step: 624/938, Loss: 2.106308784277644e-05\n",
            "Epoch: 9/10, Step: 625/938, Loss: 0.019361022859811783\n",
            "Epoch: 9/10, Step: 626/938, Loss: 0.0004165663558524102\n",
            "Epoch: 9/10, Step: 627/938, Loss: 0.05476854741573334\n",
            "Epoch: 9/10, Step: 628/938, Loss: 0.0002782906231004745\n",
            "Epoch: 9/10, Step: 629/938, Loss: 0.018276335671544075\n",
            "Epoch: 9/10, Step: 630/938, Loss: 0.0038674301467835903\n",
            "Epoch: 9/10, Step: 631/938, Loss: 0.0005283061182126403\n",
            "Epoch: 9/10, Step: 632/938, Loss: 0.0022064452059566975\n",
            "Epoch: 9/10, Step: 633/938, Loss: 6.148096872493625e-05\n",
            "Epoch: 9/10, Step: 634/938, Loss: 0.002630447270348668\n",
            "Epoch: 9/10, Step: 635/938, Loss: 0.0005815167096443474\n",
            "Epoch: 9/10, Step: 636/938, Loss: 0.021883592009544373\n",
            "Epoch: 9/10, Step: 637/938, Loss: 0.047685518860816956\n",
            "Epoch: 9/10, Step: 638/938, Loss: 0.006468667183071375\n",
            "Epoch: 9/10, Step: 639/938, Loss: 0.0005408696015365422\n",
            "Epoch: 9/10, Step: 640/938, Loss: 2.947919892903883e-05\n",
            "Epoch: 9/10, Step: 641/938, Loss: 0.002725223544985056\n",
            "Epoch: 9/10, Step: 642/938, Loss: 0.030699769034981728\n",
            "Epoch: 9/10, Step: 643/938, Loss: 0.01447934377938509\n",
            "Epoch: 9/10, Step: 644/938, Loss: 0.003697663079947233\n",
            "Epoch: 9/10, Step: 645/938, Loss: 0.015136565081775188\n",
            "Epoch: 9/10, Step: 646/938, Loss: 9.833765216171741e-05\n",
            "Epoch: 9/10, Step: 647/938, Loss: 0.00039070239290595055\n",
            "Epoch: 9/10, Step: 648/938, Loss: 0.015746289864182472\n",
            "Epoch: 9/10, Step: 649/938, Loss: 7.59422400733456e-05\n",
            "Epoch: 9/10, Step: 650/938, Loss: 0.0007190140895545483\n",
            "Epoch: 9/10, Step: 651/938, Loss: 0.00016531658184248954\n",
            "Epoch: 9/10, Step: 652/938, Loss: 0.0013372191460803151\n",
            "Epoch: 9/10, Step: 653/938, Loss: 0.005263238679617643\n",
            "Epoch: 9/10, Step: 654/938, Loss: 3.915557317668572e-05\n",
            "Epoch: 9/10, Step: 655/938, Loss: 0.00021721133089158684\n",
            "Epoch: 9/10, Step: 656/938, Loss: 0.0002842156682163477\n",
            "Epoch: 9/10, Step: 657/938, Loss: 0.001061613904312253\n",
            "Epoch: 9/10, Step: 658/938, Loss: 0.0003598271287046373\n",
            "Epoch: 9/10, Step: 659/938, Loss: 0.0006734809139743447\n",
            "Epoch: 9/10, Step: 660/938, Loss: 0.09862662106752396\n",
            "Epoch: 9/10, Step: 661/938, Loss: 0.0015097585273906589\n",
            "Epoch: 9/10, Step: 662/938, Loss: 6.384268635883927e-05\n",
            "Epoch: 9/10, Step: 663/938, Loss: 0.0003162021457683295\n",
            "Epoch: 9/10, Step: 664/938, Loss: 0.000474091648356989\n",
            "Epoch: 9/10, Step: 665/938, Loss: 0.0006274954648688436\n",
            "Epoch: 9/10, Step: 666/938, Loss: 1.0515670510358177e-05\n",
            "Epoch: 9/10, Step: 667/938, Loss: 0.005649169906973839\n",
            "Epoch: 9/10, Step: 668/938, Loss: 0.00024366792058572173\n",
            "Epoch: 9/10, Step: 669/938, Loss: 0.018185259774327278\n",
            "Epoch: 9/10, Step: 670/938, Loss: 2.1473606466315687e-05\n",
            "Epoch: 9/10, Step: 671/938, Loss: 0.03299602493643761\n",
            "Epoch: 9/10, Step: 672/938, Loss: 1.083030383597361e-05\n",
            "Epoch: 9/10, Step: 673/938, Loss: 0.00011860753875225782\n",
            "Epoch: 9/10, Step: 674/938, Loss: 0.00025372093659825623\n",
            "Epoch: 9/10, Step: 675/938, Loss: 3.836938412860036e-05\n",
            "Epoch: 9/10, Step: 676/938, Loss: 0.015561028383672237\n",
            "Epoch: 9/10, Step: 677/938, Loss: 0.01826748438179493\n",
            "Epoch: 9/10, Step: 678/938, Loss: 0.0011135126696899533\n",
            "Epoch: 9/10, Step: 679/938, Loss: 0.00018982055189553648\n",
            "Epoch: 9/10, Step: 680/938, Loss: 0.00020431751909200102\n",
            "Epoch: 9/10, Step: 681/938, Loss: 0.0005800887010991573\n",
            "Epoch: 9/10, Step: 682/938, Loss: 0.0012811679625883698\n",
            "Epoch: 9/10, Step: 683/938, Loss: 0.0005437348154373467\n",
            "Epoch: 9/10, Step: 684/938, Loss: 0.00023951739422045648\n",
            "Epoch: 9/10, Step: 685/938, Loss: 6.312024197541177e-06\n",
            "Epoch: 9/10, Step: 686/938, Loss: 0.005372317042201757\n",
            "Epoch: 9/10, Step: 687/938, Loss: 0.0049151461571455\n",
            "Epoch: 9/10, Step: 688/938, Loss: 0.0008487009909003973\n",
            "Epoch: 9/10, Step: 689/938, Loss: 0.00011750110570574179\n",
            "Epoch: 9/10, Step: 690/938, Loss: 0.0002223158226115629\n",
            "Epoch: 9/10, Step: 691/938, Loss: 5.375884211389348e-05\n",
            "Epoch: 9/10, Step: 692/938, Loss: 0.00010895111336139962\n",
            "Epoch: 9/10, Step: 693/938, Loss: 0.0005365483229979873\n",
            "Epoch: 9/10, Step: 694/938, Loss: 4.702218939200975e-05\n",
            "Epoch: 9/10, Step: 695/938, Loss: 0.006739164236932993\n",
            "Epoch: 9/10, Step: 696/938, Loss: 3.229371941415593e-05\n",
            "Epoch: 9/10, Step: 697/938, Loss: 0.0003671069862321019\n",
            "Epoch: 9/10, Step: 698/938, Loss: 6.258695793803781e-05\n",
            "Epoch: 9/10, Step: 699/938, Loss: 9.856067663349677e-06\n",
            "Epoch: 9/10, Step: 700/938, Loss: 1.9661707483464852e-05\n",
            "Epoch: 9/10, Step: 701/938, Loss: 5.1637307478813455e-05\n",
            "Epoch: 9/10, Step: 702/938, Loss: 0.00010260150884278119\n",
            "Epoch: 9/10, Step: 703/938, Loss: 1.7300748368143104e-05\n",
            "Epoch: 9/10, Step: 704/938, Loss: 4.119208824704401e-05\n",
            "Epoch: 9/10, Step: 705/938, Loss: 1.440770756744314e-05\n",
            "Epoch: 9/10, Step: 706/938, Loss: 0.00010244092845823616\n",
            "Epoch: 9/10, Step: 707/938, Loss: 8.254587555711623e-06\n",
            "Epoch: 9/10, Step: 708/938, Loss: 0.0005774259334430099\n",
            "Epoch: 9/10, Step: 709/938, Loss: 0.00012744750711135566\n",
            "Epoch: 9/10, Step: 710/938, Loss: 0.00032804999500513077\n",
            "Epoch: 9/10, Step: 711/938, Loss: 8.13818842289038e-05\n",
            "Epoch: 9/10, Step: 712/938, Loss: 0.0018458748236298561\n",
            "Epoch: 9/10, Step: 713/938, Loss: 0.005649736616760492\n",
            "Epoch: 9/10, Step: 714/938, Loss: 7.678029942326248e-05\n",
            "Epoch: 9/10, Step: 715/938, Loss: 0.0011427982244640589\n",
            "Epoch: 9/10, Step: 716/938, Loss: 0.0006076943827793002\n",
            "Epoch: 9/10, Step: 717/938, Loss: 2.8250688046682626e-05\n",
            "Epoch: 9/10, Step: 718/938, Loss: 0.0019477561581879854\n",
            "Epoch: 9/10, Step: 719/938, Loss: 0.004258282016962767\n",
            "Epoch: 9/10, Step: 720/938, Loss: 0.00024605004000477493\n",
            "Epoch: 9/10, Step: 721/938, Loss: 0.004817191511392593\n",
            "Epoch: 9/10, Step: 722/938, Loss: 1.3626841791847255e-05\n",
            "Epoch: 9/10, Step: 723/938, Loss: 0.0005563486483879387\n",
            "Epoch: 9/10, Step: 724/938, Loss: 2.6475034246686846e-05\n",
            "Epoch: 9/10, Step: 725/938, Loss: 0.00014337379252538085\n",
            "Epoch: 9/10, Step: 726/938, Loss: 0.0004934787866659462\n",
            "Epoch: 9/10, Step: 727/938, Loss: 0.006961184088140726\n",
            "Epoch: 9/10, Step: 728/938, Loss: 0.00011257243022555485\n",
            "Epoch: 9/10, Step: 729/938, Loss: 0.00031751609640195966\n",
            "Epoch: 9/10, Step: 730/938, Loss: 5.469027382787317e-05\n",
            "Epoch: 9/10, Step: 731/938, Loss: 0.04156430438160896\n",
            "Epoch: 9/10, Step: 732/938, Loss: 0.09866044670343399\n",
            "Epoch: 9/10, Step: 733/938, Loss: 2.6307434382033534e-05\n",
            "Epoch: 9/10, Step: 734/938, Loss: 0.0007275736425071955\n",
            "Epoch: 9/10, Step: 735/938, Loss: 7.383263437077403e-06\n",
            "Epoch: 9/10, Step: 736/938, Loss: 0.001252516871318221\n",
            "Epoch: 9/10, Step: 737/938, Loss: 0.00017908337758854032\n",
            "Epoch: 9/10, Step: 738/938, Loss: 0.0001079136345651932\n",
            "Epoch: 9/10, Step: 739/938, Loss: 0.0001360052265226841\n",
            "Epoch: 9/10, Step: 740/938, Loss: 9.081250755116343e-05\n",
            "Epoch: 9/10, Step: 741/938, Loss: 0.0017657758435234427\n",
            "Epoch: 9/10, Step: 742/938, Loss: 6.528767698910087e-05\n",
            "Epoch: 9/10, Step: 743/938, Loss: 0.00026237519341520965\n",
            "Epoch: 9/10, Step: 744/938, Loss: 0.0005458396626636386\n",
            "Epoch: 9/10, Step: 745/938, Loss: 0.00016835662245284766\n",
            "Epoch: 9/10, Step: 746/938, Loss: 3.4953001886606216e-05\n",
            "Epoch: 9/10, Step: 747/938, Loss: 0.001417147577740252\n",
            "Epoch: 9/10, Step: 748/938, Loss: 9.655194298829883e-05\n",
            "Epoch: 9/10, Step: 749/938, Loss: 0.00042415299685671926\n",
            "Epoch: 9/10, Step: 750/938, Loss: 0.001650389051064849\n",
            "Epoch: 9/10, Step: 751/938, Loss: 0.00040752944187261164\n",
            "Epoch: 9/10, Step: 752/938, Loss: 2.7918291380046867e-05\n",
            "Epoch: 9/10, Step: 753/938, Loss: 0.0005321388598531485\n",
            "Epoch: 9/10, Step: 754/938, Loss: 0.0020810686983168125\n",
            "Epoch: 9/10, Step: 755/938, Loss: 0.04300917312502861\n",
            "Epoch: 9/10, Step: 756/938, Loss: 4.426671875989996e-05\n",
            "Epoch: 9/10, Step: 757/938, Loss: 0.0028555633034557104\n",
            "Epoch: 9/10, Step: 758/938, Loss: 0.005006647668778896\n",
            "Epoch: 9/10, Step: 759/938, Loss: 2.5529920094413683e-05\n",
            "Epoch: 9/10, Step: 760/938, Loss: 0.0005781381041742861\n",
            "Epoch: 9/10, Step: 761/938, Loss: 0.0005790034192614257\n",
            "Epoch: 9/10, Step: 762/938, Loss: 4.115723641007207e-05\n",
            "Epoch: 9/10, Step: 763/938, Loss: 0.003356993431225419\n",
            "Epoch: 9/10, Step: 764/938, Loss: 0.005017318297177553\n",
            "Epoch: 9/10, Step: 765/938, Loss: 0.00030708781559951603\n",
            "Epoch: 9/10, Step: 766/938, Loss: 2.854835838661529e-05\n",
            "Epoch: 9/10, Step: 767/938, Loss: 0.00023781511117704213\n",
            "Epoch: 9/10, Step: 768/938, Loss: 0.0005555552197620273\n",
            "Epoch: 9/10, Step: 769/938, Loss: 0.00011376323527656496\n",
            "Epoch: 9/10, Step: 770/938, Loss: 0.0001524174731457606\n",
            "Epoch: 9/10, Step: 771/938, Loss: 0.02369854785501957\n",
            "Epoch: 9/10, Step: 772/938, Loss: 0.002745314035564661\n",
            "Epoch: 9/10, Step: 773/938, Loss: 7.879453187342733e-05\n",
            "Epoch: 9/10, Step: 774/938, Loss: 0.0014085022266954184\n",
            "Epoch: 9/10, Step: 775/938, Loss: 0.0009598849574103951\n",
            "Epoch: 9/10, Step: 776/938, Loss: 2.5834777261479758e-05\n",
            "Epoch: 9/10, Step: 777/938, Loss: 4.2670362745411694e-05\n",
            "Epoch: 9/10, Step: 778/938, Loss: 5.725501523556886e-06\n",
            "Epoch: 9/10, Step: 779/938, Loss: 0.006588590331375599\n",
            "Epoch: 9/10, Step: 780/938, Loss: 1.792983675841242e-05\n",
            "Epoch: 9/10, Step: 781/938, Loss: 2.0040131857967936e-05\n",
            "Epoch: 9/10, Step: 782/938, Loss: 0.00010022143396781757\n",
            "Epoch: 9/10, Step: 783/938, Loss: 0.020089369267225266\n",
            "Epoch: 9/10, Step: 784/938, Loss: 0.0006824696902185678\n",
            "Epoch: 9/10, Step: 785/938, Loss: 4.316965350881219e-05\n",
            "Epoch: 9/10, Step: 786/938, Loss: 0.0016647633165121078\n",
            "Epoch: 9/10, Step: 787/938, Loss: 0.0030095733236521482\n",
            "Epoch: 9/10, Step: 788/938, Loss: 0.00043784017907455564\n",
            "Epoch: 9/10, Step: 789/938, Loss: 5.127684289618628e-06\n",
            "Epoch: 9/10, Step: 790/938, Loss: 6.261761154746637e-05\n",
            "Epoch: 9/10, Step: 791/938, Loss: 0.0002881329564843327\n",
            "Epoch: 9/10, Step: 792/938, Loss: 9.581421909388155e-05\n",
            "Epoch: 9/10, Step: 793/938, Loss: 0.002445975551381707\n",
            "Epoch: 9/10, Step: 794/938, Loss: 0.0005041905678808689\n",
            "Epoch: 9/10, Step: 795/938, Loss: 0.00017193620442412794\n",
            "Epoch: 9/10, Step: 796/938, Loss: 5.880161916138604e-05\n",
            "Epoch: 9/10, Step: 797/938, Loss: 1.9038225218537264e-05\n",
            "Epoch: 9/10, Step: 798/938, Loss: 6.497703725472093e-05\n",
            "Epoch: 9/10, Step: 799/938, Loss: 0.000680123339407146\n",
            "Epoch: 9/10, Step: 800/938, Loss: 0.00244935043156147\n",
            "Epoch: 9/10, Step: 801/938, Loss: 7.047575309115928e-06\n",
            "Epoch: 9/10, Step: 802/938, Loss: 2.235434476460796e-05\n",
            "Epoch: 9/10, Step: 803/938, Loss: 0.00028823665343225\n",
            "Epoch: 9/10, Step: 804/938, Loss: 5.245805004960857e-05\n",
            "Epoch: 9/10, Step: 805/938, Loss: 7.468282274203375e-05\n",
            "Epoch: 9/10, Step: 806/938, Loss: 0.05500641092658043\n",
            "Epoch: 9/10, Step: 807/938, Loss: 0.003318114671856165\n",
            "Epoch: 9/10, Step: 808/938, Loss: 3.8739868614356965e-05\n",
            "Epoch: 9/10, Step: 809/938, Loss: 0.0010938728228211403\n",
            "Epoch: 9/10, Step: 810/938, Loss: 2.482181298546493e-05\n",
            "Epoch: 9/10, Step: 811/938, Loss: 2.8736802050843835e-05\n",
            "Epoch: 9/10, Step: 812/938, Loss: 0.0008179954020306468\n",
            "Epoch: 9/10, Step: 813/938, Loss: 1.7377418771502562e-05\n",
            "Epoch: 9/10, Step: 814/938, Loss: 0.001981992507353425\n",
            "Epoch: 9/10, Step: 815/938, Loss: 7.230431219795719e-05\n",
            "Epoch: 9/10, Step: 816/938, Loss: 0.004775225184857845\n",
            "Epoch: 9/10, Step: 817/938, Loss: 1.0440902769914828e-05\n",
            "Epoch: 9/10, Step: 818/938, Loss: 0.005373745691031218\n",
            "Epoch: 9/10, Step: 819/938, Loss: 0.0048021068796515465\n",
            "Epoch: 9/10, Step: 820/938, Loss: 0.00027700135251507163\n",
            "Epoch: 9/10, Step: 821/938, Loss: 2.3748398234602064e-06\n",
            "Epoch: 9/10, Step: 822/938, Loss: 5.922970740357414e-05\n",
            "Epoch: 9/10, Step: 823/938, Loss: 0.0010076354956254363\n",
            "Epoch: 9/10, Step: 824/938, Loss: 4.9148243306262884e-06\n",
            "Epoch: 9/10, Step: 825/938, Loss: 0.000453811400802806\n",
            "Epoch: 9/10, Step: 826/938, Loss: 0.00023423723177984357\n",
            "Epoch: 9/10, Step: 827/938, Loss: 0.0003943675255868584\n",
            "Epoch: 9/10, Step: 828/938, Loss: 0.0011905599385499954\n",
            "Epoch: 9/10, Step: 829/938, Loss: 0.00020369810226839036\n",
            "Epoch: 9/10, Step: 830/938, Loss: 1.132618126575835e-05\n",
            "Epoch: 9/10, Step: 831/938, Loss: 0.013039853423833847\n",
            "Epoch: 9/10, Step: 832/938, Loss: 0.07292697578668594\n",
            "Epoch: 9/10, Step: 833/938, Loss: 9.741420399222989e-07\n",
            "Epoch: 9/10, Step: 834/938, Loss: 0.00037439126754179597\n",
            "Epoch: 9/10, Step: 835/938, Loss: 0.00010197897790931165\n",
            "Epoch: 9/10, Step: 836/938, Loss: 0.02054709941148758\n",
            "Epoch: 9/10, Step: 837/938, Loss: 7.96107815403957e-06\n",
            "Epoch: 9/10, Step: 838/938, Loss: 8.74494799063541e-05\n",
            "Epoch: 9/10, Step: 839/938, Loss: 0.0001469927519792691\n",
            "Epoch: 9/10, Step: 840/938, Loss: 0.0003245638799853623\n",
            "Epoch: 9/10, Step: 841/938, Loss: 0.000509109697304666\n",
            "Epoch: 9/10, Step: 842/938, Loss: 6.341504195006564e-05\n",
            "Epoch: 9/10, Step: 843/938, Loss: 1.789101770555135e-05\n",
            "Epoch: 9/10, Step: 844/938, Loss: 0.00015241412620525807\n",
            "Epoch: 9/10, Step: 845/938, Loss: 2.6449004053574754e-06\n",
            "Epoch: 9/10, Step: 846/938, Loss: 9.567820598022081e-06\n",
            "Epoch: 9/10, Step: 847/938, Loss: 8.154027455020696e-05\n",
            "Epoch: 9/10, Step: 848/938, Loss: 0.004421598743647337\n",
            "Epoch: 9/10, Step: 849/938, Loss: 1.559320298838429e-05\n",
            "Epoch: 9/10, Step: 850/938, Loss: 0.00017834843310993165\n",
            "Epoch: 9/10, Step: 851/938, Loss: 0.0013527469709515572\n",
            "Epoch: 9/10, Step: 852/938, Loss: 0.003043056931346655\n",
            "Epoch: 9/10, Step: 853/938, Loss: 3.24585780617781e-05\n",
            "Epoch: 9/10, Step: 854/938, Loss: 0.00797202903777361\n",
            "Epoch: 9/10, Step: 855/938, Loss: 0.0013014599680900574\n",
            "Epoch: 9/10, Step: 856/938, Loss: 9.662698721513152e-05\n",
            "Epoch: 9/10, Step: 857/938, Loss: 0.028472773730754852\n",
            "Epoch: 9/10, Step: 858/938, Loss: 0.002393521601334214\n",
            "Epoch: 9/10, Step: 859/938, Loss: 0.00010030339763034135\n",
            "Epoch: 9/10, Step: 860/938, Loss: 1.603822056495119e-05\n",
            "Epoch: 9/10, Step: 861/938, Loss: 0.00022610057203564793\n",
            "Epoch: 9/10, Step: 862/938, Loss: 0.0015499746659770608\n",
            "Epoch: 9/10, Step: 863/938, Loss: 0.00959013681858778\n",
            "Epoch: 9/10, Step: 864/938, Loss: 3.796327655436471e-05\n",
            "Epoch: 9/10, Step: 865/938, Loss: 8.583177259424701e-05\n",
            "Epoch: 9/10, Step: 866/938, Loss: 1.5198883147604647e-06\n",
            "Epoch: 9/10, Step: 867/938, Loss: 0.0002473999629728496\n",
            "Epoch: 9/10, Step: 868/938, Loss: 0.0004913108423352242\n",
            "Epoch: 9/10, Step: 869/938, Loss: 0.0014343936927616596\n",
            "Epoch: 9/10, Step: 870/938, Loss: 0.00012335964129306376\n",
            "Epoch: 9/10, Step: 871/938, Loss: 0.0014951098710298538\n",
            "Epoch: 9/10, Step: 872/938, Loss: 2.1573847334366292e-05\n",
            "Epoch: 9/10, Step: 873/938, Loss: 0.0002252038975711912\n",
            "Epoch: 9/10, Step: 874/938, Loss: 2.393501199549064e-05\n",
            "Epoch: 9/10, Step: 875/938, Loss: 0.004143544472754002\n",
            "Epoch: 9/10, Step: 876/938, Loss: 0.05232597142457962\n",
            "Epoch: 9/10, Step: 877/938, Loss: 4.627252201316878e-05\n",
            "Epoch: 9/10, Step: 878/938, Loss: 0.0004849277320317924\n",
            "Epoch: 9/10, Step: 879/938, Loss: 0.0069239321164786816\n",
            "Epoch: 9/10, Step: 880/938, Loss: 0.002950311405584216\n",
            "Epoch: 9/10, Step: 881/938, Loss: 0.0004345743509475142\n",
            "Epoch: 9/10, Step: 882/938, Loss: 0.024262867867946625\n",
            "Epoch: 9/10, Step: 883/938, Loss: 0.01108870655298233\n",
            "Epoch: 9/10, Step: 884/938, Loss: 0.00036685532541014254\n",
            "Epoch: 9/10, Step: 885/938, Loss: 5.056407462689094e-05\n",
            "Epoch: 9/10, Step: 886/938, Loss: 0.0023413673043251038\n",
            "Epoch: 9/10, Step: 887/938, Loss: 2.8529411792987958e-05\n",
            "Epoch: 9/10, Step: 888/938, Loss: 9.341567056253552e-05\n",
            "Epoch: 9/10, Step: 889/938, Loss: 1.27030716612353e-06\n",
            "Epoch: 9/10, Step: 890/938, Loss: 2.5632602046243846e-05\n",
            "Epoch: 9/10, Step: 891/938, Loss: 0.0616900734603405\n",
            "Epoch: 9/10, Step: 892/938, Loss: 0.00027697565383277833\n",
            "Epoch: 9/10, Step: 893/938, Loss: 0.0010685898596420884\n",
            "Epoch: 9/10, Step: 894/938, Loss: 6.6100932599511e-05\n",
            "Epoch: 9/10, Step: 895/938, Loss: 0.001136712497100234\n",
            "Epoch: 9/10, Step: 896/938, Loss: 4.9755464715417475e-05\n",
            "Epoch: 9/10, Step: 897/938, Loss: 0.004306452814489603\n",
            "Epoch: 9/10, Step: 898/938, Loss: 0.010796481743454933\n",
            "Epoch: 9/10, Step: 899/938, Loss: 0.04005742445588112\n",
            "Epoch: 9/10, Step: 900/938, Loss: 0.0009644897654652596\n",
            "Epoch: 9/10, Step: 901/938, Loss: 0.01905185729265213\n",
            "Epoch: 9/10, Step: 902/938, Loss: 0.0006146488594822586\n",
            "Epoch: 9/10, Step: 903/938, Loss: 0.0005383359966799617\n",
            "Epoch: 9/10, Step: 904/938, Loss: 0.0008661788306199014\n",
            "Epoch: 9/10, Step: 905/938, Loss: 0.002105884486809373\n",
            "Epoch: 9/10, Step: 906/938, Loss: 8.614883699920028e-05\n",
            "Epoch: 9/10, Step: 907/938, Loss: 0.0027891614008694887\n",
            "Epoch: 9/10, Step: 908/938, Loss: 2.882818807847798e-05\n",
            "Epoch: 9/10, Step: 909/938, Loss: 0.0353272445499897\n",
            "Epoch: 9/10, Step: 910/938, Loss: 0.0021395995281636715\n",
            "Epoch: 9/10, Step: 911/938, Loss: 0.00010120442311745137\n",
            "Epoch: 9/10, Step: 912/938, Loss: 0.00013762564049102366\n",
            "Epoch: 9/10, Step: 913/938, Loss: 0.00026186168543063104\n",
            "Epoch: 9/10, Step: 914/938, Loss: 0.0002771268191281706\n",
            "Epoch: 9/10, Step: 915/938, Loss: 0.030089760199189186\n",
            "Epoch: 9/10, Step: 916/938, Loss: 0.001832080539315939\n",
            "Epoch: 9/10, Step: 917/938, Loss: 0.035323839634656906\n",
            "Epoch: 9/10, Step: 918/938, Loss: 7.969622856762726e-06\n",
            "Epoch: 9/10, Step: 919/938, Loss: 0.0002827951102517545\n",
            "Epoch: 9/10, Step: 920/938, Loss: 0.00046184397069737315\n",
            "Epoch: 9/10, Step: 921/938, Loss: 0.001995048252865672\n",
            "Epoch: 9/10, Step: 922/938, Loss: 0.00017500125977676362\n",
            "Epoch: 9/10, Step: 923/938, Loss: 0.0002543678565416485\n",
            "Epoch: 9/10, Step: 924/938, Loss: 0.020141666755080223\n",
            "Epoch: 9/10, Step: 925/938, Loss: 2.9414581149467267e-05\n",
            "Epoch: 9/10, Step: 926/938, Loss: 0.0008180619333870709\n",
            "Epoch: 9/10, Step: 927/938, Loss: 0.00021378317615017295\n",
            "Epoch: 9/10, Step: 928/938, Loss: 8.368322596652433e-06\n",
            "Epoch: 9/10, Step: 929/938, Loss: 2.553630565671483e-06\n",
            "Epoch: 9/10, Step: 930/938, Loss: 0.00030091963708400726\n",
            "Epoch: 9/10, Step: 931/938, Loss: 0.011125101707875729\n",
            "Epoch: 9/10, Step: 932/938, Loss: 0.016122888773679733\n",
            "Epoch: 9/10, Step: 933/938, Loss: 0.04151073098182678\n",
            "Epoch: 9/10, Step: 934/938, Loss: 2.05258129426511e-06\n",
            "Epoch: 9/10, Step: 935/938, Loss: 0.00020784480147995055\n",
            "Epoch: 9/10, Step: 936/938, Loss: 0.0020767117384821177\n",
            "Epoch: 9/10, Step: 937/938, Loss: 0.00011900896788574755\n",
            "Epoch: 9/10, Step: 938/938, Loss: 7.413299272229779e-07\n",
            "Epoch: 10/10, Step: 1/938, Loss: 0.0017183164600282907\n",
            "Epoch: 10/10, Step: 2/938, Loss: 0.0003172385913785547\n",
            "Epoch: 10/10, Step: 3/938, Loss: 0.0004434359725564718\n",
            "Epoch: 10/10, Step: 4/938, Loss: 0.00023553460778202862\n",
            "Epoch: 10/10, Step: 5/938, Loss: 7.236286910483614e-05\n",
            "Epoch: 10/10, Step: 6/938, Loss: 0.004111983813345432\n",
            "Epoch: 10/10, Step: 7/938, Loss: 0.10193746536970139\n",
            "Epoch: 10/10, Step: 8/938, Loss: 6.8039727921132e-05\n",
            "Epoch: 10/10, Step: 9/938, Loss: 0.0007083071977831423\n",
            "Epoch: 10/10, Step: 10/938, Loss: 0.00625491002574563\n",
            "Epoch: 10/10, Step: 11/938, Loss: 0.0007700480055063963\n",
            "Epoch: 10/10, Step: 12/938, Loss: 0.00029156063101254404\n",
            "Epoch: 10/10, Step: 13/938, Loss: 1.800097197701689e-05\n",
            "Epoch: 10/10, Step: 14/938, Loss: 0.035697534680366516\n",
            "Epoch: 10/10, Step: 15/938, Loss: 3.688294600578956e-05\n",
            "Epoch: 10/10, Step: 16/938, Loss: 0.0014022111427038908\n",
            "Epoch: 10/10, Step: 17/938, Loss: 7.53820058889687e-05\n",
            "Epoch: 10/10, Step: 18/938, Loss: 0.014119490049779415\n",
            "Epoch: 10/10, Step: 19/938, Loss: 0.0007690483471378684\n",
            "Epoch: 10/10, Step: 20/938, Loss: 2.8286318411119282e-05\n",
            "Epoch: 10/10, Step: 21/938, Loss: 0.0001580860116519034\n",
            "Epoch: 10/10, Step: 22/938, Loss: 0.0003055592824239284\n",
            "Epoch: 10/10, Step: 23/938, Loss: 0.0027949954383075237\n",
            "Epoch: 10/10, Step: 24/938, Loss: 0.0001732330274535343\n",
            "Epoch: 10/10, Step: 25/938, Loss: 0.00029071050812490284\n",
            "Epoch: 10/10, Step: 26/938, Loss: 0.0020668760407716036\n",
            "Epoch: 10/10, Step: 27/938, Loss: 5.6403929193038493e-05\n",
            "Epoch: 10/10, Step: 28/938, Loss: 1.4420224033528939e-05\n",
            "Epoch: 10/10, Step: 29/938, Loss: 0.0016027732053771615\n",
            "Epoch: 10/10, Step: 30/938, Loss: 0.00370504567399621\n",
            "Epoch: 10/10, Step: 31/938, Loss: 0.0010604881681501865\n",
            "Epoch: 10/10, Step: 32/938, Loss: 0.02266591414809227\n",
            "Epoch: 10/10, Step: 33/938, Loss: 0.003265542211011052\n",
            "Epoch: 10/10, Step: 34/938, Loss: 0.00018831412307918072\n",
            "Epoch: 10/10, Step: 35/938, Loss: 1.1381215699657332e-05\n",
            "Epoch: 10/10, Step: 36/938, Loss: 3.957885564886965e-05\n",
            "Epoch: 10/10, Step: 37/938, Loss: 0.027790876105427742\n",
            "Epoch: 10/10, Step: 38/938, Loss: 0.0004842637572437525\n",
            "Epoch: 10/10, Step: 39/938, Loss: 2.409643457212951e-05\n",
            "Epoch: 10/10, Step: 40/938, Loss: 0.006463265977799892\n",
            "Epoch: 10/10, Step: 41/938, Loss: 0.00028704426949843764\n",
            "Epoch: 10/10, Step: 42/938, Loss: 0.000424589728936553\n",
            "Epoch: 10/10, Step: 43/938, Loss: 0.0014369833515956998\n",
            "Epoch: 10/10, Step: 44/938, Loss: 0.038050271570682526\n",
            "Epoch: 10/10, Step: 45/938, Loss: 0.0003736122162081301\n",
            "Epoch: 10/10, Step: 46/938, Loss: 0.00012088855146430433\n",
            "Epoch: 10/10, Step: 47/938, Loss: 0.0018746149726212025\n",
            "Epoch: 10/10, Step: 48/938, Loss: 4.971128419128945e-06\n",
            "Epoch: 10/10, Step: 49/938, Loss: 0.0006556412554346025\n",
            "Epoch: 10/10, Step: 50/938, Loss: 0.00014276968431659043\n",
            "Epoch: 10/10, Step: 51/938, Loss: 4.0279002860188484e-05\n",
            "Epoch: 10/10, Step: 52/938, Loss: 0.015170877799391747\n",
            "Epoch: 10/10, Step: 53/938, Loss: 6.675343684037216e-06\n",
            "Epoch: 10/10, Step: 54/938, Loss: 0.0006611637072637677\n",
            "Epoch: 10/10, Step: 55/938, Loss: 0.0005898442468605936\n",
            "Epoch: 10/10, Step: 56/938, Loss: 0.006056805606931448\n",
            "Epoch: 10/10, Step: 57/938, Loss: 4.428729516803287e-05\n",
            "Epoch: 10/10, Step: 58/938, Loss: 8.721212361706421e-05\n",
            "Epoch: 10/10, Step: 59/938, Loss: 0.00024411213234998286\n",
            "Epoch: 10/10, Step: 60/938, Loss: 0.0010538571514189243\n",
            "Epoch: 10/10, Step: 61/938, Loss: 0.004608017858117819\n",
            "Epoch: 10/10, Step: 62/938, Loss: 0.00011656923743430525\n",
            "Epoch: 10/10, Step: 63/938, Loss: 0.0003264469560235739\n",
            "Epoch: 10/10, Step: 64/938, Loss: 0.04423128813505173\n",
            "Epoch: 10/10, Step: 65/938, Loss: 0.0003690082230605185\n",
            "Epoch: 10/10, Step: 66/938, Loss: 0.00030013854848220944\n",
            "Epoch: 10/10, Step: 67/938, Loss: 0.00015709539002273232\n",
            "Epoch: 10/10, Step: 68/938, Loss: 9.70381370279938e-05\n",
            "Epoch: 10/10, Step: 69/938, Loss: 1.745229383232072e-05\n",
            "Epoch: 10/10, Step: 70/938, Loss: 8.300387889903504e-06\n",
            "Epoch: 10/10, Step: 71/938, Loss: 0.0002786582917906344\n",
            "Epoch: 10/10, Step: 72/938, Loss: 0.0005658204318024218\n",
            "Epoch: 10/10, Step: 73/938, Loss: 1.982795583899133e-05\n",
            "Epoch: 10/10, Step: 74/938, Loss: 0.0012844488956034184\n",
            "Epoch: 10/10, Step: 75/938, Loss: 1.6115578546305187e-05\n",
            "Epoch: 10/10, Step: 76/938, Loss: 0.05546049401164055\n",
            "Epoch: 10/10, Step: 77/938, Loss: 0.0016077372711151838\n",
            "Epoch: 10/10, Step: 78/938, Loss: 1.2535429050331004e-06\n",
            "Epoch: 10/10, Step: 79/938, Loss: 0.00014262697368394583\n",
            "Epoch: 10/10, Step: 80/938, Loss: 0.0006942684412933886\n",
            "Epoch: 10/10, Step: 81/938, Loss: 3.4129210689570755e-05\n",
            "Epoch: 10/10, Step: 82/938, Loss: 1.0910172932199202e-05\n",
            "Epoch: 10/10, Step: 83/938, Loss: 0.09253625571727753\n",
            "Epoch: 10/10, Step: 84/938, Loss: 0.013459905982017517\n",
            "Epoch: 10/10, Step: 85/938, Loss: 0.001223619794473052\n",
            "Epoch: 10/10, Step: 86/938, Loss: 0.0010172352194786072\n",
            "Epoch: 10/10, Step: 87/938, Loss: 0.0007291146321222186\n",
            "Epoch: 10/10, Step: 88/938, Loss: 0.004269669763743877\n",
            "Epoch: 10/10, Step: 89/938, Loss: 0.0005549317575059831\n",
            "Epoch: 10/10, Step: 90/938, Loss: 0.001030669896863401\n",
            "Epoch: 10/10, Step: 91/938, Loss: 0.0003297542571090162\n",
            "Epoch: 10/10, Step: 92/938, Loss: 0.0003899239527527243\n",
            "Epoch: 10/10, Step: 93/938, Loss: 0.001323513686656952\n",
            "Epoch: 10/10, Step: 94/938, Loss: 0.0003527440130710602\n",
            "Epoch: 10/10, Step: 95/938, Loss: 0.0018962029134854674\n",
            "Epoch: 10/10, Step: 96/938, Loss: 8.403068204643205e-05\n",
            "Epoch: 10/10, Step: 97/938, Loss: 0.00015314461779780686\n",
            "Epoch: 10/10, Step: 98/938, Loss: 0.0005912839551456273\n",
            "Epoch: 10/10, Step: 99/938, Loss: 0.0021339531522244215\n",
            "Epoch: 10/10, Step: 100/938, Loss: 0.005927888676524162\n",
            "Epoch: 10/10, Step: 101/938, Loss: 0.0023583918809890747\n",
            "Epoch: 10/10, Step: 102/938, Loss: 2.730498817982152e-05\n",
            "Epoch: 10/10, Step: 103/938, Loss: 0.00020177765691187233\n",
            "Epoch: 10/10, Step: 104/938, Loss: 7.263464794959873e-05\n",
            "Epoch: 10/10, Step: 105/938, Loss: 0.03860985487699509\n",
            "Epoch: 10/10, Step: 106/938, Loss: 0.00021533285325858742\n",
            "Epoch: 10/10, Step: 107/938, Loss: 8.351973519893363e-05\n",
            "Epoch: 10/10, Step: 108/938, Loss: 0.00021071734954603016\n",
            "Epoch: 10/10, Step: 109/938, Loss: 6.334085628623143e-05\n",
            "Epoch: 10/10, Step: 110/938, Loss: 2.0916344510624185e-05\n",
            "Epoch: 10/10, Step: 111/938, Loss: 0.012696058489382267\n",
            "Epoch: 10/10, Step: 112/938, Loss: 0.0014579272828996181\n",
            "Epoch: 10/10, Step: 113/938, Loss: 0.0171833299100399\n",
            "Epoch: 10/10, Step: 114/938, Loss: 0.061889901757240295\n",
            "Epoch: 10/10, Step: 115/938, Loss: 0.00011414199252612889\n",
            "Epoch: 10/10, Step: 116/938, Loss: 0.00016611209139227867\n",
            "Epoch: 10/10, Step: 117/938, Loss: 0.003794277086853981\n",
            "Epoch: 10/10, Step: 118/938, Loss: 0.00013486221723724157\n",
            "Epoch: 10/10, Step: 119/938, Loss: 0.003913670312613249\n",
            "Epoch: 10/10, Step: 120/938, Loss: 0.00011699770402628928\n",
            "Epoch: 10/10, Step: 121/938, Loss: 0.01728546991944313\n",
            "Epoch: 10/10, Step: 122/938, Loss: 0.00015837966930121183\n",
            "Epoch: 10/10, Step: 123/938, Loss: 0.0027469717897474766\n",
            "Epoch: 10/10, Step: 124/938, Loss: 9.042328747455031e-05\n",
            "Epoch: 10/10, Step: 125/938, Loss: 0.0009757874067872763\n",
            "Epoch: 10/10, Step: 126/938, Loss: 0.00019396976858843118\n",
            "Epoch: 10/10, Step: 127/938, Loss: 0.0004772291285917163\n",
            "Epoch: 10/10, Step: 128/938, Loss: 0.001658477121964097\n",
            "Epoch: 10/10, Step: 129/938, Loss: 0.021877478808164597\n",
            "Epoch: 10/10, Step: 130/938, Loss: 0.0021499579306691885\n",
            "Epoch: 10/10, Step: 131/938, Loss: 2.8612166715902276e-05\n",
            "Epoch: 10/10, Step: 132/938, Loss: 0.04786715656518936\n",
            "Epoch: 10/10, Step: 133/938, Loss: 0.00011613537208177149\n",
            "Epoch: 10/10, Step: 134/938, Loss: 0.0013955291360616684\n",
            "Epoch: 10/10, Step: 135/938, Loss: 0.00066908891312778\n",
            "Epoch: 10/10, Step: 136/938, Loss: 0.00011214570986339822\n",
            "Epoch: 10/10, Step: 137/938, Loss: 0.002266120398417115\n",
            "Epoch: 10/10, Step: 138/938, Loss: 0.002072551054880023\n",
            "Epoch: 10/10, Step: 139/938, Loss: 0.00012728030560538173\n",
            "Epoch: 10/10, Step: 140/938, Loss: 0.008824111893773079\n",
            "Epoch: 10/10, Step: 141/938, Loss: 0.002750934800133109\n",
            "Epoch: 10/10, Step: 142/938, Loss: 0.0014988617040216923\n",
            "Epoch: 10/10, Step: 143/938, Loss: 0.001140095992013812\n",
            "Epoch: 10/10, Step: 144/938, Loss: 0.01591389626264572\n",
            "Epoch: 10/10, Step: 145/938, Loss: 7.220763654913753e-05\n",
            "Epoch: 10/10, Step: 146/938, Loss: 0.0075244964100420475\n",
            "Epoch: 10/10, Step: 147/938, Loss: 2.0703195332316682e-05\n",
            "Epoch: 10/10, Step: 148/938, Loss: 0.0006525205099023879\n",
            "Epoch: 10/10, Step: 149/938, Loss: 0.0002675289870239794\n",
            "Epoch: 10/10, Step: 150/938, Loss: 3.8420039345510304e-05\n",
            "Epoch: 10/10, Step: 151/938, Loss: 0.01368747465312481\n",
            "Epoch: 10/10, Step: 152/938, Loss: 0.001181463012471795\n",
            "Epoch: 10/10, Step: 153/938, Loss: 5.5901989981066436e-05\n",
            "Epoch: 10/10, Step: 154/938, Loss: 1.9675164367072284e-05\n",
            "Epoch: 10/10, Step: 155/938, Loss: 0.0005898428498767316\n",
            "Epoch: 10/10, Step: 156/938, Loss: 1.9209646779927425e-05\n",
            "Epoch: 10/10, Step: 157/938, Loss: 3.750713949557394e-05\n",
            "Epoch: 10/10, Step: 158/938, Loss: 0.013929912820458412\n",
            "Epoch: 10/10, Step: 159/938, Loss: 0.00013821561879012734\n",
            "Epoch: 10/10, Step: 160/938, Loss: 0.0006000249995850027\n",
            "Epoch: 10/10, Step: 161/938, Loss: 0.0010559277143329382\n",
            "Epoch: 10/10, Step: 162/938, Loss: 0.00012174285802757367\n",
            "Epoch: 10/10, Step: 163/938, Loss: 0.00010622946865623817\n",
            "Epoch: 10/10, Step: 164/938, Loss: 0.000836983323097229\n",
            "Epoch: 10/10, Step: 165/938, Loss: 0.0008930792682804167\n",
            "Epoch: 10/10, Step: 166/938, Loss: 0.00019834868726320565\n",
            "Epoch: 10/10, Step: 167/938, Loss: 5.4500880651175976e-05\n",
            "Epoch: 10/10, Step: 168/938, Loss: 9.178480104310438e-05\n",
            "Epoch: 10/10, Step: 169/938, Loss: 1.034423621604219e-05\n",
            "Epoch: 10/10, Step: 170/938, Loss: 5.402939223131398e-06\n",
            "Epoch: 10/10, Step: 171/938, Loss: 7.217338861664757e-05\n",
            "Epoch: 10/10, Step: 172/938, Loss: 1.299431187362643e-05\n",
            "Epoch: 10/10, Step: 173/938, Loss: 0.001835849485360086\n",
            "Epoch: 10/10, Step: 174/938, Loss: 1.4479016499535646e-05\n",
            "Epoch: 10/10, Step: 175/938, Loss: 0.007756989914923906\n",
            "Epoch: 10/10, Step: 176/938, Loss: 2.1401046979008242e-05\n",
            "Epoch: 10/10, Step: 177/938, Loss: 0.00011101635755039752\n",
            "Epoch: 10/10, Step: 178/938, Loss: 0.0004814354469999671\n",
            "Epoch: 10/10, Step: 179/938, Loss: 0.018239742144942284\n",
            "Epoch: 10/10, Step: 180/938, Loss: 0.00011339531192788854\n",
            "Epoch: 10/10, Step: 181/938, Loss: 1.6163961845450103e-05\n",
            "Epoch: 10/10, Step: 182/938, Loss: 0.038691770285367966\n",
            "Epoch: 10/10, Step: 183/938, Loss: 0.010868903249502182\n",
            "Epoch: 10/10, Step: 184/938, Loss: 0.0006716796196997166\n",
            "Epoch: 10/10, Step: 185/938, Loss: 2.068021240120288e-05\n",
            "Epoch: 10/10, Step: 186/938, Loss: 0.0008050639880821109\n",
            "Epoch: 10/10, Step: 187/938, Loss: 1.103662907553371e-05\n",
            "Epoch: 10/10, Step: 188/938, Loss: 9.850741480477154e-05\n",
            "Epoch: 10/10, Step: 189/938, Loss: 0.0018176436424255371\n",
            "Epoch: 10/10, Step: 190/938, Loss: 0.00042128225322812796\n",
            "Epoch: 10/10, Step: 191/938, Loss: 4.4794214772991836e-05\n",
            "Epoch: 10/10, Step: 192/938, Loss: 0.0008493143832311034\n",
            "Epoch: 10/10, Step: 193/938, Loss: 0.002183803590014577\n",
            "Epoch: 10/10, Step: 194/938, Loss: 0.00014747068053111434\n",
            "Epoch: 10/10, Step: 195/938, Loss: 5.515664452104829e-05\n",
            "Epoch: 10/10, Step: 196/938, Loss: 0.0005011138855479658\n",
            "Epoch: 10/10, Step: 197/938, Loss: 8.235494897235185e-05\n",
            "Epoch: 10/10, Step: 198/938, Loss: 0.0957733690738678\n",
            "Epoch: 10/10, Step: 199/938, Loss: 0.00038082533865235746\n",
            "Epoch: 10/10, Step: 200/938, Loss: 0.00010324883623979986\n",
            "Epoch: 10/10, Step: 201/938, Loss: 0.0008203212637454271\n",
            "Epoch: 10/10, Step: 202/938, Loss: 0.0011180253932252526\n",
            "Epoch: 10/10, Step: 203/938, Loss: 0.00031032355036586523\n",
            "Epoch: 10/10, Step: 204/938, Loss: 0.00036916998215019703\n",
            "Epoch: 10/10, Step: 205/938, Loss: 0.00022894176072441041\n",
            "Epoch: 10/10, Step: 206/938, Loss: 7.654966611880809e-05\n",
            "Epoch: 10/10, Step: 207/938, Loss: 2.9072840334265493e-05\n",
            "Epoch: 10/10, Step: 208/938, Loss: 0.030745334923267365\n",
            "Epoch: 10/10, Step: 209/938, Loss: 8.854259795043617e-05\n",
            "Epoch: 10/10, Step: 210/938, Loss: 0.0005621510208584368\n",
            "Epoch: 10/10, Step: 211/938, Loss: 0.00343268271535635\n",
            "Epoch: 10/10, Step: 212/938, Loss: 0.03963718190789223\n",
            "Epoch: 10/10, Step: 213/938, Loss: 0.01324286125600338\n",
            "Epoch: 10/10, Step: 214/938, Loss: 0.00019742303993552923\n",
            "Epoch: 10/10, Step: 215/938, Loss: 0.00035197153920307755\n",
            "Epoch: 10/10, Step: 216/938, Loss: 0.00028867507353425026\n",
            "Epoch: 10/10, Step: 217/938, Loss: 0.0028023491613566875\n",
            "Epoch: 10/10, Step: 218/938, Loss: 0.01413952186703682\n",
            "Epoch: 10/10, Step: 219/938, Loss: 0.0003960291505791247\n",
            "Epoch: 10/10, Step: 220/938, Loss: 0.04803133010864258\n",
            "Epoch: 10/10, Step: 221/938, Loss: 0.03166995197534561\n",
            "Epoch: 10/10, Step: 222/938, Loss: 0.0016422533662989736\n",
            "Epoch: 10/10, Step: 223/938, Loss: 2.719907570281066e-05\n",
            "Epoch: 10/10, Step: 224/938, Loss: 0.002839979249984026\n",
            "Epoch: 10/10, Step: 225/938, Loss: 0.014229238033294678\n",
            "Epoch: 10/10, Step: 226/938, Loss: 0.0007507099071517587\n",
            "Epoch: 10/10, Step: 227/938, Loss: 1.1744469702534843e-05\n",
            "Epoch: 10/10, Step: 228/938, Loss: 0.00011252041440457106\n",
            "Epoch: 10/10, Step: 229/938, Loss: 3.368769830558449e-05\n",
            "Epoch: 10/10, Step: 230/938, Loss: 0.0004759822622872889\n",
            "Epoch: 10/10, Step: 231/938, Loss: 6.758368544979021e-05\n",
            "Epoch: 10/10, Step: 232/938, Loss: 0.022864138707518578\n",
            "Epoch: 10/10, Step: 233/938, Loss: 3.304238134660409e-06\n",
            "Epoch: 10/10, Step: 234/938, Loss: 0.00041761365719139576\n",
            "Epoch: 10/10, Step: 235/938, Loss: 0.00010064301022794098\n",
            "Epoch: 10/10, Step: 236/938, Loss: 0.0018542201723903418\n",
            "Epoch: 10/10, Step: 237/938, Loss: 0.03947867453098297\n",
            "Epoch: 10/10, Step: 238/938, Loss: 4.5870365283917636e-05\n",
            "Epoch: 10/10, Step: 239/938, Loss: 0.01076070312410593\n",
            "Epoch: 10/10, Step: 240/938, Loss: 0.007217375561594963\n",
            "Epoch: 10/10, Step: 241/938, Loss: 0.00031791182118467987\n",
            "Epoch: 10/10, Step: 242/938, Loss: 0.00016135261103045195\n",
            "Epoch: 10/10, Step: 243/938, Loss: 0.004992395639419556\n",
            "Epoch: 10/10, Step: 244/938, Loss: 0.002464323304593563\n",
            "Epoch: 10/10, Step: 245/938, Loss: 7.450618431903422e-05\n",
            "Epoch: 10/10, Step: 246/938, Loss: 0.0030310768634080887\n",
            "Epoch: 10/10, Step: 247/938, Loss: 0.006338680628687143\n",
            "Epoch: 10/10, Step: 248/938, Loss: 0.037020858377218246\n",
            "Epoch: 10/10, Step: 249/938, Loss: 0.055669356137514114\n",
            "Epoch: 10/10, Step: 250/938, Loss: 0.021617013961076736\n",
            "Epoch: 10/10, Step: 251/938, Loss: 0.00014844760880805552\n",
            "Epoch: 10/10, Step: 252/938, Loss: 0.00961560383439064\n",
            "Epoch: 10/10, Step: 253/938, Loss: 0.0004659650439862162\n",
            "Epoch: 10/10, Step: 254/938, Loss: 0.06913887709379196\n",
            "Epoch: 10/10, Step: 255/938, Loss: 0.006313529331237078\n",
            "Epoch: 10/10, Step: 256/938, Loss: 0.003337377915158868\n",
            "Epoch: 10/10, Step: 257/938, Loss: 0.0002685478830244392\n",
            "Epoch: 10/10, Step: 258/938, Loss: 6.303636473603547e-05\n",
            "Epoch: 10/10, Step: 259/938, Loss: 7.396834553219378e-05\n",
            "Epoch: 10/10, Step: 260/938, Loss: 0.0005467984592542052\n",
            "Epoch: 10/10, Step: 261/938, Loss: 7.452063437085599e-05\n",
            "Epoch: 10/10, Step: 262/938, Loss: 3.03645538224373e-05\n",
            "Epoch: 10/10, Step: 263/938, Loss: 6.236517947399989e-05\n",
            "Epoch: 10/10, Step: 264/938, Loss: 0.0002487498277332634\n",
            "Epoch: 10/10, Step: 265/938, Loss: 0.06143730506300926\n",
            "Epoch: 10/10, Step: 266/938, Loss: 6.792150816181675e-05\n",
            "Epoch: 10/10, Step: 267/938, Loss: 0.0022672659251838923\n",
            "Epoch: 10/10, Step: 268/938, Loss: 0.004918141756206751\n",
            "Epoch: 10/10, Step: 269/938, Loss: 0.0010717283003032207\n",
            "Epoch: 10/10, Step: 270/938, Loss: 0.00033184103085659444\n",
            "Epoch: 10/10, Step: 271/938, Loss: 3.7337635149015114e-05\n",
            "Epoch: 10/10, Step: 272/938, Loss: 6.640551146119833e-05\n",
            "Epoch: 10/10, Step: 273/938, Loss: 0.0003541470505297184\n",
            "Epoch: 10/10, Step: 274/938, Loss: 5.053263885201886e-05\n",
            "Epoch: 10/10, Step: 275/938, Loss: 0.0010675318771973252\n",
            "Epoch: 10/10, Step: 276/938, Loss: 0.00021559286687988788\n",
            "Epoch: 10/10, Step: 277/938, Loss: 0.0007979265064932406\n",
            "Epoch: 10/10, Step: 278/938, Loss: 0.0003362910938449204\n",
            "Epoch: 10/10, Step: 279/938, Loss: 8.36439139675349e-05\n",
            "Epoch: 10/10, Step: 280/938, Loss: 7.087021367624402e-05\n",
            "Epoch: 10/10, Step: 281/938, Loss: 0.00011598345008678734\n",
            "Epoch: 10/10, Step: 282/938, Loss: 3.602942524594255e-05\n",
            "Epoch: 10/10, Step: 283/938, Loss: 4.976855052518658e-06\n",
            "Epoch: 10/10, Step: 284/938, Loss: 0.005917317699640989\n",
            "Epoch: 10/10, Step: 285/938, Loss: 0.0095668975263834\n",
            "Epoch: 10/10, Step: 286/938, Loss: 0.0001377362641505897\n",
            "Epoch: 10/10, Step: 287/938, Loss: 0.007735279388725758\n",
            "Epoch: 10/10, Step: 288/938, Loss: 0.00017349659174215049\n",
            "Epoch: 10/10, Step: 289/938, Loss: 0.02430652640759945\n",
            "Epoch: 10/10, Step: 290/938, Loss: 0.00021347845904529095\n",
            "Epoch: 10/10, Step: 291/938, Loss: 4.291912046028301e-05\n",
            "Epoch: 10/10, Step: 292/938, Loss: 0.010683298110961914\n",
            "Epoch: 10/10, Step: 293/938, Loss: 0.00023073544434737414\n",
            "Epoch: 10/10, Step: 294/938, Loss: 0.008784926496446133\n",
            "Epoch: 10/10, Step: 295/938, Loss: 0.000623556727077812\n",
            "Epoch: 10/10, Step: 296/938, Loss: 2.259928260173183e-05\n",
            "Epoch: 10/10, Step: 297/938, Loss: 0.0007657075766474009\n",
            "Epoch: 10/10, Step: 298/938, Loss: 0.003484435146674514\n",
            "Epoch: 10/10, Step: 299/938, Loss: 0.007939979434013367\n",
            "Epoch: 10/10, Step: 300/938, Loss: 0.00021618975733872503\n",
            "Epoch: 10/10, Step: 301/938, Loss: 0.0021421583369374275\n",
            "Epoch: 10/10, Step: 302/938, Loss: 0.0005504879518412054\n",
            "Epoch: 10/10, Step: 303/938, Loss: 0.011069422587752342\n",
            "Epoch: 10/10, Step: 304/938, Loss: 0.00016831512039061636\n",
            "Epoch: 10/10, Step: 305/938, Loss: 0.013731119222939014\n",
            "Epoch: 10/10, Step: 306/938, Loss: 0.0005091649945825338\n",
            "Epoch: 10/10, Step: 307/938, Loss: 0.0002552315127104521\n",
            "Epoch: 10/10, Step: 308/938, Loss: 0.038994111120700836\n",
            "Epoch: 10/10, Step: 309/938, Loss: 0.0002758129849098623\n",
            "Epoch: 10/10, Step: 310/938, Loss: 1.027361213346012e-05\n",
            "Epoch: 10/10, Step: 311/938, Loss: 5.377098204917274e-06\n",
            "Epoch: 10/10, Step: 312/938, Loss: 0.0015529829543083906\n",
            "Epoch: 10/10, Step: 313/938, Loss: 0.0006995014846324921\n",
            "Epoch: 10/10, Step: 314/938, Loss: 0.00023592989600729197\n",
            "Epoch: 10/10, Step: 315/938, Loss: 5.661108298227191e-05\n",
            "Epoch: 10/10, Step: 316/938, Loss: 2.1512794319278328e-06\n",
            "Epoch: 10/10, Step: 317/938, Loss: 0.013433380983769894\n",
            "Epoch: 10/10, Step: 318/938, Loss: 0.00010906176612479612\n",
            "Epoch: 10/10, Step: 319/938, Loss: 0.00025838223518803716\n",
            "Epoch: 10/10, Step: 320/938, Loss: 0.004727014806121588\n",
            "Epoch: 10/10, Step: 321/938, Loss: 0.0015154143329709768\n",
            "Epoch: 10/10, Step: 322/938, Loss: 0.020684847608208656\n",
            "Epoch: 10/10, Step: 323/938, Loss: 2.4144294002326205e-05\n",
            "Epoch: 10/10, Step: 324/938, Loss: 0.00782256480306387\n",
            "Epoch: 10/10, Step: 325/938, Loss: 0.003134980332106352\n",
            "Epoch: 10/10, Step: 326/938, Loss: 0.0015574082499369979\n",
            "Epoch: 10/10, Step: 327/938, Loss: 0.0479932464659214\n",
            "Epoch: 10/10, Step: 328/938, Loss: 1.1405580153223127e-05\n",
            "Epoch: 10/10, Step: 329/938, Loss: 0.00015431655629072338\n",
            "Epoch: 10/10, Step: 330/938, Loss: 0.008471359498798847\n",
            "Epoch: 10/10, Step: 331/938, Loss: 2.217226938228123e-05\n",
            "Epoch: 10/10, Step: 332/938, Loss: 0.0742751881480217\n",
            "Epoch: 10/10, Step: 333/938, Loss: 0.0001263488520635292\n",
            "Epoch: 10/10, Step: 334/938, Loss: 0.002975278301164508\n",
            "Epoch: 10/10, Step: 335/938, Loss: 0.00022146383707877249\n",
            "Epoch: 10/10, Step: 336/938, Loss: 0.004212656058371067\n",
            "Epoch: 10/10, Step: 337/938, Loss: 0.00035350260441191494\n",
            "Epoch: 10/10, Step: 338/938, Loss: 0.0002991149667650461\n",
            "Epoch: 10/10, Step: 339/938, Loss: 0.008497667498886585\n",
            "Epoch: 10/10, Step: 340/938, Loss: 5.2114937716396526e-06\n",
            "Epoch: 10/10, Step: 341/938, Loss: 9.462878369959071e-05\n",
            "Epoch: 10/10, Step: 342/938, Loss: 0.0003996040904894471\n",
            "Epoch: 10/10, Step: 343/938, Loss: 0.0059988838620483875\n",
            "Epoch: 10/10, Step: 344/938, Loss: 0.002346913330256939\n",
            "Epoch: 10/10, Step: 345/938, Loss: 5.7711418776307255e-05\n",
            "Epoch: 10/10, Step: 346/938, Loss: 0.00876196101307869\n",
            "Epoch: 10/10, Step: 347/938, Loss: 0.00020237777789589018\n",
            "Epoch: 10/10, Step: 348/938, Loss: 0.000470293452963233\n",
            "Epoch: 10/10, Step: 349/938, Loss: 0.0010770773515105247\n",
            "Epoch: 10/10, Step: 350/938, Loss: 0.000478290137834847\n",
            "Epoch: 10/10, Step: 351/938, Loss: 8.826069461065345e-06\n",
            "Epoch: 10/10, Step: 352/938, Loss: 0.0033030379563570023\n",
            "Epoch: 10/10, Step: 353/938, Loss: 5.367922494770028e-05\n",
            "Epoch: 10/10, Step: 354/938, Loss: 0.002007527509704232\n",
            "Epoch: 10/10, Step: 355/938, Loss: 0.0009740259265527129\n",
            "Epoch: 10/10, Step: 356/938, Loss: 0.0013545716647058725\n",
            "Epoch: 10/10, Step: 357/938, Loss: 0.00498005049303174\n",
            "Epoch: 10/10, Step: 358/938, Loss: 0.00010124166874447837\n",
            "Epoch: 10/10, Step: 359/938, Loss: 0.0011730859987437725\n",
            "Epoch: 10/10, Step: 360/938, Loss: 0.00029856141190975904\n",
            "Epoch: 10/10, Step: 361/938, Loss: 0.0003914836561307311\n",
            "Epoch: 10/10, Step: 362/938, Loss: 0.00015880288265179843\n",
            "Epoch: 10/10, Step: 363/938, Loss: 1.033761577673431e-06\n",
            "Epoch: 10/10, Step: 364/938, Loss: 0.010289805009961128\n",
            "Epoch: 10/10, Step: 365/938, Loss: 6.33129384368658e-05\n",
            "Epoch: 10/10, Step: 366/938, Loss: 9.273387149733026e-06\n",
            "Epoch: 10/10, Step: 367/938, Loss: 0.0031601148657500744\n",
            "Epoch: 10/10, Step: 368/938, Loss: 0.001552095403894782\n",
            "Epoch: 10/10, Step: 369/938, Loss: 5.087499812361784e-05\n",
            "Epoch: 10/10, Step: 370/938, Loss: 0.00015503744361922145\n",
            "Epoch: 10/10, Step: 371/938, Loss: 0.0005221893079578876\n",
            "Epoch: 10/10, Step: 372/938, Loss: 9.654501627665013e-05\n",
            "Epoch: 10/10, Step: 373/938, Loss: 0.000990428146906197\n",
            "Epoch: 10/10, Step: 374/938, Loss: 0.0028057899326086044\n",
            "Epoch: 10/10, Step: 375/938, Loss: 4.759634248330258e-05\n",
            "Epoch: 10/10, Step: 376/938, Loss: 0.00022183189867064357\n",
            "Epoch: 10/10, Step: 377/938, Loss: 0.0005310695269145072\n",
            "Epoch: 10/10, Step: 378/938, Loss: 5.786550445918692e-06\n",
            "Epoch: 10/10, Step: 379/938, Loss: 1.595836329215672e-05\n",
            "Epoch: 10/10, Step: 380/938, Loss: 0.024749180302023888\n",
            "Epoch: 10/10, Step: 381/938, Loss: 5.189041075936984e-06\n",
            "Epoch: 10/10, Step: 382/938, Loss: 0.000523919821716845\n",
            "Epoch: 10/10, Step: 383/938, Loss: 3.1733623472973704e-05\n",
            "Epoch: 10/10, Step: 384/938, Loss: 0.0004015748272649944\n",
            "Epoch: 10/10, Step: 385/938, Loss: 0.0006298045045696199\n",
            "Epoch: 10/10, Step: 386/938, Loss: 0.00013478808978106827\n",
            "Epoch: 10/10, Step: 387/938, Loss: 3.8768150261603296e-05\n",
            "Epoch: 10/10, Step: 388/938, Loss: 0.0006426517502404749\n",
            "Epoch: 10/10, Step: 389/938, Loss: 0.0009705147240310907\n",
            "Epoch: 10/10, Step: 390/938, Loss: 0.0113579286262393\n",
            "Epoch: 10/10, Step: 391/938, Loss: 4.533890387392603e-05\n",
            "Epoch: 10/10, Step: 392/938, Loss: 0.0031655915081501007\n",
            "Epoch: 10/10, Step: 393/938, Loss: 6.296222272794694e-05\n",
            "Epoch: 10/10, Step: 394/938, Loss: 1.9346098270034418e-05\n",
            "Epoch: 10/10, Step: 395/938, Loss: 0.00034990679705515504\n",
            "Epoch: 10/10, Step: 396/938, Loss: 0.012891936115920544\n",
            "Epoch: 10/10, Step: 397/938, Loss: 0.0008597389096394181\n",
            "Epoch: 10/10, Step: 398/938, Loss: 0.0014618438435718417\n",
            "Epoch: 10/10, Step: 399/938, Loss: 0.00019308982882648706\n",
            "Epoch: 10/10, Step: 400/938, Loss: 0.10693808645009995\n",
            "Epoch: 10/10, Step: 401/938, Loss: 0.002046038396656513\n",
            "Epoch: 10/10, Step: 402/938, Loss: 0.00969679281115532\n",
            "Epoch: 10/10, Step: 403/938, Loss: 5.269148005027091e-06\n",
            "Epoch: 10/10, Step: 404/938, Loss: 0.00026122244889847934\n",
            "Epoch: 10/10, Step: 405/938, Loss: 0.00018040470604319125\n",
            "Epoch: 10/10, Step: 406/938, Loss: 0.01283243391662836\n",
            "Epoch: 10/10, Step: 407/938, Loss: 0.00015140019240789115\n",
            "Epoch: 10/10, Step: 408/938, Loss: 7.702237780904397e-05\n",
            "Epoch: 10/10, Step: 409/938, Loss: 4.6254343033069745e-05\n",
            "Epoch: 10/10, Step: 410/938, Loss: 0.0008871194440871477\n",
            "Epoch: 10/10, Step: 411/938, Loss: 0.004976474680006504\n",
            "Epoch: 10/10, Step: 412/938, Loss: 0.00030747728305868804\n",
            "Epoch: 10/10, Step: 413/938, Loss: 0.0034919690806418657\n",
            "Epoch: 10/10, Step: 414/938, Loss: 0.0003853971138596535\n",
            "Epoch: 10/10, Step: 415/938, Loss: 0.0011951178312301636\n",
            "Epoch: 10/10, Step: 416/938, Loss: 0.049774378538131714\n",
            "Epoch: 10/10, Step: 417/938, Loss: 0.00041257383418269455\n",
            "Epoch: 10/10, Step: 418/938, Loss: 6.909260991960764e-05\n",
            "Epoch: 10/10, Step: 419/938, Loss: 0.00028878921875730157\n",
            "Epoch: 10/10, Step: 420/938, Loss: 0.004475662484765053\n",
            "Epoch: 10/10, Step: 421/938, Loss: 0.003145757131278515\n",
            "Epoch: 10/10, Step: 422/938, Loss: 6.368868343997747e-05\n",
            "Epoch: 10/10, Step: 423/938, Loss: 1.9106444597127847e-05\n",
            "Epoch: 10/10, Step: 424/938, Loss: 4.114923649467528e-05\n",
            "Epoch: 10/10, Step: 425/938, Loss: 0.006313467863947153\n",
            "Epoch: 10/10, Step: 426/938, Loss: 0.0003459191066212952\n",
            "Epoch: 10/10, Step: 427/938, Loss: 0.0004504566895775497\n",
            "Epoch: 10/10, Step: 428/938, Loss: 0.0035630445927381516\n",
            "Epoch: 10/10, Step: 429/938, Loss: 0.001673010177910328\n",
            "Epoch: 10/10, Step: 430/938, Loss: 0.0002960527781397104\n",
            "Epoch: 10/10, Step: 431/938, Loss: 2.7399868486099876e-05\n",
            "Epoch: 10/10, Step: 432/938, Loss: 0.0005851892638020217\n",
            "Epoch: 10/10, Step: 433/938, Loss: 0.00043492624536156654\n",
            "Epoch: 10/10, Step: 434/938, Loss: 0.0005643187323585153\n",
            "Epoch: 10/10, Step: 435/938, Loss: 0.02803782746195793\n",
            "Epoch: 10/10, Step: 436/938, Loss: 0.018823185935616493\n",
            "Epoch: 10/10, Step: 437/938, Loss: 8.541592251276597e-06\n",
            "Epoch: 10/10, Step: 438/938, Loss: 1.3449799553200137e-05\n",
            "Epoch: 10/10, Step: 439/938, Loss: 0.0004831532423850149\n",
            "Epoch: 10/10, Step: 440/938, Loss: 0.0003420553985051811\n",
            "Epoch: 10/10, Step: 441/938, Loss: 0.00015932430687826127\n",
            "Epoch: 10/10, Step: 442/938, Loss: 0.0012335414066910744\n",
            "Epoch: 10/10, Step: 443/938, Loss: 0.00015510090452153236\n",
            "Epoch: 10/10, Step: 444/938, Loss: 0.0001870822161436081\n",
            "Epoch: 10/10, Step: 445/938, Loss: 0.002948127454146743\n",
            "Epoch: 10/10, Step: 446/938, Loss: 0.00018388235184829682\n",
            "Epoch: 10/10, Step: 447/938, Loss: 0.0005301748751662672\n",
            "Epoch: 10/10, Step: 448/938, Loss: 0.003895004978403449\n",
            "Epoch: 10/10, Step: 449/938, Loss: 0.007716075051575899\n",
            "Epoch: 10/10, Step: 450/938, Loss: 0.0003154917503707111\n",
            "Epoch: 10/10, Step: 451/938, Loss: 3.787108289543539e-05\n",
            "Epoch: 10/10, Step: 452/938, Loss: 0.016601061448454857\n",
            "Epoch: 10/10, Step: 453/938, Loss: 0.002902036067098379\n",
            "Epoch: 10/10, Step: 454/938, Loss: 7.199145329650491e-05\n",
            "Epoch: 10/10, Step: 455/938, Loss: 0.03976176679134369\n",
            "Epoch: 10/10, Step: 456/938, Loss: 0.0005872524343430996\n",
            "Epoch: 10/10, Step: 457/938, Loss: 0.000712392560672015\n",
            "Epoch: 10/10, Step: 458/938, Loss: 0.004752887412905693\n",
            "Epoch: 10/10, Step: 459/938, Loss: 0.002287450945004821\n",
            "Epoch: 10/10, Step: 460/938, Loss: 0.00041101782699115574\n",
            "Epoch: 10/10, Step: 461/938, Loss: 0.0015069589717313647\n",
            "Epoch: 10/10, Step: 462/938, Loss: 7.018860924290493e-05\n",
            "Epoch: 10/10, Step: 463/938, Loss: 0.000290206226054579\n",
            "Epoch: 10/10, Step: 464/938, Loss: 0.0021404053550213575\n",
            "Epoch: 10/10, Step: 465/938, Loss: 3.2763291528681293e-06\n",
            "Epoch: 10/10, Step: 466/938, Loss: 0.001286528306081891\n",
            "Epoch: 10/10, Step: 467/938, Loss: 0.03552895411849022\n",
            "Epoch: 10/10, Step: 468/938, Loss: 0.016598118469119072\n",
            "Epoch: 10/10, Step: 469/938, Loss: 3.8876565668033436e-05\n",
            "Epoch: 10/10, Step: 470/938, Loss: 0.01902630552649498\n",
            "Epoch: 10/10, Step: 471/938, Loss: 0.002666778862476349\n",
            "Epoch: 10/10, Step: 472/938, Loss: 0.0021487432532012463\n",
            "Epoch: 10/10, Step: 473/938, Loss: 1.1362428267602809e-05\n",
            "Epoch: 10/10, Step: 474/938, Loss: 0.0003051201638299972\n",
            "Epoch: 10/10, Step: 475/938, Loss: 1.97624331121915e-06\n",
            "Epoch: 10/10, Step: 476/938, Loss: 0.00018786847067531198\n",
            "Epoch: 10/10, Step: 477/938, Loss: 1.0229922736471053e-05\n",
            "Epoch: 10/10, Step: 478/938, Loss: 0.004300559405237436\n",
            "Epoch: 10/10, Step: 479/938, Loss: 0.0006667576963081956\n",
            "Epoch: 10/10, Step: 480/938, Loss: 0.0028944690711796284\n",
            "Epoch: 10/10, Step: 481/938, Loss: 0.00011085646110586822\n",
            "Epoch: 10/10, Step: 482/938, Loss: 6.84502738295123e-05\n",
            "Epoch: 10/10, Step: 483/938, Loss: 0.008181882090866566\n",
            "Epoch: 10/10, Step: 484/938, Loss: 0.0005227887304499745\n",
            "Epoch: 10/10, Step: 485/938, Loss: 0.00025703205028548837\n",
            "Epoch: 10/10, Step: 486/938, Loss: 7.458044274244457e-05\n",
            "Epoch: 10/10, Step: 487/938, Loss: 0.00014668446965515614\n",
            "Epoch: 10/10, Step: 488/938, Loss: 0.0009276990313082933\n",
            "Epoch: 10/10, Step: 489/938, Loss: 0.0004735635593533516\n",
            "Epoch: 10/10, Step: 490/938, Loss: 0.005535080563277006\n",
            "Epoch: 10/10, Step: 491/938, Loss: 0.0011574717937037349\n",
            "Epoch: 10/10, Step: 492/938, Loss: 0.000727201986592263\n",
            "Epoch: 10/10, Step: 493/938, Loss: 0.0017421371303498745\n",
            "Epoch: 10/10, Step: 494/938, Loss: 2.2641555915470235e-05\n",
            "Epoch: 10/10, Step: 495/938, Loss: 0.0002378342323936522\n",
            "Epoch: 10/10, Step: 496/938, Loss: 0.0016136853955686092\n",
            "Epoch: 10/10, Step: 497/938, Loss: 0.016899755224585533\n",
            "Epoch: 10/10, Step: 498/938, Loss: 5.8847763284575194e-05\n",
            "Epoch: 10/10, Step: 499/938, Loss: 0.00021704533719457686\n",
            "Epoch: 10/10, Step: 500/938, Loss: 0.0016139447689056396\n",
            "Epoch: 10/10, Step: 501/938, Loss: 0.025120310485363007\n",
            "Epoch: 10/10, Step: 502/938, Loss: 8.132112998282537e-05\n",
            "Epoch: 10/10, Step: 503/938, Loss: 0.03749936446547508\n",
            "Epoch: 10/10, Step: 504/938, Loss: 0.0176611989736557\n",
            "Epoch: 10/10, Step: 505/938, Loss: 3.18100574077107e-05\n",
            "Epoch: 10/10, Step: 506/938, Loss: 0.013822364620864391\n",
            "Epoch: 10/10, Step: 507/938, Loss: 4.942892337567173e-05\n",
            "Epoch: 10/10, Step: 508/938, Loss: 0.00010342278983443975\n",
            "Epoch: 10/10, Step: 509/938, Loss: 0.0007054444286040962\n",
            "Epoch: 10/10, Step: 510/938, Loss: 6.067900176276453e-05\n",
            "Epoch: 10/10, Step: 511/938, Loss: 0.0004726298793684691\n",
            "Epoch: 10/10, Step: 512/938, Loss: 0.005128262098878622\n",
            "Epoch: 10/10, Step: 513/938, Loss: 0.010335329920053482\n",
            "Epoch: 10/10, Step: 514/938, Loss: 0.00024575775023549795\n",
            "Epoch: 10/10, Step: 515/938, Loss: 0.0005867996369488537\n",
            "Epoch: 10/10, Step: 516/938, Loss: 0.0008423157269135118\n",
            "Epoch: 10/10, Step: 517/938, Loss: 0.014304609969258308\n",
            "Epoch: 10/10, Step: 518/938, Loss: 3.683213799376972e-05\n",
            "Epoch: 10/10, Step: 519/938, Loss: 7.647899474250153e-05\n",
            "Epoch: 10/10, Step: 520/938, Loss: 0.0006651137373410165\n",
            "Epoch: 10/10, Step: 521/938, Loss: 2.1495583496289328e-05\n",
            "Epoch: 10/10, Step: 522/938, Loss: 0.004733564332127571\n",
            "Epoch: 10/10, Step: 523/938, Loss: 0.0037284891586750746\n",
            "Epoch: 10/10, Step: 524/938, Loss: 0.00018767314031720161\n",
            "Epoch: 10/10, Step: 525/938, Loss: 0.00938086025416851\n",
            "Epoch: 10/10, Step: 526/938, Loss: 0.0008693401468917727\n",
            "Epoch: 10/10, Step: 527/938, Loss: 0.10258810967206955\n",
            "Epoch: 10/10, Step: 528/938, Loss: 0.00010900133202085271\n",
            "Epoch: 10/10, Step: 529/938, Loss: 0.0007985308766365051\n",
            "Epoch: 10/10, Step: 530/938, Loss: 0.0011932316701859236\n",
            "Epoch: 10/10, Step: 531/938, Loss: 4.249285120749846e-05\n",
            "Epoch: 10/10, Step: 532/938, Loss: 6.927044887561351e-05\n",
            "Epoch: 10/10, Step: 533/938, Loss: 0.004394399933516979\n",
            "Epoch: 10/10, Step: 534/938, Loss: 0.00033991551026701927\n",
            "Epoch: 10/10, Step: 535/938, Loss: 0.00046992526040412486\n",
            "Epoch: 10/10, Step: 536/938, Loss: 0.014465652406215668\n",
            "Epoch: 10/10, Step: 537/938, Loss: 0.010713819414377213\n",
            "Epoch: 10/10, Step: 538/938, Loss: 0.00012812369095627218\n",
            "Epoch: 10/10, Step: 539/938, Loss: 3.7703095586039126e-05\n",
            "Epoch: 10/10, Step: 540/938, Loss: 0.00015428478945977986\n",
            "Epoch: 10/10, Step: 541/938, Loss: 0.002733966801315546\n",
            "Epoch: 10/10, Step: 542/938, Loss: 0.04493767023086548\n",
            "Epoch: 10/10, Step: 543/938, Loss: 0.014488332904875278\n",
            "Epoch: 10/10, Step: 544/938, Loss: 1.7063444829545915e-05\n",
            "Epoch: 10/10, Step: 545/938, Loss: 0.0346696712076664\n",
            "Epoch: 10/10, Step: 546/938, Loss: 0.0025931086856871843\n",
            "Epoch: 10/10, Step: 547/938, Loss: 4.385799547890201e-05\n",
            "Epoch: 10/10, Step: 548/938, Loss: 7.014833681751043e-05\n",
            "Epoch: 10/10, Step: 549/938, Loss: 0.00040399827412329614\n",
            "Epoch: 10/10, Step: 550/938, Loss: 0.001443258486688137\n",
            "Epoch: 10/10, Step: 551/938, Loss: 0.003087277291342616\n",
            "Epoch: 10/10, Step: 552/938, Loss: 0.001849144697189331\n",
            "Epoch: 10/10, Step: 553/938, Loss: 0.008255907334387302\n",
            "Epoch: 10/10, Step: 554/938, Loss: 0.001268456457182765\n",
            "Epoch: 10/10, Step: 555/938, Loss: 0.037416260689496994\n",
            "Epoch: 10/10, Step: 556/938, Loss: 2.274352482345421e-05\n",
            "Epoch: 10/10, Step: 557/938, Loss: 0.000971046625636518\n",
            "Epoch: 10/10, Step: 558/938, Loss: 0.0006054443074390292\n",
            "Epoch: 10/10, Step: 559/938, Loss: 0.0051127648912370205\n",
            "Epoch: 10/10, Step: 560/938, Loss: 0.007844747975468636\n",
            "Epoch: 10/10, Step: 561/938, Loss: 3.9635328903386835e-06\n",
            "Epoch: 10/10, Step: 562/938, Loss: 0.0005846963031217456\n",
            "Epoch: 10/10, Step: 563/938, Loss: 0.0013861290644854307\n",
            "Epoch: 10/10, Step: 564/938, Loss: 0.0027459922712296247\n",
            "Epoch: 10/10, Step: 565/938, Loss: 0.0184671338647604\n",
            "Epoch: 10/10, Step: 566/938, Loss: 0.0004282727895770222\n",
            "Epoch: 10/10, Step: 567/938, Loss: 0.00046988503891043365\n",
            "Epoch: 10/10, Step: 568/938, Loss: 0.0002612225944176316\n",
            "Epoch: 10/10, Step: 569/938, Loss: 8.357235856237821e-06\n",
            "Epoch: 10/10, Step: 570/938, Loss: 5.625164476441569e-07\n",
            "Epoch: 10/10, Step: 571/938, Loss: 0.0035300403833389282\n",
            "Epoch: 10/10, Step: 572/938, Loss: 0.00022130059369374067\n",
            "Epoch: 10/10, Step: 573/938, Loss: 0.022785507142543793\n",
            "Epoch: 10/10, Step: 574/938, Loss: 0.011670769192278385\n",
            "Epoch: 10/10, Step: 575/938, Loss: 3.741404361790046e-05\n",
            "Epoch: 10/10, Step: 576/938, Loss: 0.00038999918615445495\n",
            "Epoch: 10/10, Step: 577/938, Loss: 0.0033115141559392214\n",
            "Epoch: 10/10, Step: 578/938, Loss: 1.714043173706159e-05\n",
            "Epoch: 10/10, Step: 579/938, Loss: 0.00040825875476002693\n",
            "Epoch: 10/10, Step: 580/938, Loss: 9.475565093453042e-06\n",
            "Epoch: 10/10, Step: 581/938, Loss: 0.00018906280456576496\n",
            "Epoch: 10/10, Step: 582/938, Loss: 0.004410651512444019\n",
            "Epoch: 10/10, Step: 583/938, Loss: 0.002213013358414173\n",
            "Epoch: 10/10, Step: 584/938, Loss: 0.0002823461254592985\n",
            "Epoch: 10/10, Step: 585/938, Loss: 0.0012088994262740016\n",
            "Epoch: 10/10, Step: 586/938, Loss: 0.018465649336576462\n",
            "Epoch: 10/10, Step: 587/938, Loss: 0.00447149109095335\n",
            "Epoch: 10/10, Step: 588/938, Loss: 0.0031899302266538143\n",
            "Epoch: 10/10, Step: 589/938, Loss: 0.00020619470160454512\n",
            "Epoch: 10/10, Step: 590/938, Loss: 4.602168337441981e-05\n",
            "Epoch: 10/10, Step: 591/938, Loss: 2.0413217498571612e-05\n",
            "Epoch: 10/10, Step: 592/938, Loss: 0.00017954771465156227\n",
            "Epoch: 10/10, Step: 593/938, Loss: 0.026365431025624275\n",
            "Epoch: 10/10, Step: 594/938, Loss: 0.0003552052949089557\n",
            "Epoch: 10/10, Step: 595/938, Loss: 0.0002986695908475667\n",
            "Epoch: 10/10, Step: 596/938, Loss: 0.00034291224437765777\n",
            "Epoch: 10/10, Step: 597/938, Loss: 2.0018853319925256e-05\n",
            "Epoch: 10/10, Step: 598/938, Loss: 0.0014536029193550348\n",
            "Epoch: 10/10, Step: 599/938, Loss: 0.00017756744637154043\n",
            "Epoch: 10/10, Step: 600/938, Loss: 1.1767794603656512e-05\n",
            "Epoch: 10/10, Step: 601/938, Loss: 1.3097322153043933e-05\n",
            "Epoch: 10/10, Step: 602/938, Loss: 4.041903594043106e-07\n",
            "Epoch: 10/10, Step: 603/938, Loss: 0.0007445037481375039\n",
            "Epoch: 10/10, Step: 604/938, Loss: 0.06505545973777771\n",
            "Epoch: 10/10, Step: 605/938, Loss: 2.0746390873682685e-05\n",
            "Epoch: 10/10, Step: 606/938, Loss: 0.001239155768416822\n",
            "Epoch: 10/10, Step: 607/938, Loss: 0.0002530079218558967\n",
            "Epoch: 10/10, Step: 608/938, Loss: 0.0033039681147783995\n",
            "Epoch: 10/10, Step: 609/938, Loss: 0.0001587950246175751\n",
            "Epoch: 10/10, Step: 610/938, Loss: 0.0004645132285077125\n",
            "Epoch: 10/10, Step: 611/938, Loss: 0.031377486884593964\n",
            "Epoch: 10/10, Step: 612/938, Loss: 0.006889027077704668\n",
            "Epoch: 10/10, Step: 613/938, Loss: 2.3206297555589117e-05\n",
            "Epoch: 10/10, Step: 614/938, Loss: 2.526331809349358e-05\n",
            "Epoch: 10/10, Step: 615/938, Loss: 0.0013275445671752095\n",
            "Epoch: 10/10, Step: 616/938, Loss: 0.0004988497239537537\n",
            "Epoch: 10/10, Step: 617/938, Loss: 0.00021594487770926207\n",
            "Epoch: 10/10, Step: 618/938, Loss: 4.842850103159435e-07\n",
            "Epoch: 10/10, Step: 619/938, Loss: 0.00015963941405061632\n",
            "Epoch: 10/10, Step: 620/938, Loss: 4.9027377826860175e-05\n",
            "Epoch: 10/10, Step: 621/938, Loss: 3.682357601064723e-06\n",
            "Epoch: 10/10, Step: 622/938, Loss: 2.5155592084047385e-05\n",
            "Epoch: 10/10, Step: 623/938, Loss: 5.539725680137053e-05\n",
            "Epoch: 10/10, Step: 624/938, Loss: 0.003286761697381735\n",
            "Epoch: 10/10, Step: 625/938, Loss: 0.0005564631428569555\n",
            "Epoch: 10/10, Step: 626/938, Loss: 0.00018623082723934203\n",
            "Epoch: 10/10, Step: 627/938, Loss: 0.0014570406638085842\n",
            "Epoch: 10/10, Step: 628/938, Loss: 0.0004545833508018404\n",
            "Epoch: 10/10, Step: 629/938, Loss: 1.4379369304151624e-06\n",
            "Epoch: 10/10, Step: 630/938, Loss: 0.00017529772594571114\n",
            "Epoch: 10/10, Step: 631/938, Loss: 0.0006517167785204947\n",
            "Epoch: 10/10, Step: 632/938, Loss: 0.0054458137601614\n",
            "Epoch: 10/10, Step: 633/938, Loss: 0.00016033381689339876\n",
            "Epoch: 10/10, Step: 634/938, Loss: 0.003945200238376856\n",
            "Epoch: 10/10, Step: 635/938, Loss: 0.09248830378055573\n",
            "Epoch: 10/10, Step: 636/938, Loss: 0.015298417769372463\n",
            "Epoch: 10/10, Step: 637/938, Loss: 0.01309540681540966\n",
            "Epoch: 10/10, Step: 638/938, Loss: 2.719100666581653e-05\n",
            "Epoch: 10/10, Step: 639/938, Loss: 0.019899940118193626\n",
            "Epoch: 10/10, Step: 640/938, Loss: 0.036695487797260284\n",
            "Epoch: 10/10, Step: 641/938, Loss: 1.287636496272171e-05\n",
            "Epoch: 10/10, Step: 642/938, Loss: 0.005666469689458609\n",
            "Epoch: 10/10, Step: 643/938, Loss: 0.00030179833993315697\n",
            "Epoch: 10/10, Step: 644/938, Loss: 5.3312651289161295e-05\n",
            "Epoch: 10/10, Step: 645/938, Loss: 0.000639026693534106\n",
            "Epoch: 10/10, Step: 646/938, Loss: 0.015057602897286415\n",
            "Epoch: 10/10, Step: 647/938, Loss: 7.817893492756411e-05\n",
            "Epoch: 10/10, Step: 648/938, Loss: 0.017234869301319122\n",
            "Epoch: 10/10, Step: 649/938, Loss: 3.207138797733933e-05\n",
            "Epoch: 10/10, Step: 650/938, Loss: 0.0007660351111553609\n",
            "Epoch: 10/10, Step: 651/938, Loss: 7.216897938633338e-05\n",
            "Epoch: 10/10, Step: 652/938, Loss: 0.0010564858093857765\n",
            "Epoch: 10/10, Step: 653/938, Loss: 0.0022955727763473988\n",
            "Epoch: 10/10, Step: 654/938, Loss: 0.0032711103558540344\n",
            "Epoch: 10/10, Step: 655/938, Loss: 0.0014889473095536232\n",
            "Epoch: 10/10, Step: 656/938, Loss: 0.0005252181435935199\n",
            "Epoch: 10/10, Step: 657/938, Loss: 9.831662464421242e-05\n",
            "Epoch: 10/10, Step: 658/938, Loss: 8.972337673185393e-05\n",
            "Epoch: 10/10, Step: 659/938, Loss: 0.0002458894159644842\n",
            "Epoch: 10/10, Step: 660/938, Loss: 4.261479261913337e-06\n",
            "Epoch: 10/10, Step: 661/938, Loss: 0.0013545234687626362\n",
            "Epoch: 10/10, Step: 662/938, Loss: 0.0011065008584409952\n",
            "Epoch: 10/10, Step: 663/938, Loss: 9.682655945653096e-05\n",
            "Epoch: 10/10, Step: 664/938, Loss: 6.38577839708887e-05\n",
            "Epoch: 10/10, Step: 665/938, Loss: 0.04727576673030853\n",
            "Epoch: 10/10, Step: 666/938, Loss: 0.01128693763166666\n",
            "Epoch: 10/10, Step: 667/938, Loss: 9.151455014944077e-05\n",
            "Epoch: 10/10, Step: 668/938, Loss: 0.0076925321482121944\n",
            "Epoch: 10/10, Step: 669/938, Loss: 0.03339936584234238\n",
            "Epoch: 10/10, Step: 670/938, Loss: 5.276266165310517e-06\n",
            "Epoch: 10/10, Step: 671/938, Loss: 0.11869616061449051\n",
            "Epoch: 10/10, Step: 672/938, Loss: 0.004248386714607477\n",
            "Epoch: 10/10, Step: 673/938, Loss: 0.0008780586649663746\n",
            "Epoch: 10/10, Step: 674/938, Loss: 0.010245082899928093\n",
            "Epoch: 10/10, Step: 675/938, Loss: 0.0010600603418424726\n",
            "Epoch: 10/10, Step: 676/938, Loss: 0.010899114422500134\n",
            "Epoch: 10/10, Step: 677/938, Loss: 0.00023431678710039705\n",
            "Epoch: 10/10, Step: 678/938, Loss: 0.0006089384551160038\n",
            "Epoch: 10/10, Step: 679/938, Loss: 0.00044056345359422266\n",
            "Epoch: 10/10, Step: 680/938, Loss: 9.152488928521052e-05\n",
            "Epoch: 10/10, Step: 681/938, Loss: 0.02534709870815277\n",
            "Epoch: 10/10, Step: 682/938, Loss: 0.05877678468823433\n",
            "Epoch: 10/10, Step: 683/938, Loss: 0.053186140954494476\n",
            "Epoch: 10/10, Step: 684/938, Loss: 0.0006189033738337457\n",
            "Epoch: 10/10, Step: 685/938, Loss: 0.00777985155582428\n",
            "Epoch: 10/10, Step: 686/938, Loss: 3.351879786350764e-05\n",
            "Epoch: 10/10, Step: 687/938, Loss: 6.003986709401943e-05\n",
            "Epoch: 10/10, Step: 688/938, Loss: 0.00027302297530695796\n",
            "Epoch: 10/10, Step: 689/938, Loss: 0.0013135700719431043\n",
            "Epoch: 10/10, Step: 690/938, Loss: 0.01513419859111309\n",
            "Epoch: 10/10, Step: 691/938, Loss: 0.009833388961851597\n",
            "Epoch: 10/10, Step: 692/938, Loss: 0.04697097837924957\n",
            "Epoch: 10/10, Step: 693/938, Loss: 0.0005969266640022397\n",
            "Epoch: 10/10, Step: 694/938, Loss: 0.11069648712873459\n",
            "Epoch: 10/10, Step: 695/938, Loss: 0.0012915655970573425\n",
            "Epoch: 10/10, Step: 696/938, Loss: 0.00037628671270795166\n",
            "Epoch: 10/10, Step: 697/938, Loss: 0.00021579537133220583\n",
            "Epoch: 10/10, Step: 698/938, Loss: 0.00014683493645861745\n",
            "Epoch: 10/10, Step: 699/938, Loss: 0.0008539764094166458\n",
            "Epoch: 10/10, Step: 700/938, Loss: 0.0059163253754377365\n",
            "Epoch: 10/10, Step: 701/938, Loss: 0.019186558201909065\n",
            "Epoch: 10/10, Step: 702/938, Loss: 7.52633495721966e-05\n",
            "Epoch: 10/10, Step: 703/938, Loss: 0.0006476931739598513\n",
            "Epoch: 10/10, Step: 704/938, Loss: 0.01976696401834488\n",
            "Epoch: 10/10, Step: 705/938, Loss: 0.0006067350041121244\n",
            "Epoch: 10/10, Step: 706/938, Loss: 0.008047351613640785\n",
            "Epoch: 10/10, Step: 707/938, Loss: 0.001812949776649475\n",
            "Epoch: 10/10, Step: 708/938, Loss: 0.004743447992950678\n",
            "Epoch: 10/10, Step: 709/938, Loss: 0.00849071890115738\n",
            "Epoch: 10/10, Step: 710/938, Loss: 0.0017980304546654224\n",
            "Epoch: 10/10, Step: 711/938, Loss: 0.00019227237498853356\n",
            "Epoch: 10/10, Step: 712/938, Loss: 0.0006304950220510364\n",
            "Epoch: 10/10, Step: 713/938, Loss: 0.011436015367507935\n",
            "Epoch: 10/10, Step: 714/938, Loss: 0.10452356189489365\n",
            "Epoch: 10/10, Step: 715/938, Loss: 0.06872716546058655\n",
            "Epoch: 10/10, Step: 716/938, Loss: 0.0012928678188472986\n",
            "Epoch: 10/10, Step: 717/938, Loss: 2.9797625757055357e-05\n",
            "Epoch: 10/10, Step: 718/938, Loss: 0.00010634430509526283\n",
            "Epoch: 10/10, Step: 719/938, Loss: 2.4420805857516825e-05\n",
            "Epoch: 10/10, Step: 720/938, Loss: 0.00027216627495363355\n",
            "Epoch: 10/10, Step: 721/938, Loss: 0.0016361895250156522\n",
            "Epoch: 10/10, Step: 722/938, Loss: 0.0007194423815235496\n",
            "Epoch: 10/10, Step: 723/938, Loss: 0.019269470125436783\n",
            "Epoch: 10/10, Step: 724/938, Loss: 0.0027436933014541864\n",
            "Epoch: 10/10, Step: 725/938, Loss: 0.03746058791875839\n",
            "Epoch: 10/10, Step: 726/938, Loss: 0.0001902468502521515\n",
            "Epoch: 10/10, Step: 727/938, Loss: 9.191830031340942e-05\n",
            "Epoch: 10/10, Step: 728/938, Loss: 0.006912044249475002\n",
            "Epoch: 10/10, Step: 729/938, Loss: 0.090552419424057\n",
            "Epoch: 10/10, Step: 730/938, Loss: 0.002763933502137661\n",
            "Epoch: 10/10, Step: 731/938, Loss: 0.018550556153059006\n",
            "Epoch: 10/10, Step: 732/938, Loss: 0.001016008434817195\n",
            "Epoch: 10/10, Step: 733/938, Loss: 0.0002933921350631863\n",
            "Epoch: 10/10, Step: 734/938, Loss: 0.05564813315868378\n",
            "Epoch: 10/10, Step: 735/938, Loss: 0.006343017797917128\n",
            "Epoch: 10/10, Step: 736/938, Loss: 0.011028529144823551\n",
            "Epoch: 10/10, Step: 737/938, Loss: 0.002953758928924799\n",
            "Epoch: 10/10, Step: 738/938, Loss: 0.003248164663091302\n",
            "Epoch: 10/10, Step: 739/938, Loss: 0.0011452181497588754\n",
            "Epoch: 10/10, Step: 740/938, Loss: 0.010796534828841686\n",
            "Epoch: 10/10, Step: 741/938, Loss: 0.00010779558215290308\n",
            "Epoch: 10/10, Step: 742/938, Loss: 0.0005658321897499263\n",
            "Epoch: 10/10, Step: 743/938, Loss: 0.0004607814771588892\n",
            "Epoch: 10/10, Step: 744/938, Loss: 0.012332803569734097\n",
            "Epoch: 10/10, Step: 745/938, Loss: 0.07069811224937439\n",
            "Epoch: 10/10, Step: 746/938, Loss: 0.00010372786346124485\n",
            "Epoch: 10/10, Step: 747/938, Loss: 0.00022874513524584472\n",
            "Epoch: 10/10, Step: 748/938, Loss: 0.0017698588781058788\n",
            "Epoch: 10/10, Step: 749/938, Loss: 0.00015559270104859024\n",
            "Epoch: 10/10, Step: 750/938, Loss: 0.007582620717585087\n",
            "Epoch: 10/10, Step: 751/938, Loss: 0.0009423939627595246\n",
            "Epoch: 10/10, Step: 752/938, Loss: 2.486498033249518e-06\n",
            "Epoch: 10/10, Step: 753/938, Loss: 0.00022217615332920104\n",
            "Epoch: 10/10, Step: 754/938, Loss: 0.006469457410275936\n",
            "Epoch: 10/10, Step: 755/938, Loss: 0.00018085315241478384\n",
            "Epoch: 10/10, Step: 756/938, Loss: 2.276481973240152e-05\n",
            "Epoch: 10/10, Step: 757/938, Loss: 0.04234859719872475\n",
            "Epoch: 10/10, Step: 758/938, Loss: 0.08205601572990417\n",
            "Epoch: 10/10, Step: 759/938, Loss: 0.002022600034251809\n",
            "Epoch: 10/10, Step: 760/938, Loss: 0.000685174367390573\n",
            "Epoch: 10/10, Step: 761/938, Loss: 0.007981098257005215\n",
            "Epoch: 10/10, Step: 762/938, Loss: 3.275367271271534e-05\n",
            "Epoch: 10/10, Step: 763/938, Loss: 0.0009955107234418392\n",
            "Epoch: 10/10, Step: 764/938, Loss: 0.014427382498979568\n",
            "Epoch: 10/10, Step: 765/938, Loss: 0.0011075891088694334\n",
            "Epoch: 10/10, Step: 766/938, Loss: 0.0045525748282670975\n",
            "Epoch: 10/10, Step: 767/938, Loss: 0.001072402112185955\n",
            "Epoch: 10/10, Step: 768/938, Loss: 0.0009714199113659561\n",
            "Epoch: 10/10, Step: 769/938, Loss: 0.005526076070964336\n",
            "Epoch: 10/10, Step: 770/938, Loss: 0.001782709383405745\n",
            "Epoch: 10/10, Step: 771/938, Loss: 0.06400463730096817\n",
            "Epoch: 10/10, Step: 772/938, Loss: 0.0013470131671056151\n",
            "Epoch: 10/10, Step: 773/938, Loss: 0.0017225630581378937\n",
            "Epoch: 10/10, Step: 774/938, Loss: 0.00010086525435326621\n",
            "Epoch: 10/10, Step: 775/938, Loss: 0.0001283030433114618\n",
            "Epoch: 10/10, Step: 776/938, Loss: 0.0009515445563010871\n",
            "Epoch: 10/10, Step: 777/938, Loss: 0.002520845038816333\n",
            "Epoch: 10/10, Step: 778/938, Loss: 0.0002607566420920193\n",
            "Epoch: 10/10, Step: 779/938, Loss: 0.0070607904344797134\n",
            "Epoch: 10/10, Step: 780/938, Loss: 2.3790205887053162e-05\n",
            "Epoch: 10/10, Step: 781/938, Loss: 0.0007466414826922119\n",
            "Epoch: 10/10, Step: 782/938, Loss: 0.008025788702070713\n",
            "Epoch: 10/10, Step: 783/938, Loss: 0.0014029762241989374\n",
            "Epoch: 10/10, Step: 784/938, Loss: 0.029909731820225716\n",
            "Epoch: 10/10, Step: 785/938, Loss: 0.005618639290332794\n",
            "Epoch: 10/10, Step: 786/938, Loss: 0.0007049196865409613\n",
            "Epoch: 10/10, Step: 787/938, Loss: 0.0035911411978304386\n",
            "Epoch: 10/10, Step: 788/938, Loss: 0.01351996511220932\n",
            "Epoch: 10/10, Step: 789/938, Loss: 6.346408918034285e-05\n",
            "Epoch: 10/10, Step: 790/938, Loss: 3.920305607607588e-05\n",
            "Epoch: 10/10, Step: 791/938, Loss: 0.10625342279672623\n",
            "Epoch: 10/10, Step: 792/938, Loss: 0.04004489257931709\n",
            "Epoch: 10/10, Step: 793/938, Loss: 0.004804388619959354\n",
            "Epoch: 10/10, Step: 794/938, Loss: 0.00048325431998819113\n",
            "Epoch: 10/10, Step: 795/938, Loss: 0.0007560373633168638\n",
            "Epoch: 10/10, Step: 796/938, Loss: 3.2418753107776865e-05\n",
            "Epoch: 10/10, Step: 797/938, Loss: 4.106918640900403e-05\n",
            "Epoch: 10/10, Step: 798/938, Loss: 5.783167125628097e-06\n",
            "Epoch: 10/10, Step: 799/938, Loss: 1.1415455446694978e-05\n",
            "Epoch: 10/10, Step: 800/938, Loss: 0.018844421952962875\n",
            "Epoch: 10/10, Step: 801/938, Loss: 0.00016941972717177123\n",
            "Epoch: 10/10, Step: 802/938, Loss: 0.00010169930465053767\n",
            "Epoch: 10/10, Step: 803/938, Loss: 0.009255390614271164\n",
            "Epoch: 10/10, Step: 804/938, Loss: 0.01063776295632124\n",
            "Epoch: 10/10, Step: 805/938, Loss: 0.002642938867211342\n",
            "Epoch: 10/10, Step: 806/938, Loss: 0.00015400536358356476\n",
            "Epoch: 10/10, Step: 807/938, Loss: 0.00043568408000282943\n",
            "Epoch: 10/10, Step: 808/938, Loss: 0.0035131401382386684\n",
            "Epoch: 10/10, Step: 809/938, Loss: 0.005339429248124361\n",
            "Epoch: 10/10, Step: 810/938, Loss: 0.0006430464563891292\n",
            "Epoch: 10/10, Step: 811/938, Loss: 8.627464558230713e-05\n",
            "Epoch: 10/10, Step: 812/938, Loss: 7.063823431963101e-05\n",
            "Epoch: 10/10, Step: 813/938, Loss: 0.0003784452273976058\n",
            "Epoch: 10/10, Step: 814/938, Loss: 0.0006082745385356247\n",
            "Epoch: 10/10, Step: 815/938, Loss: 0.027477584779262543\n",
            "Epoch: 10/10, Step: 816/938, Loss: 0.0005691469996236265\n",
            "Epoch: 10/10, Step: 817/938, Loss: 0.0022606374695897102\n",
            "Epoch: 10/10, Step: 818/938, Loss: 0.0002738531620707363\n",
            "Epoch: 10/10, Step: 819/938, Loss: 0.00015476852422580123\n",
            "Epoch: 10/10, Step: 820/938, Loss: 0.03913599252700806\n",
            "Epoch: 10/10, Step: 821/938, Loss: 0.05905020609498024\n",
            "Epoch: 10/10, Step: 822/938, Loss: 0.00689740339294076\n",
            "Epoch: 10/10, Step: 823/938, Loss: 0.016327476128935814\n",
            "Epoch: 10/10, Step: 824/938, Loss: 5.129924466018565e-05\n",
            "Epoch: 10/10, Step: 825/938, Loss: 0.0009276553173549473\n",
            "Epoch: 10/10, Step: 826/938, Loss: 0.014196290634572506\n",
            "Epoch: 10/10, Step: 827/938, Loss: 0.0007909857667982578\n",
            "Epoch: 10/10, Step: 828/938, Loss: 0.00016095108003355563\n",
            "Epoch: 10/10, Step: 829/938, Loss: 0.0212598517537117\n",
            "Epoch: 10/10, Step: 830/938, Loss: 0.004220824223011732\n",
            "Epoch: 10/10, Step: 831/938, Loss: 0.03483525663614273\n",
            "Epoch: 10/10, Step: 832/938, Loss: 0.00018028964404948056\n",
            "Epoch: 10/10, Step: 833/938, Loss: 0.006030699238181114\n",
            "Epoch: 10/10, Step: 834/938, Loss: 0.0003480438026599586\n",
            "Epoch: 10/10, Step: 835/938, Loss: 0.041191913187503815\n",
            "Epoch: 10/10, Step: 836/938, Loss: 0.00014067403390072286\n",
            "Epoch: 10/10, Step: 837/938, Loss: 0.0033278418704867363\n",
            "Epoch: 10/10, Step: 838/938, Loss: 0.00026477285427972674\n",
            "Epoch: 10/10, Step: 839/938, Loss: 0.004481302574276924\n",
            "Epoch: 10/10, Step: 840/938, Loss: 0.0009349190513603389\n",
            "Epoch: 10/10, Step: 841/938, Loss: 0.003308367682620883\n",
            "Epoch: 10/10, Step: 842/938, Loss: 0.0001515604672022164\n",
            "Epoch: 10/10, Step: 843/938, Loss: 4.2580410081427544e-05\n",
            "Epoch: 10/10, Step: 844/938, Loss: 0.014132719486951828\n",
            "Epoch: 10/10, Step: 845/938, Loss: 0.0070115672424435616\n",
            "Epoch: 10/10, Step: 846/938, Loss: 4.1995626816060394e-05\n",
            "Epoch: 10/10, Step: 847/938, Loss: 0.02862362191081047\n",
            "Epoch: 10/10, Step: 848/938, Loss: 0.002988241147249937\n",
            "Epoch: 10/10, Step: 849/938, Loss: 0.00749623728916049\n",
            "Epoch: 10/10, Step: 850/938, Loss: 0.043765872716903687\n",
            "Epoch: 10/10, Step: 851/938, Loss: 0.007603927981108427\n",
            "Epoch: 10/10, Step: 852/938, Loss: 0.00012688100105151534\n",
            "Epoch: 10/10, Step: 853/938, Loss: 0.05643532797694206\n",
            "Epoch: 10/10, Step: 854/938, Loss: 0.0005342997028492391\n",
            "Epoch: 10/10, Step: 855/938, Loss: 0.0024150731042027473\n",
            "Epoch: 10/10, Step: 856/938, Loss: 0.00020760558254551142\n",
            "Epoch: 10/10, Step: 857/938, Loss: 0.07007225602865219\n",
            "Epoch: 10/10, Step: 858/938, Loss: 0.002539422595873475\n",
            "Epoch: 10/10, Step: 859/938, Loss: 0.004120838828384876\n",
            "Epoch: 10/10, Step: 860/938, Loss: 0.0027305432595312595\n",
            "Epoch: 10/10, Step: 861/938, Loss: 5.98957522015553e-05\n",
            "Epoch: 10/10, Step: 862/938, Loss: 0.021542377769947052\n",
            "Epoch: 10/10, Step: 863/938, Loss: 0.00024988455697894096\n",
            "Epoch: 10/10, Step: 864/938, Loss: 0.0001589272724231705\n",
            "Epoch: 10/10, Step: 865/938, Loss: 0.001641522510908544\n",
            "Epoch: 10/10, Step: 866/938, Loss: 0.02076350525021553\n",
            "Epoch: 10/10, Step: 867/938, Loss: 0.0005917034577578306\n",
            "Epoch: 10/10, Step: 868/938, Loss: 0.037869032472372055\n",
            "Epoch: 10/10, Step: 869/938, Loss: 0.00017852871678769588\n",
            "Epoch: 10/10, Step: 870/938, Loss: 2.475170185789466e-05\n",
            "Epoch: 10/10, Step: 871/938, Loss: 2.493885222065728e-05\n",
            "Epoch: 10/10, Step: 872/938, Loss: 0.004099508281797171\n",
            "Epoch: 10/10, Step: 873/938, Loss: 0.0004574513004627079\n",
            "Epoch: 10/10, Step: 874/938, Loss: 0.00019398890435695648\n",
            "Epoch: 10/10, Step: 875/938, Loss: 0.0004654531949199736\n",
            "Epoch: 10/10, Step: 876/938, Loss: 0.0018151749391108751\n",
            "Epoch: 10/10, Step: 877/938, Loss: 3.642318188212812e-05\n",
            "Epoch: 10/10, Step: 878/938, Loss: 4.846486262977123e-05\n",
            "Epoch: 10/10, Step: 879/938, Loss: 0.001824340084567666\n",
            "Epoch: 10/10, Step: 880/938, Loss: 0.009807144291698933\n",
            "Epoch: 10/10, Step: 881/938, Loss: 0.0012789383763447404\n",
            "Epoch: 10/10, Step: 882/938, Loss: 0.00048215201240964234\n",
            "Epoch: 10/10, Step: 883/938, Loss: 0.06980196386575699\n",
            "Epoch: 10/10, Step: 884/938, Loss: 0.004022281151264906\n",
            "Epoch: 10/10, Step: 885/938, Loss: 0.008755739778280258\n",
            "Epoch: 10/10, Step: 886/938, Loss: 0.03603019565343857\n",
            "Epoch: 10/10, Step: 887/938, Loss: 0.0008337987819686532\n",
            "Epoch: 10/10, Step: 888/938, Loss: 4.873311263509095e-05\n",
            "Epoch: 10/10, Step: 889/938, Loss: 0.00011379904026398435\n",
            "Epoch: 10/10, Step: 890/938, Loss: 4.499858550843783e-05\n",
            "Epoch: 10/10, Step: 891/938, Loss: 0.004194675944745541\n",
            "Epoch: 10/10, Step: 892/938, Loss: 0.00037559441989287734\n",
            "Epoch: 10/10, Step: 893/938, Loss: 0.006044442765414715\n",
            "Epoch: 10/10, Step: 894/938, Loss: 0.004628945142030716\n",
            "Epoch: 10/10, Step: 895/938, Loss: 0.005215183831751347\n",
            "Epoch: 10/10, Step: 896/938, Loss: 0.08138464391231537\n",
            "Epoch: 10/10, Step: 897/938, Loss: 0.08375827223062515\n",
            "Epoch: 10/10, Step: 898/938, Loss: 0.11404010653495789\n",
            "Epoch: 10/10, Step: 899/938, Loss: 0.008000582456588745\n",
            "Epoch: 10/10, Step: 900/938, Loss: 0.0010162538383156061\n",
            "Epoch: 10/10, Step: 901/938, Loss: 0.032013267278671265\n",
            "Epoch: 10/10, Step: 902/938, Loss: 0.0007018992910161614\n",
            "Epoch: 10/10, Step: 903/938, Loss: 0.0007729802164249122\n",
            "Epoch: 10/10, Step: 904/938, Loss: 0.0004921396030113101\n",
            "Epoch: 10/10, Step: 905/938, Loss: 0.00018121942412108183\n",
            "Epoch: 10/10, Step: 906/938, Loss: 0.0034627753775566816\n",
            "Epoch: 10/10, Step: 907/938, Loss: 0.0007820515311323106\n",
            "Epoch: 10/10, Step: 908/938, Loss: 0.0002078962279483676\n",
            "Epoch: 10/10, Step: 909/938, Loss: 0.0001493702584411949\n",
            "Epoch: 10/10, Step: 910/938, Loss: 0.00017931855109054595\n",
            "Epoch: 10/10, Step: 911/938, Loss: 0.0005642616306431592\n",
            "Epoch: 10/10, Step: 912/938, Loss: 0.0005767861730419099\n",
            "Epoch: 10/10, Step: 913/938, Loss: 0.0035936313215643167\n",
            "Epoch: 10/10, Step: 914/938, Loss: 0.022050336003303528\n",
            "Epoch: 10/10, Step: 915/938, Loss: 0.0002919904363807291\n",
            "Epoch: 10/10, Step: 916/938, Loss: 4.0562317735748366e-05\n",
            "Epoch: 10/10, Step: 917/938, Loss: 0.0015119763556867838\n",
            "Epoch: 10/10, Step: 918/938, Loss: 0.002086983760818839\n",
            "Epoch: 10/10, Step: 919/938, Loss: 0.0018708830466493964\n",
            "Epoch: 10/10, Step: 920/938, Loss: 0.005168745759874582\n",
            "Epoch: 10/10, Step: 921/938, Loss: 0.00023712329857517034\n",
            "Epoch: 10/10, Step: 922/938, Loss: 0.004438488744199276\n",
            "Epoch: 10/10, Step: 923/938, Loss: 0.0015045213513076305\n",
            "Epoch: 10/10, Step: 924/938, Loss: 4.127603460801765e-05\n",
            "Epoch: 10/10, Step: 925/938, Loss: 0.000501222733873874\n",
            "Epoch: 10/10, Step: 926/938, Loss: 0.0004181778058409691\n",
            "Epoch: 10/10, Step: 927/938, Loss: 0.07087235897779465\n",
            "Epoch: 10/10, Step: 928/938, Loss: 0.038593851029872894\n",
            "Epoch: 10/10, Step: 929/938, Loss: 0.0001844468351919204\n",
            "Epoch: 10/10, Step: 930/938, Loss: 3.6477900721365586e-05\n",
            "Epoch: 10/10, Step: 931/938, Loss: 0.0015494348481297493\n",
            "Epoch: 10/10, Step: 932/938, Loss: 4.8846271965885535e-05\n",
            "Epoch: 10/10, Step: 933/938, Loss: 4.355509372544475e-05\n",
            "Epoch: 10/10, Step: 934/938, Loss: 0.0005792526062577963\n",
            "Epoch: 10/10, Step: 935/938, Loss: 1.9266870367573574e-05\n",
            "Epoch: 10/10, Step: 936/938, Loss: 0.0002660521131474525\n",
            "Epoch: 10/10, Step: 937/938, Loss: 6.554352876264602e-05\n",
            "Epoch: 10/10, Step: 938/938, Loss: 0.00013474505976773798\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images\n",
        "    labels = labels\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = cost(outputs, labels)\n",
        "\n",
        "    # Back prop and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{num_epochs}, Step: {i+1}/{total_step}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMkDZp3KBtQN",
        "outputId": "1aa39093-9dc2-46f4-aefa-77bb972a4df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 99.07 %\n"
          ]
        }
      ],
      "source": [
        "# Test the Model\n",
        "\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pkdd3dh1PqFS"
      },
      "outputs": [],
      "source": [
        "# Save state_dict\n",
        "torch.save(model.state_dict(), \"lenet_mnist.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
